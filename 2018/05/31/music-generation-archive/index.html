<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="Zhili">
<meta name="description" content="Sed magna purus, fermentum eu, tincidunt eu, varius ut, felis. Morbi mollis tellus ac sapien. Vestibulum ullamcorper mauris at ligula. In hac habitasse platea dictumst. Vivamus in erat ut urna cursus vestibulum.
    ">
<meta name="keywords" content="åšå®¢, æŠ€æœ¯, ç”Ÿç‰©ä¿¡æ¯ï¼Œç²¾å‡†åŒ»ç–—, é—ä¼ å’¨è¯¢, é«˜é€šé‡æŠ€æœ¯, ç®—æ³•, å­¦ä¹ , ä½œå“, å†™ä½œ, C&#43;&#43;, Perl">
<meta name="referrer" content="always">
<title>A simple archive for music generation - sy123.ml</title>
<link rel="stylesheet" type="text/css" href="/css/main.css">
<link rel="icon" href="/logo/favicon.ico" type="image/x-icon">
</head>
<body>
<header>
  <div>
    <h1><a href="https://sy123.ml/">sy123.ml</a></h1><h2><a href="https://sy123.ml/">winter is coming.</a></h2>
  </div>
  <nav><a href="/tags/">Tags</a><a href="/about/">About</a></nav>
</header>
<main>
  <article>
    <div class="title">
  <h1>A simple archive for music generation</h1>
  </div>
<div class="meta">
  <div>2018-05-31 16:07</div>
  <div>
    <span><a href="https://sy123.ml/tags/music/">#music</a></span>
      <span><a href="https://sy123.ml/tags/recourse/">#recourse</a></span>
      </div>
  </div>
<div class="content">
  <p>A random collection of recent works on music generation.</p>
<!-- toc -->
<h1 id="papers">Papers</h1>
<ul>
<li><strong>Melody Generation for Pop Music via Word Representation of Musical Properties</strong> (2017.10) [<a href="https://arxiv.org/abs/1710.11549">arXiv</a>] [<a href="https://github.com/mil-tokyo/NeuralMelody">Code</a>]</li>
<li><strong>Generating Nontrivial Melodies for Music as a Service</strong> (2017.10) [<a href="https://arxiv.org/abs/1710.02280">arXiv</a>] [<a href="https://composing.ai">Page</a>]</li>
<li><strong>MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks</strong> (2017.9) [<a href="https://arxiv.org/abs/1709.06298">arXiv</a>] [<a href="https://salu133445.github.io/musegan/">Page</a>]</li>
<li><strong>Similarity Embedding Network for Unsupervised Sequential Pattern Learning by Playing Music Puzzle Games</strong> ï¼ˆ2017.9ï¼‰[<a href="https://arxiv.org/abs/1709.04384">arXiv</a>] [<a href="https://remyhuang.github.io/DJnet">Page</a>]</li>
<li><strong>A Tutorial on Deep Learning for Music Information Retrieval</strong> (2017.9) [<a href="https://arxiv.org/abs/1709.04396">arXiv</a>]</li>
<li><strong>Deep Learning Techniques for Music Generation - A Survey</strong> (2017.9) [<a href="https://arxiv.org/abs/1709.01620">arXiv</a>] (è®ºæ–‡ç»¼è¿°)</li>
<li><strong>Neural Translation of Musical Style</strong> (2017.8) [<a href="https://arxiv.org/abs/1708.03535">arXiv</a>] [<a href="http://imanmalik.com/cs/2017/06/05/neural-style.html">Page</a>]</li>
<li><strong>GLSR-VAE: Geodesic Latent Space Regularization for Variational AutoEncoder Architectures</strong> (2017.7) [<a href="https://arxiv.org/abs/1707.04588">arXiv</a>]</li>
<li><strong>Learning and Evaluating Musical Features with Deep Autoencoders</strong> (2017.6) [<a href="https://arxiv.org/abs/1706.04486">arXiv</a>]</li>
<li><strong>Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models</strong> (2017.5) [<a href="https://arxiv.org/abs/1705.10843">arXiv</a>] [<a href="https://github.com/gablg1/ORGAN">Code</a>]</li>
<li><strong>MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation using 1D and 2D Conditions</strong> - <strong>ISMIR 2017</strong> (2017.3) [<a href="https://arxiv.org/abs/1703.10847">arXiv</a>] [<a href="https://richardyang40148.github.io/TheBlog/midinet_arxiv_demo.html">Page</a>]</li>
<li><strong>Automatic Conversion of Pop Music into Chiptunes for 8-bit Pixel Art</strong> - <strong>ICASSP 2017</strong> (2017.2) [<a href="http://mac.citi.sinica.edu.tw/~yang/pub/su17icassp_8bit.pdf">Paper</a>] [<a href="https://github.com/LemonATsu/pop-to-8bit">Code</a>] [<a href="https://lemonatsu.github.io">Page</a>]</li>
<li><strong>DeepBach: a Steerable Model for Bach Chorales Generation</strong> (2016.12) [<a href="https://arxiv.org/abs/1612.01010">arXiv</a>] [<a href="https://github.com/Ghadjeres/DeepBach">Code</a>]</li>
<li><strong>C-RNN-GAN: Continuous Recurrent Neural Networks with Adversarial Training</strong> (2016.11) [<a href="https://arxiv.org/abs/1611.09904">arXiv</a>] [<a href="https://github.com/olofmogren/c-rnn-gan">Code</a>] ðŸŒŸ</li>
<li><strong>Tuning Recurrent Neural Networks with Reinforcement Learning - ICLR 2017</strong> (2016.11) [<a href="https://arxiv.org/abs/1611.02796">arXiv</a>] [<a href="https://magenta.tensorflow.org/2016/11/09/tuning-recurrent-networks-with-reinforcement-learning">Web</a>] [<a href="https://github.com/tensorflow/magenta/tree/master/magenta/models/rl_tuner">Code</a>] ðŸŒŸ</li>
<li><strong>SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient</strong> - <strong>AAAI 2017</strong> (2016.9) [<a href="http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14344/14489">Paper</a>] [<a href="https://github.com/LantaoYu/SeqGAN">Code</a>]</li>
<li><strong>Song From PI: A Musically Plausible Network for Pop Music Generation</strong> - <strong>ICLR 2017</strong> [<a href="https://arxiv.org/abs/1611.03477">arXiv</a>] [<a href="http://www.theregister.co.uk/2016/11/11/ai_pop_music_maker/">Reports</a>]ðŸŒŸ</li>
<li><strong>Text-based LSTM networks for Automatic Music Composition</strong> (2016.4) [<a href="https://arxiv.org/abs/1604.05358#">arXiv</a>] [<a href="https://keunwoochoi.wordpress.com/2016/02/23/lstmetallica/">Web</a>] [<a href="https://github.com/keunwoochoi/LSTMetallica">Code</a>]</li>
<li><strong>Music Transcription Modelling and Composition Using Deep Learning</strong> (2016.4) [<a href="https://arxiv.org/abs/1604.08723">arXiv</a>] [<a href="https://github.com/IraKorshunova/folk-rnn">Code</a>]</li>
<li><strong>Composing A Melody with Long-short Term Memory (LSTM) Recurrent Neural Networks</strong> (2016.2) [<a href="http://konstilackner.github.io/LSTM-RNN-Melody-Composer-Website/">Web</a>] [<a href="https://github.com/konstilackner/LSTM-RNN-Melody-Composer">Code</a>] [<a href="http://konstilackner.github.io/LSTM-RNN-Melody-Composer-Website/Thesis_final01.pdf">Paper</a>]</li>
<li><strong>Neural Adaptive Sequential Monte Carlo - NIPS 2015</strong> (2015) [<a href="http://papers.nips.cc/paper/5961-neural-adaptive-sequential-monte-carlo.pdf">Paper</a>]</li>
<li><strong>A Recurrent Latent Variable Model for Sequential Data - NIPS 2015</strong> (2015) [<a href="http://papers.nips.cc/paper/5653-a-recurrent-latent-variable-model-for-sequential-data.pdf">Paper</a>] [<a href="https://github.com/jych/nips2015_vrnn">Code</a>]</li>
<li><strong>AI Methods in Algorithmic Composition: A Comprehensive Survey</strong> (2013) [<a href="http://www.jair.org/media/3908/live-3908-7454-jair.pdf">Paper</a>] ðŸŒŸ</li>
<li><strong>Modeling Temporal Dependencies in High-dimensional Sequences: Application to Polyphonic Music Generation and Transcription</strong> (2012) [<a href="https://arxiv.org/abs/1206.6392">arXiv</a>]</li>
<li><strong>Towards Adaptive Music Generation By Reinforcement Learning of Musical Tension</strong> (2010) [<a href="https://ccrma.stanford.edu/~slegroux/affect/pubs/SMC2010.pdf">Paper</a>]</li>
<li><strong>A First Look at Music Composition using LSTM Recurrent Neural Networks</strong> (2002) [<a href="http://www.iro.umontreal.ca/~eckdoug/blues/index.html">Web</a>] [<a href="http://www.iro.umontreal.ca/~eckdoug/blues/IDSIA-07-02.pdf">Paper</a>]</li>
</ul>
<h1 id="projects">Projects</h1>
<ul>
<li><strong>Google Magenta</strong> [<a href="https://magenta.tensorflow.org/welcome-to-magenta">Web</a>] [<a href="https://github.com/tensorflow/magenta">Code</a>]</li>
<li><strong>Deep Jazz</strong>  [<a href="https://deepjazz.io/">Web</a>] [<a href="https://deepjazz.io/">Code</a>]</li>
<li><strong>BachBot</strong> [<a href="http://bachbot.com/">Web</a>] [<a href="https://github.com/feynmanliang/bachbot/">Code</a>]</li>
<li><strong>WaveNet</strong> [<a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">Web</a>][<a href="https://github.com/ibab/tensorflow-wavenet">Code</a>] (not fully)</li>
<li><strong>GRUV</strong> [<a href="https://github.com/MattVitelli/GRUV">Code</a>]</li>
<li><strong>Kulitta</strong> [<a href="https://github.com/donya/Kulitta">Code</a>]</li>
</ul>
<h1 id="applications">Applications</h1>
<ul>
<li><strong>AIVA</strong>[<a href="http://aiva.ai">Link</a>]</li>
<li><strong>Google A.I. Duet</strong> [<a href="https://aiexperiments.withgoogle.com/ai-duet">Link</a>]</li>
<li><strong>The Infinite Drum Machine</strong> [<a href="https://aiexperiments.withgoogle.com/drum-machine">Link</a>]</li>
<li><strong>Amper Music</strong> [<a href="https://www.ampermusic.com/app#/">Link</a>]</li>
<li><strong>Intelligent Music System</strong> [<a href="http://120.52.72.53/www.intelligentmusicsystems.com/c3pr90ntc0td/vid/tempo_shifting.mp4">Link</a>]</li>
<li><strong>Unwind</strong> [<a href="http://unwind.ai">Link</a>]</li>
<li><strong>Tidalcycles</strong> [<a href="https://tidalcycles.org">Link</a>] [<a href="https://www.youtube.com/watch?v=xoa3OT8ncX0">Video</a>]</li>
<li><strong>Jukedeck</strong> [<a href="https://www.jukedeck.com/">Link</a>]</li>
</ul>
<h1 id="conferencesworkshops">Conferences&amp;Workshops</h1>
<ul>
<li><strong>ACM MM</strong> - ACM MultiMedia [<a href="http://www.acmmm.org/2017">Web</a>]</li>
<li><strong>ISMIR</strong> - The International Society of Music Information Retrieval [<a href="http://www.ismir.net/">Web</a>]</li>
<li><strong>ICASSP</strong> - Conference on Acoustics, Speech and Signal Processing [<a href="http://www.ieee-icassp2017.org/">Web</a>]</li>
<li><strong>DLM</strong> - Deep Learning for Music Workshop [<a href="http://dorienherremans.com/dlm2017/">Web</a>]</li>
<li><strong>CSMC</strong> - Conference on Computer Simulation of Musical  Creativity [<a href="https://csmc2016.wordpress.com/">Web</a>]</li>
<li><strong>CCRMA</strong> - Center for Computer Research in Music and Acoustics (Stanford University) [<a href="https://ccrma.stanford.edu/">Web</a>]</li>
<li><strong>ICMC</strong> - Internatonal Computer Music Conference [<a href="http://www.icmc2017.com/">Web</a>] [<a href="http://www.icmc2017.com/cn/page1.html">Lists</a>]</li>
</ul>
<h1 id="blogs">Blogs</h1>
<ul>
<li><strong>Neural Nets for Generating Music</strong> [<a href="https://medium.com/@kcimc/neural-nets-for-generating-music-f46dffac21c0">Web</a>]</li>
<li><strong>Generative Music with JavaScript &amp; Web Audio</strong> [<a href="https://teropa.info/generative-music-slides/">Web</a>]</li>
<li><strong>The Current State Of AI: Artificial Intelligence In Music, Movies &amp; More</strong> (2017.7) [<a href="http://www.hypebot.com/hypebot/2017/07/ai-today-the-current-state-of-artificial-intelligence.html">Web</a>]</li>
<li><strong>Composing Music With Recurrent Neural Networks</strong> (2015.8) [<a href="http://www.hexahedria.com/2015/08/03/composing-music-with-recurrent-neural-networks/">Web</a>] [<a href="https://github.com/hexahedria/biaxial-rnn-music-composition">Code</a>]</li>
<li><strong>Analyzing deep learning tools for music generation</strong> [<a href="http://www.asimovinstitute.org/analyzing-deep-learning-tools-music/">Web</a>]</li>
<li><strong>COORD</strong> [<a href="http://www.coord.fm/home/">Web</a>]</li>
<li><strong>How evolved LSTMS improvise on a melogy you specify</strong>[<a href="https://www.sentient.ai/sentient-labs/ea/lstm-music/">Web</a>]</li>
<li><strong>AI makes pop music in the style of any composer</strong>[<a href="http://www.flow-machines.com/ai-makes-pop-music/">Web</a>]</li>
<li><strong>Richard Yang's Blog</strong>[<a href="https://richardyang40148.github.io/TheBlog/index.html">Blog</a>]</li>
<li><strong>Thousands of bird sounds visualized using machine learning</strong>[<a href="https://experiments.withgoogle.com/bird-sounds">Web</a>]</li>
<li><strong>Music AI: Loop-in-the-Human</strong>[<a href="https://medium.com/@jayhardesty/music-ai-loop-in-the-human-1a15681e573e">Web</a>]</li>
</ul></div>

  </article>
</main>
<footer>
  <div>
    <div>
      2007-2020 Zhili.</div>
  </div>
</footer>
</body>
</html>

[{"categories":[],"contents":"前端掘金者H\n一、DOMContentLoaded的概念 当初始HTML文档已完全加载和解析时，将触发DOMContentLoaded事件，而不需要等待样式表，图像和子框��页面加载。与 window.onload 事件非常相似，但有一定区别：\nDOMContentLoaded 事件是在文档完全加载和解析之后触发 window.onload 事件不但文档完全加载和解析完毕，相关资源都要加载完毕，比如图片和CSS文件等 二、HTML解析过程与DOMContentLoaded触发时机 1. 既无JS也无CSS的情况 2. 有CSS但无JS的情况 由图可见，DOMContentLoaded触发仍为DOM之后，无论此时CSS解析为CSSOM的过程是否完成。\n3. 既有CSS也有JS的情况 上图描述的只包含了同步加载脚本的情况，然而对于JS的引用却不止一种方式，对于通过 async 和 defer 引用脚本，DOMContentLoaded触发时机存在差异：\n（1）普通JS/sync（同步） 文档解析的过程中，如果遇到script脚本，就会停止页面的解析进行下载，当脚本都执行完毕后，才会继续解析页面。\n（2）async（异步） async 脚本会在加载完毕后执行，下面两种情况都是有可能发生的：\n①HTML 还没有被解析完的时候，async 脚本已经加载完了；那么 HTML 停止解析，去执行脚本，脚本执行完毕后继续 HTML 加载与解析，HTML 解析完了之后触发 DOMContentLoaded 事件。\n②HTML 解析完了之后，async脚本才加载完，然后再执行脚本；那么在HTML解析完毕、async 脚本还没加载完的时候就触发 DOMContentLoaded 事件。\n（3）defer 文档解析时遇到设置了 defer 的脚本，就会在后台进行下载，但是并不会阻止文档的渲染，当页面解析和渲染完毕后，会等到所有的 defer 脚本加载完毕并按照顺序执行完毕才会触发 DOMContentLoaded 事件，下面两种情况都是有可能发生的：\n①HTML 还没有被解析完的时候，defer脚本已经加载完了，那么 等待HTML 解析完成后执行脚本，脚本执行完毕后触发 DOMContentLoaded 事件。\n②HTML 解析完了之后，defer脚本才加载完，然后再执行脚本，脚本执行完毕后触发 DOMContentLoaded 事件。\n原文\n","date":"2024-08-04","permalink":"http://localhost:1313/posts/1722768240/","section":"","summary":"","tags":[""],"title":"深入理解DOMContentLoaded的触发时机"},{"categories":[""],"contents":"前言 今天在浏览网页时发现页面上的数字变成了表情符号，而且空格符号也显示异常\n解决 定位到元素的字体后用fc-match逐个测试后才发现找不到最后的通用字体sans-serif只能匹配到Segoe UI Emoji，经过排查发现是由于之前在配置字体时随意复制了一些网上的配置导致系统字体出现了问题，很多配置全乱写，conf.d的软链接也全死了，全干掉用默认得了\n~/.config/fontconfig/ ❯ sudo pacman -Rns noto-fonts ttf-dejavu adobe-source-han* ttf-roboto ❯ rm -f fonts.conf ❯ rm -f conf.d/* ❯ ln -s /etc/fonts/fonts.conf ❯ ln -s conf.avail/64-language-selector-prefer.conf conf.d/ ❯ cat conf.d/64-language-selector-prefer.conf Copy \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;sans-serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Liberation Sans\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Color Emoji\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Emoji\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;serif\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Liberation Serif\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Serif CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Color Emoji\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Emoji\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;alias\u0026gt; \u0026lt;family\u0026gt;monospace\u0026lt;/family\u0026gt; \u0026lt;prefer\u0026gt; \u0026lt;family\u0026gt;Source Code Pro\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK SC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK TC\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK JP\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Sans Mono CJK KR\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Color Emoji\u0026lt;/family\u0026gt; \u0026lt;family\u0026gt;Noto Emoji\u0026lt;/family\u0026gt; \u0026lt;/prefer\u0026gt; \u0026lt;/alias\u0026gt; \u0026lt;/fontconfig\u0026gt; 参考资料 https://wiki.archlinux.org/title/Font_configuration\n","date":"2024-08-03","permalink":"http://localhost:1313/posts/1722679457/","section":"","summary":"","tags":[""],"title":"解决Noto字体数字和空格使用emoji符号数字"},{"categories":[],"contents":"用了这么多年SwitchyOmega才发现这玩意是多余的，有了clash后除了调试切代理方便真没啥用，旧时代的残党该死死了🤔\nCopy \u0026#34;C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\u0026#34; --proxy-server=\u0026#34;socks://127.0.0.1:1080\u0026#34; Copy google-chrome-stable --proxy-server=\u0026#34;socks://127.0.0.1:1080\u0026#34; ","date":"2024-07-29","permalink":"http://localhost:1313/posts/1722231351/","section":"","summary":"","tags":["",""],"title":"chrome 全局代理"},{"categories":[""],"contents":"订阅转换 https://subweb.sbe.us.kg\nhttps://acl4ssr-sub.github.io\n面板 https://yacd.metacubex.one/#/proxies\nhttps://yacd.haishan.me/\nhttps://yacd-meta.vercel.app/\nhttps://clash.dejavu.moe/\n其他 https://emn178.github.io/online-tools/url_decode.html\nhttps://emn178.github.io/online-tools/base64_decode.html\nhttps://pb.sbf.us.kg/\n命令 使用以下命令检查 mihomo 的运行日志：\nCopy journalctl -u mihomo -o cat -e Phasellus nec sem in justo pellentesque facilisis. In consectetuer turpis ut velit. Cras dapibus. Proin magna. Donec sodales sagittis magna.s ante. ","date":"2024-07-28","permalink":"http://localhost:1313/posts/mihomo/","section":"","summary":"","tags":[""],"title":"Mihomo"},{"categories":[],"contents":"输入搜索内容 ","date":"2024-07-27","permalink":"http://localhost:1313/search/","section":"","summary":"","tags":[],"title":"搜索"},{"categories":[],"contents":"","date":"2024-07-27","permalink":"http://localhost:1313/tools/yacdmeta/","section":"","summary":"","tags":[""],"title":"yacdmeta"},{"categories":[],"contents":"","date":"2024-07-27","permalink":"http://localhost:1313/tools/jsj/","section":"","summary":"","tags":[""],"title":"jsj.lol"},{"categories":[],"contents":"","date":"2024-07-26","permalink":"http://localhost:1313/tools/suoyt/","section":"","summary":"","tags":[""],"title":"suoyt"},{"categories":[""],"contents":"升级后发现虚拟机全炸了，查下日志基本看起来libvirtd不知为何使用了iptables而不是nftables\njournalctl -u libvirtd -o cat -f libvirtd[2311]: internal error: Failed to apply firewall rules /usr/sbin/ip6tables -w --table filter --list-rules: ip6tables v1.8.4 (nf_tables): table filter is incompatible, use nft tool. 关掉防火墙能正常通网，或者加条规则让数据能通过主机防火墙规则通过桥接器返回\necho -A FORWARD -m physdev --physdev-is-bridged -j ACCEPT \u0026gt;\u0026gt; /etc/sysconfig/iptables 研究半天无果，wiki搜关键词iptables找到个建议照做改了默认后端后就正常了，libvirtd跟nftables的交互似乎有点问题，以后还是不使用libvirtd创建虚拟网络好点\nCopy echo firewall_backend=\u0026#34;iptables\u0026#34; \u0026gt;\u0026gt; /etc/libvirt/network.conf See aslo https://wiki.archlinux.org/title/Libvirt/ ","date":"2024-07-25","permalink":"http://localhost:1313/posts/kvmnonet/","section":"","summary":"","tags":["",""],"title":"libvirt升级后虚拟机没网络"},{"categories":[],"contents":"手动操作需求：在升级过程中，如果涉及到JDK和JRE的更新或替换，可能需要用户手动执行一些操作。这是因为这些软件包之间可能存在依赖关系或冲突，自动升级工具可能无法妥善处理。\nJDK和JRE的安装：\n如果用户同时安装了JDK和JRE，可以使用pacman命令手动安装JDK。pacman -Sy jdk-openjdk命令会下载并安装JDK，而pacman -Su命令则会更新系统上的所有已安装的软件包。执行这些命令后，与JRE相关的软件包可能会被移除，因为JDK本身包含了JRE的功能。 JRE和JRE-headless的选择：\n如果用户同时安装了JRE和JRE-headless（无头版本的JRE，通常用于没有图形用户界面的服务器环境），则需要手动选择一个进行安装。这是因为它们之间可能存在冲突，不能同时存在于同一个系统中。用户需要根据自己的需求选择其中一个版本进行安装。 单一安装的情况：\n如果用户系统中只安装了JDK、JRE或JRE-headless中的一个，那么pacman应该能够正常解决依赖关系，无需用户进行额外的手动操作。\nSee aslo https://archlinux.org/news/incoming-changes-in-jdk-jre-21-packages-may-require-manual-intervention/ ","date":"2024-03-28","permalink":"http://localhost:1313/posts/kb2919351/","section":"","summary":"","tags":["",""],"title":"Incoming changes in JDK / JRE 21 packages may require manual intervention"},{"categories":[],"contents":"原因：我的系统是Windows Server 2012 R2 Standard首先我是想要安装SVN客户端，然后系统让我安装Windows Server 2012 R2 安装补丁KB2999226\n思路：经过网上查找资料安装补丁KB2999226之前需要安装KB2919355，安装KB2919355之前必须安装补丁KB2919442，一层一层的，当然过程显然没那么顺利，记录下安装过程\n下载补丁KB2919442；KB2919355；KB2999226 请百度查找相关文件上自行下载补丁，这里也有链接：\nhttps://support.microsoft.com/en-us/help/2919442/march-2014-servicing-stack-update-for-windows-8-1-and-windows-server-2\nhttps://support.microsoft.com/en-us/help/2919355/windows-rt-8-1-windows-8-1-windows-server-2012-r2-update-april-2014\nhttps://support.microsoft.com/en-us/help/2999226/update-for-universal-c-runtime-in-windows\nKB2919442 此更新不适用于你的计算机\n我记得当年刷surface贴吧就看过有老哥说过这个补丁只能第一个安装，很多更新都不能卸载，无奈只能回到初始快照，然后就顺利装上了\nKB2919355 Installation Failure: Windows failed to install the following update with error 0x80070070: Update for Windows (KB2919355).\n看了下C盘空间还有6G，看下日志也是disk full之类的报错，我之前就帮同事处理过这类问题，很明显就是系统还原的问题，服务器完全用不到关掉就好，但是关闭系统还原后就引出本文的主题，真正的难题\nWe couldn’t update system reserved partition, error code 0x800f0922.\n参考了这个链接后我发现这个是老疑难杂症了，众说纷纭说啥的都有，不过根据各种线索再结合我自己的情况基本可以确定是分区问题，如果是正常安装的系统无论是uefi还是legacy应该都是能正常更新，不过开csm的就很不正常了，这也是为什么当年很多人都出问题，我不想折腾切换成legacy模式来更新就完事了\n不用uefi固件就好，xml文件也一样\n$ qemu-system-x86_64 -cdrom ubuntu-21.04-desktop-amd64.iso # -bios /usr/share/ovmf/OVMF.fd 果然改成legacy模式就能正常更新了，真是一波三折，最后顺利安装KB2999226，安装圆满成功了，我的SVN客户端也安装完成。\n后记 为了防止麻烦我觉得还是得集成这两个更新一劳永逸，直接把打好补丁的系统做成镜像\n# 准备工作 # 首先，您需要确保系统中已经安装了 genisoimage 工具，如果没有，请使用以下命令安装： sudo apt-get install genisoimage # 创建目录 # 在根目录下创建一个空目录（例如 myiso）用于存放 ISO 镜像文件： sudo mkdir /myiso # 复制系统文件 # 将当前系统的所有文件复制到 myiso 目录下： sudo cp -r / /myiso # 这个命令会将整个文件系统复制到 myiso 目录下。 # 创建 ISO 镜像文件 # 现在，可以使用以下命令创建 ISO 镜像文件： sudo genisoimage -o /myiso.iso -r -J /myiso # 该命令将在根目录下创建名为 myiso.iso 的 ISO 镜像文件。 #-r 表示以 ISO9660 标准创建镜像，-J 表示使用 Joliet 扩展格式支持长文件名和中文文件名。 # 清理工作 # 最后，可以将 myiso 目录删除： sudo rm -rf /myiso # 到此为止，您已经成功将当前系统制作成 ISO 镜像文件。 # 如果需要在其他计算机上安装此系统，可以将该镜像文件刻录到光盘或者使用虚拟机软件进行安装。 See aslo https://www.microsoft.com/en-us/download/details.aspx?id=42335 ","date":"2023-10-13","permalink":"http://localhost:1313/posts/kb2919355/","section":"","summary":"","tags":[""],"title":"Windows update KB2919355 fails to install - Error code 800F0922"},{"categories":[],"contents":"git clone/push 我的 Github 私人仓库，通过ssh，命令行报错：\nCloning into \u0026#39;test\u0026#39;... kex_exchange_identification: Connection closed by remote host Connection closed by 20.205.243.166 port 22 fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 但是关闭 clash 之后一切正常，看了下clash日志原来是机场屏蔽了22端口\n改成通过443端口git clone就没问题了 ssh配置需要进行一下修改 https://docs.github.com/en/authentication/troubleshooting-ssh/using-ssh-over-the-https-port\ncat ~/site/blog ❯ cat ~/.ssh/config Host github.com Hostname ssh.github.com Port 443 User git ","date":"2022-12-05","permalink":"http://localhost:1313/posts/git-pory22/","section":"","summary":"","tags":["",""],"title":"无法使用 git clone/push，kex ssh 密钥错误"},{"categories":[],"contents":"linux下的chrome内置翻译也只能用系统代理，linux还是比windows好解决，不过我懒得折腾还是直接改hosts好了\nsu echo 180.163.151.34 translate.googleapis.com \u0026gt;\u0026gt; /etc/hosts systemctl restart systemd-networkd ","date":"2022-10-09","permalink":"http://localhost:1313/posts/chrome-translate/","section":"","summary":"","tags":["",""],"title":"Chrome内置翻译被抢"},{"categories":[],"contents":"当配置好i3窗口后，使用polybar显示状态时，如果使用命令行启动polybar时，经常会提示\nDropping unmatched character  (U+f02b)\n这样的错误。这时候就需要注意了，可能是没有安装Awesom字体所致。\n在Ubuntu下安装也很简单：\nsudo apt-get fonts-font-awesome\n这时候重启polybar,应该可以正常显示状态栏上的图标。\n如果这时还不成，可能就需要改改polybar配置里面的字体设置。要知道怎么使用字体设置，还需要执行一个指令：\nfc-list | grep awesome\n输出如下：\n/usr/share/fonts/opentype/font-awesome/FontAwesome.otf: FontAwesome:style=Regular /usr/share/fonts/woff/fork-awesome/forkawesome-webfont.woff: forkawesome:style=Regular /usr/share/fonts/truetype/fork-awesome/forkawesome-webfont.ttf: forkawesome:style=Regular /usr/share/fonts/woff/fork-awesome/forkawesome-webfont.woff2: forkawesome:style=Regular /usr/share/fonts/truetype/font-awesome/fontawesome-webfont.ttf: FontAwesome:style=Regular 这时候，字体路径后面的比如 FontAwesome:style=Regular，这段文字，就是需要放到配置文件中的内容。\n修改完成后如下：\nfont-0 = ttf-liberation-sans:fixed:pixelsize=12;1 font-1 = source han sans cn:pixelsize=12:antialias=false;1 font-2 = \u0026#34;Font Awesome 6 Free:style=Solid:pixelsize=12;1\u0026#34; font-3 = \u0026#34;Font Awesome 6 Brands:style=Regular:pixelsize=12;1\u0026#34; font-4 = \u0026#34;material icons:pixelsize=16;3\u0026#34; 我这次不显示图标的原因是升级导致的，Awesome5改成6就好了\n","date":"2022-10-09","permalink":"http://localhost:1313/posts/polybar-awesome/","section":"","summary":"","tags":[""],"title":"polybar不显示Awesome字体"},{"categories":[],"contents":"pacman安装软件包出现损坏 很久没用了arch了，更新一下出现了签名过期问题，记录下\nFile .pkg.tar.xz is corrupted (invalid or corrupted package (PGP signature)).Do you want to delete it? [Y/n] # 更新已知的密钥 (没啥用甚至卡住) pacman-key --refresh-keys # 其实先更新下就好了 pacman -S archlinux-keyring pacman -Syu See aslo http://www.mamicode.com/info-detail-1674262.html ","date":"2022-03-23","permalink":"http://localhost:1313/posts/20220323-archlinux-pgp-signature/","section":"","summary":"","tags":[""],"title":"Archlinux PGP Signature"},{"categories":[],"contents":"换了新显卡这么久才发现会画面撕裂，网上搜了下在v2看到有人提到关闭渲染器的硬件加速可以解决，试了下果然有效\ncompton --backend xrender 彻底解决 顺藤摸瓜进去wiki查下了原因是i3的BUG，这么多年至今都未修复，之后还发现compton已经被重定向到Picom，估计已经没人维护了，我也要跑路了\nsudo pacman -S picom 我的compton配置是直接从别人仓库里git clone的有没有垂直同步不知道，反正picom是默认开启垂直同步，一劳永逸终于可以不用看不到烦人的裂缝\nSee aslo https://wiki.archlinux.org/title/Picom ","date":"2021-05-16","permalink":"http://localhost:1313/posts/20210516-picom/","section":"","summary":"","tags":["",""],"title":"linux 解决i3画面撕裂"},{"categories":[],"contents":"前言 今天我试着更新我的 Arch Linux 系统，然后遇到一个错误 error：failed to commit transaction (conflicting files) stfl：/usr/lib/libstfl.so.0 exists in filesystem。看起来是 pacman 无法更新一个已经存在于文件系统上的库 (/usr/lib/libstfl.so.0)。如果你也遇到了同样的问题，下面是一个快速解决方案。\n解决 用自带的命令覆盖，wiki上是推荐这种做法\nsudo pacman -Syu --overwrite /usr/lib/libstfl.so.0 暴力解决，直接解决出问题的文件，或者你也可以把重复的包备份一下防止意外，不过一般没啥意外，按照经验出这个问题的方式千奇百怪，反正就是更新出错了，比如你更新的时候换源之类的操作也会导致这样，直接删掉就完事\nsudo rm /usr/lib/libstfl.so.0 最后更新就完事\nsudo pacman -Syu 我选择第三种方法，直接删除该文件然后升级 Arch Linux 系统。很有效！\n我用linux一直秉承着能偷懒就偷懒的原则，已经折腾不动了，鬼知道我年轻的时候到底经历了什么。\n希望本文对你有所帮助。还有更多好东西。敬请期待！\nSee aslo https://wiki.archlinux.org/index.php/pacman#%22Failed_to_commit_transaction_(conflicting_files)%22_error\n","date":"2020-11-25","permalink":"http://localhost:1313/posts/20201125-archlinux-failed-to-commit-transaction-conflicting-file/","section":"","summary":"","tags":["",""],"title":"Archlinux Failed to Commit Transaction Conflicting File"},{"categories":[],"contents":"新游戏被用户狂喷无奈研究一下，先在官方的问题跟踪器查一下就发现很多开发者纷纷都说是android 11的问题，我当场裂开，修复完又要改代码，之前一直在模拟器调试没啥问题，我自己用pixel 11测试一下果然秒退，还好11没普及，修复不存在的，混就完事\nSee also https://issuetracker.unity3d.com/issues/android-il2cpp-empty-project-crashes-on-launch-with-using-memoryadresses-from-more-than-16gb-of-memory-messages\n","date":"2020-11-18","permalink":"http://localhost:1313/posts/20201118-android-il2cpp-empty-project-crashes-on-launch-with-using-memoryadresses-from-more-than-16gb-of-memory-messages/","section":"","summary":"","tags":["",""],"title":"unity游戏提示 Using memoryadresses from more than 16GB of memory "},{"categories":[],"contents":"前言 最近又在搞某游戏，懒得跟程序员斗智斗勇了，直接来抓包一劳永逸，不过chrome导入自签证书失败了，网上查了下现在只支持PKCS12证书\nmake a p12 file 为了将.crt和.key正确导入Chrome的nssdb数据库，建议将客户端证书+私钥转换为PKCS12证书，例如：\nopenssl pkcs12 -export -inkey ./sample.key -in ./sample.crt -out ./sample.p12 为其提供所需的任何导出密码，请写下来，因为稍后导入时将需要它。\n之后你就可以导入sample.p12。\n","date":"2020-11-09","permalink":"http://localhost:1313/posts/20201109-private-key-is-missing-or-invalid-when-importing-a-certificate-in-google-chrom/","section":"","summary":"","tags":[],"title":"解决浏览器以及手机导入证书失败"},{"categories":[],"contents":"错误提示如下\n$ ssh root@108.61.163.242 @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the ECDSA key sent by the remote host is SHA256:HDjXJvu0VYXWF+SKMZjSGn4FQmg/+w6eV9ljJvIXpx0. Please contact your system administrator. Add correct host key in /Users/wangdong/.ssh/known_hosts to get rid of this message. Offending ECDSA key in /Users/wangdong/.ssh/known_hosts:46 ECDSA host key for 108.61.163.242 has changed and you have requested strict checking. Host key verification failed. 这里面，有一句很关键\nECDSA host key for 108.61.163.242 has changed and you have requested strict checking. Host key verification failed. 一般这个问题，是你重置过你的服务器或者虚拟机后，你再次想访问会出现这个问题。\n解决方法 手动去删除掉就完事，或者直接用 ssh-keygen 命令\nssh-keygen -R 108.61.163.242 密钥环管理 seahorse ","date":"2020-11-05","permalink":"http://localhost:1313/posts/20201105-how-to-fix-the-error-host-key-verification-failed/","section":"","summary":"","tags":["",""],"title":"解决Host key verification failed"},{"categories":[],"contents":"环境：Mint Xfce 19 x64 我平时使用的鼠标移动速度比较慢，而且鼠标加速从来不开。一般1000-1200DPI最适合我。Mint下鼠标疯狂起飞，手腕一抖鼠标指针飞过半个屏幕让我很是头疼。而xfce设置里的鼠标速度似乎完全没有作用，Google后我发现这其实是历史的锅，以前X11是用xset管理输入设备的，现在变成了xinput。而xfce的设置还是去修改xset的配置文件。\n既然如此，那我们只能来手动研究一下xinput怎么改鼠标速度了。\n$ xinput -list # 可以查看到所有输入设备，我的部分输出如下： ⎡ Virtual core pointer id=2 [master pointer (3)] ⎜ ↳ Virtual core XTEST pointer id=4 [slave pointer (2)] ⎜ ↳ SynPS/2 Synaptics TouchPad id=15 [slave pointer (2)] ⎜ ↳ PixArt USB Optical Mouse id=11 [slave pointer (2)] ⎣ Virtual core keyboard id=3 [master keyboard (2)] ↳ Virtual core XTEST keyboard id=5 [slave keyboard (3)] 可以看到，USB鼠标id为11，接下来再去查看USB鼠标的详细信息：\n$ xinput -list-props 11 Device \u0026#39;PixArt USB Optical Mouse\u0026#39;: Device Enabled (145): 1 Coordinate Transformation Matrix (147): 1.000000, 0.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000, 0.000000, 1.000000 libinput Natural Scrolling Enabled (280): 0 libinput Natural Scrolling Enabled Default (281): 0 libinput Scroll Methods Available (282): 0, 0, 1 libinput Scroll Method Enabled (283): 0, 0, 0 libinput Scroll Method Enabled Default (284): 0, 0, 0 libinput Button Scrolling Button (285): 2 libinput Button Scrolling Button Default (286): 2 libinput Middle Emulation Enabled (287): 0 libinput Middle Emulation Enabled Default (288): 0 libinput Accel Speed (289): ]0.000000 libinput Accel Speed Default (290): 0.000000 libinput Accel Profiles Available (291): 1, 1 libinput Accel Profile Enabled (292): 1, 0 libinput Accel Profile Enabled Default (293): 1, 0 libinput Left Handed Enabled (294): 0 libinput Left Handed Enabled Default (295): 0 libinput Send Events Modes Available (265): 1, 0 libinput Send Events Mode Enabled (266): 0, 0 libinput Send Events Mode Enabled Default (267): 0, 0 Device Node (268): \u0026#34;/dev/input/event5\u0026#34; Device Product ID (269): 2362, 9488 libinput Drag Lock Buttons (296): \u0026lt;no items\u0026gt; libinput Horizontal Scroll Enabled (297): 1 根据libinput官网文档所述：https://wayland.freedesktop.org/libinput/doc/latest/scrolling.html 前面一堆Scroll的都是触摸板的参数，不管他，下面一个Accel Speed就是我想要的，找到文档对应部分： https://wayland.freedesktop.org/libinput/doc/latest/configuration.html#pointer-acceleration 可以看到，设置区间为[-1,1]，默认是0，那么我现在嫌它快了，直接设置为-0.5，可用看到这个属性的id是289，所以执行\nxinput set-prop 11 289 -0.5 完美解决\n当然，我还需要搞个开机启动，考虑到图形界面下才会有鼠标，这个设置放在systemd的multi-user节点或者直接扔xprofile/.xinitrc里比较合适，图懒省事，我直接扔~/.xinitrc里了。\n","date":"2020-08-05","permalink":"http://localhost:1313/posts/20200805-linux-set-mouse-speed/","section":"","summary":"","tags":[],"title":"解决linux下鼠标移动速度太快的问题(libinput)"},{"categories":[],"contents":"做为Bioconductor包作者，而git push传代码到Bioconductor上是被封的。这很是恼火，随着10月份将迎来新一版本的Bioconductor发布，不能够push代码是多么惨的一件事。\n代理其实也挺恼火的，因为各种协议啊，你要各种设置啊，http/https/ssh/git都是各种配置，其实我只要有一个socks5的代理，然后你们所有需要走代理的程序都通过它就好了。\n谁特么有空天天在琢磨怎么配置各种不同协议的代理！只要我们想得到的，一般都有人做了。\n于是万能的github上找到了proxychains。\nA hook preloader that allows to redirect TCP traffic of existing dynamically linked programs through one or more SOCKS or HTTP proxies 它强制给定程序发起的TCP连接通过事先配置的代理。可以涵盖所有需要代理的情景。就以git为例，没有proxychains的话，就必须为每个协议（https, git, ssh）按照git文档的要求分别设置代理，过程复杂且不稳定。有了proxychains，这些完全可以不用管，当然应用场景不限于git，任何一个需要代理的命令行程序都是一样在运行的指令前面加proxychains完事。\nArch安装很容易：\nyay -S proxychains-ng 安装之后，打开/etc/proxychains.conf，注释掉下面这行（disable远程DNS解析，有DNS污染风险）。\nproxy_dns 最后添加如下行：\nsocks5 127.0.0.1 32997 上面这个代理是我自己机器上跑了某著名软件，用于每日科学上网。\n我平时是同时push到Bioconductor和github上的，所以我不会跑完一个git push再跑一个，而是写在Makefile里，自动化这个过程，我只需要make push指令就OK。\n所以此处我用的指令是：\nproxychains make push 这样就加了代理。\n$ proxychains make push #### #### 实际的指令，有两条，分别push到两个服务器 #### [proxychains] config file found: /etc/proxychains.conf [proxychains] preloading /usr/lib/libproxychains4.so [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 git push upstream master;\\ git push origin master #### #### 第一条指令，push到Bioconductor #### [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 [proxychains] Strict chain ... 127.0.0.1:32997 ... 34.192.48.227:22 ... OK [proxychains] DLL init: proxychains-ng 4.13 Enumerating objects: 56, done. Counting objects: 100% (56/56), done. Delta compression using up to 4 threads Compressing objects: 100% (34/34), done. Writing objects: 100% (41/41), 4.87 KiB | 4.87 MiB/s, done. Total 41 (delta 32), reused 11 (delta 7) To git.bioconductor.org:packages/ggtree.git c372741..e84c1f7 master -\u0026gt; master #### #### 第二条指令，push到github #### [proxychains] DLL init: proxychains-ng 4.13 [proxychains] DLL init: proxychains-ng 4.13 [proxychains] Strict chain ... 127.0.0.1:32997 ... 192.30.253.112:22 ... OK [proxychains] DLL init: proxychains-ng 4.13 Enumerating objects: 11, done. Counting objects: 100% (11/11), done. Delta compression using up to 4 threads Compressing objects: 100% (6/6), done. Writing objects: 100% (6/6), 843 bytes | 843.00 KiB/s, done. Total 6 (delta 5), reused 0 (delta 0) remote: Resolving deltas: 100% (5/5), completed with 5 local objects. To github.com:GuangchuangYu/ggtree.git 92847e8..e84c1f7 master -\u0026gt; master 整个世界清静了，没法push到Bioconductor困扰我多时。而且经过了这个事件，以后打命令，只要需要代理的，都可以直接加proxychains搞定了，没有各种配置的烦恼。\n","date":"2020-07-27","permalink":"http://localhost:1313/posts/20200727-proxychains/","section":"","summary":"","tags":[],"title":"Proxychains"},{"categories":[],"contents":"前言 新买了耳机发现没声音，上网查了一下发现耳机自带了 usb 驱动，又又又开始了折腾之旅～\n解决声音问题 # 切换一下就完事 ~/site/blog ❯ asoundconf list Names of available sound cards: PCH Device ~/site/blog ❯ asoundconf set-default-card 1 Polybar 报错 \u0026ldquo;error: Disabling module \u0026ldquo;alsa\u0026rdquo; (reason: Could not connect pulseaudio context.)\u0026rdquo; 音乐嗨了没多久才发现顶部工具栏调不了音量，查了下日志发现报错了，后来在 issues 上找到解决方法，搞定收工\n; ~/.config/polybar/config [module/alsa] type = internal/alsa ; Soundcard to be used ; Usually in the format hw:# where # is the card number ; You can find the different card numbers in `/proc/asound/cards` master-soundcard = hw:1 speaker-soundcard = hw:1 headphone-soundcard = hw:1 ; Name of the master, speaker and headphone mixers ; Use the following command to list available mixer controls: ; $ amixer scontrols | sed -nr \u0026#34;s/.*\u0026#39;([[:alnum:]]+)\u0026#39;.*/\\1/p\u0026#34; ; If master, speaker or headphone-soundcard isn\u0026#39;t the default, ; use `amixer -c # scontrols` instead where # is the number ; of the master, speaker or headphone soundcard respectively ; ; Default: Master master-mixer = Speaker ; Optionally define speaker and headphone mixers ; Default: none speaker-mixer = Speaker 20200629 更新 今天 usb 设备变动后，声音又出问题了，cat /proc/asound/modules查看一下后发现是顺序乱了，再读了一遍文章发现有更简单的解决方法\n# Set the default sound card ~/site/blog ❯ cat /etc/modprobe.d/alsa-base.conf options snd_usb_audio index=0 options snd_hda_intel index=1 前面的配置文件全删了再改一下 polybar 又正常了～\n20210512 # Good news! I found a solution # It seems to be that this is issue is reported in Ubuntu kernel 5.3.0-41 and -42, you can go into details in this Bug report # Anyway the easiest way to fix it is to: # Edit /etc/modprobe.d/alsa-base.conf as root and add options snd-hda-intel dmic_detect=0 at the end of this file by writing this on the terminal: echo \u0026#34;options snd-hda-intel dmic_detect=0\u0026#34; | sudo tee -a /etc/modprobe.d/alsa-base.conf # Edit /etc/modprobe.d/blacklist.conf as root and add blacklist snd_soc_skl at the end of the file by writing this on the terminal: echo \u0026#34;blacklist snd_soc_skl\u0026#34; | sudo tee -a /etc/modprobe.d/blacklist.conf # Restart the computer 20210513 时隔很久又来折腾声音，电脑性能不足换了新设备，固态插上去直接点亮你敢信？\n不过有点小小瑕疵alsa禁音会禁用混音，看了下issues他们好像都说是BUG，秉承着不解决问题的原则(逃，这次决定改用更方便的pulseaudio控制音量\nsudo pacman -S pulseaudio-alsa polybar模块里注释掉alsa启动pulseaudio模块\nSee also https://wiki.sabayon.org/index.php?title=HOWTO:_Configure_ALSA_to_handle_a_USB_sound_card\nhttps://raspberrypi.stackexchange.com/questions/19705/usb-card-as-my-default-audio-device\nhttps://wiki.archlinux.org/index.php/Advanced_Linux_Sound_Architecture\nhttps://github.com/polybar/polybar/issues/1287\nhttps://wiki.archlinux.org/index.php/Advanced_Linux_Sound_Architecture#Set_the_default_sound_card\nhttps://superuser.com/questions/626606/how-to-make-alsa-pick-a-preferred-sound-device-automatically\nhttps://bugs.launchpad.net/ubuntu/+source/pulseaudio/+bug/878986\n","date":"2020-06-22","permalink":"http://localhost:1313/posts/20200622-usb-card-as-my-default-audio-device/","section":"","summary":"","tags":[""],"title":"linux 使用usb声卡"},{"categories":[""],"contents":"rc4.js\n/* * RC4 symmetric cipher encryption/decryption * * @license Public Domain * @param string key - secret key for encryption/decryption * @param string str - string to be encrypted/decrypted * @return string */ function rc4(key, str) { var s = [], j = 0, x, res = \u0026#39;\u0026#39;; for (var i = 0; i \u0026lt; 256; i++) { s[i] = i; } for (i = 0; i \u0026lt; 256; i++) { j = (j + s[i] + key.charCodeAt(i % key.length)) % 256; x = s[i]; s[i] = s[j]; s[j] = x; } i = 0; j = 0; for (var y = 0; y \u0026lt; str.length; y++) { i = (i + 1) % 256; j = (j + s[i]) % 256; x = s[i]; s[i] = s[j]; s[j] = x; res += String.fromCharCode(str.charCodeAt(y) ^ s[(s[i] + s[j]) % 256]); } return res; } ","date":"2020-06-07","permalink":"http://localhost:1313/files/20200607-rc4/","section":"","summary":"","tags":["",""],"title":"Rc4"},{"categories":[],"contents":"base64.c\n#include \u0026lt;stdint.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; static char encoding_table[] = {\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;H\u0026#39;, \u0026#39;I\u0026#39;, \u0026#39;J\u0026#39;, \u0026#39;K\u0026#39;, \u0026#39;L\u0026#39;, \u0026#39;M\u0026#39;, \u0026#39;N\u0026#39;, \u0026#39;O\u0026#39;, \u0026#39;P\u0026#39;, \u0026#39;Q\u0026#39;, \u0026#39;R\u0026#39;, \u0026#39;S\u0026#39;, \u0026#39;T\u0026#39;, \u0026#39;U\u0026#39;, \u0026#39;V\u0026#39;, \u0026#39;W\u0026#39;, \u0026#39;X\u0026#39;, \u0026#39;Y\u0026#39;, \u0026#39;Z\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;f\u0026#39;, \u0026#39;g\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;i\u0026#39;, \u0026#39;j\u0026#39;, \u0026#39;k\u0026#39;, \u0026#39;l\u0026#39;, \u0026#39;m\u0026#39;, \u0026#39;n\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;p\u0026#39;, \u0026#39;q\u0026#39;, \u0026#39;r\u0026#39;, \u0026#39;s\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;u\u0026#39;, \u0026#39;v\u0026#39;, \u0026#39;w\u0026#39;, \u0026#39;x\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;z\u0026#39;, \u0026#39;0\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;, \u0026#39;3\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;5\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;7\u0026#39;, \u0026#39;8\u0026#39;, \u0026#39;9\u0026#39;, \u0026#39;+\u0026#39;, \u0026#39;/\u0026#39;}; static char *decoding_table = NULL; static int mod_table[] = {0, 2, 1}; char *base64_encode(const unsigned char *data, size_t input_length, size_t *output_length) { *output_length = 4 * ((input_length + 2) / 3); char *encoded_data = malloc(*output_length); if (encoded_data == NULL) return NULL; for (int i = 0, j = 0; i \u0026lt; input_length;) { uint32_t octet_a = i \u0026lt; input_length ? (unsigned char)data[i++] : 0; uint32_t octet_b = i \u0026lt; input_length ? (unsigned char)data[i++] : 0; uint32_t octet_c = i \u0026lt; input_length ? (unsigned char)data[i++] : 0; uint32_t triple = (octet_a \u0026lt;\u0026lt; 0x10) + (octet_b \u0026lt;\u0026lt; 0x08) + octet_c; encoded_data[j++] = encoding_table[(triple \u0026gt;\u0026gt; 3 * 6) \u0026amp; 0x3F]; encoded_data[j++] = encoding_table[(triple \u0026gt;\u0026gt; 2 * 6) \u0026amp; 0x3F]; encoded_data[j++] = encoding_table[(triple \u0026gt;\u0026gt; 1 * 6) \u0026amp; 0x3F]; encoded_data[j++] = encoding_table[(triple \u0026gt;\u0026gt; 0 * 6) \u0026amp; 0x3F]; } for (int i = 0; i \u0026lt; mod_table[input_length % 3]; i++) encoded_data[*output_length - 1 - i] = \u0026#39;=\u0026#39;; return encoded_data; } unsigned char *base64_decode(const char *data, size_t input_length, size_t *output_length) { if (decoding_table == NULL) build_decoding_table(); if (input_length % 4 != 0) return NULL; *output_length = input_length / 4 * 3; if (data[input_length - 1] == \u0026#39;=\u0026#39;) (*output_length)--; if (data[input_length - 2] == \u0026#39;=\u0026#39;) (*output_length)--; unsigned char *decoded_data = malloc(*output_length); if (decoded_data == NULL) return NULL; for (int i = 0, j = 0; i \u0026lt; input_length;) { uint32_t sextet_a = data[i] == \u0026#39;=\u0026#39; ? 0 \u0026amp; i++ : decoding_table[data[i++]]; uint32_t sextet_b = data[i] == \u0026#39;=\u0026#39; ? 0 \u0026amp; i++ : decoding_table[data[i++]]; uint32_t sextet_c = data[i] == \u0026#39;=\u0026#39; ? 0 \u0026amp; i++ : decoding_table[data[i++]]; uint32_t sextet_d = data[i] == \u0026#39;=\u0026#39; ? 0 \u0026amp; i++ : decoding_table[data[i++]]; uint32_t triple = (sextet_a \u0026lt;\u0026lt; 3 * 6) + (sextet_b \u0026lt;\u0026lt; 2 * 6) + (sextet_c \u0026lt;\u0026lt; 1 * 6) + (sextet_d \u0026lt;\u0026lt; 0 * 6); if (j \u0026lt; *output_length) decoded_data[j++] = (triple \u0026gt;\u0026gt; 2 * 8) \u0026amp; 0xFF; if (j \u0026lt; *output_length) decoded_data[j++] = (triple \u0026gt;\u0026gt; 1 * 8) \u0026amp; 0xFF; if (j \u0026lt; *output_length) decoded_data[j++] = (triple \u0026gt;\u0026gt; 0 * 8) \u0026amp; 0xFF; } return decoded_data; } void build_decoding_table() { decoding_table = malloc(256); for (int i = 0; i \u0026lt; 64; i++) decoding_table[(unsigned char) encoding_table[i]] = i; } ","date":"2020-06-07","permalink":"http://localhost:1313/files/20200607-base64/","section":"","summary":"","tags":["",""],"title":"Base64"},{"categories":[],"contents":"前言 之前安装 noto-fonts-emoji 这个包后一直半彩色半黑白吊着，看着是真的不爽，实在太懒，今天在google意外看到很简单就解决了\n解决方法 01-emoji.conf \u0026lt;?xml version=\u0026#39;1.0\u0026#39;?\u0026gt; \u0026lt;!DOCTYPE fontconfig SYSTEM \u0026#39;fonts.dtd\u0026#39;\u0026gt; \u0026lt;fontconfig\u0026gt; \u0026lt;match target=\u0026#34;pattern\u0026#34;\u0026gt; \u0026lt;edit name=\u0026#34;family\u0026#34; mode=\u0026#34;prepend\u0026#34;\u0026gt; \u0026lt;string\u0026gt;Noto Color Emoji\u0026lt;/string\u0026gt; \u0026lt;string\u0026gt;Noto Emoji\u0026lt;/string\u0026gt; \u0026lt;/edit\u0026gt; \u0026lt;/match\u0026gt; \u0026lt;/fontconfig\u0026gt; cp 01-emoji.conf $HOME/.config/fontconfig/conf.d/ fc-cache -f -v 重启就能显示大部分了，不过还是有一些之前没法显示，emoji还是有问题，以后再研究了\nSee also https://getemoji.com/ https://www.reddit.com/r/archlinux/comments/6wkval/enable_noto_color_emoji_easily/ ","date":"2020-05-28","permalink":"http://localhost:1313/posts/20200528-enable-noto_color-emoji-easily/","section":"","summary":"","tags":[""],"title":"Linux显示彩色Emoji表情"},{"categories":[],"contents":"Golang 在 VSCode 中的调试配置 （解决Golang在VSCode中调试时无法接收标准输入(stdin)的问题）\n最近开始接触Go语言，但在配置VSCode的调试文件的时候发现VSCode中的官方GO插件调试时用的是调试控制台(debug console)而非终端(terminal)，找了很多设置也没有类似于terminal或者internalTerminal或者externalTerminal的配置项。最终在vscode-go仓库的issue里找到了问题所在。鉴于目前还没有国内的博客帖子总结该问题，在这里总结一下问题原因及解决方案。\n问题起因 最开始以为是vscode-go插件的锅，但在相关问题的issue里，vscode-go的开发团队给出的回复是，由于delve调试器本身在普通模式运行时就无法直接接受命令行标准输入(stdin)，导致配套的相关插件也无法正常工作。本来delve自身加上支持接受命令行输入的功能即可彻底解决这个问题，但似乎delve开发团队的人员并不对此感兴趣，不少开发者也同样也对此表示无奈,只有用目前其他开发者给出的折中的解决办法。\n解决方案 虽然delve在普通模式下不能接受标准输入(stdin)，但其在headless模式下是可以接受标准输入的。在VSCode中我们也可以借助这个特性来实现Golang的调试时输入功能。\n以下是开发者HowieLiuX给出的参考配置：\ntasks.json\n{ // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format \u0026ldquo;version\u0026rdquo;: \u0026ldquo;2.0.0\u0026rdquo;, \u0026ldquo;tasks\u0026rdquo;: [ { \u0026ldquo;label\u0026rdquo;: \u0026ldquo;echo\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;shell\u0026rdquo;, \u0026ldquo;command\u0026rdquo;: \u0026ldquo;cd ${fileDirname} \u0026amp;\u0026amp; dlv debug \u0026ndash;headless \u0026ndash;listen=:2345 \u0026ndash;log \u0026ndash;api-version=2\u0026rdquo;, \u0026ldquo;problemMatcher\u0026rdquo;: [], \u0026ldquo;group\u0026rdquo;: { \u0026ldquo;kind\u0026rdquo;: \u0026ldquo;build\u0026rdquo;, \u0026ldquo;isDefault\u0026rdquo;: true } } ] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 launch.json\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026ldquo;version\u0026rdquo;: \u0026ldquo;0.2.0\u0026rdquo;, \u0026ldquo;configurations\u0026rdquo;: [ { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;Connect to server\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;go\u0026rdquo;, \u0026ldquo;request\u0026rdquo;: \u0026ldquo;launch\u0026rdquo;, \u0026ldquo;mode\u0026rdquo;: \u0026ldquo;remote\u0026rdquo;, \u0026ldquo;remotePath\u0026rdquo;: \u0026ldquo;${fileDirname}\u0026rdquo;, \u0026ldquo;port\u0026rdquo;: 2345, \u0026ldquo;host\u0026rdquo;: \u0026ldquo;127.0.0.1\u0026rdquo;, \u0026ldquo;program\u0026rdquo;: \u0026ldquo;${fileDirname}\u0026rdquo;, \u0026ldquo;env\u0026rdquo;: {}, \u0026ldquo;args\u0026rdquo;: [] } ] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 然而，我在macOS平台尝试以以上配置启动调试时却先后遇到了 zsh\u0026#x1f4bf;1: too many arguments、 zsh:1: command not found: dlv Request type of \u0026rsquo;launch\u0026rsquo; with mode \u0026lsquo;remote\u0026rsquo; is deprecated, please use request type \u0026lsquo;attach\u0026rsquo; with mode \u0026lsquo;remote\u0026rsquo; instead. 这些问题。\n在大半天的折腾之后，总结下来问题1是由于路径中含有特殊符号（如空格），需要将cd ${fileDirname}改为cd \u0026quot;${fileDirname}\u0026quot;；问题2是由于PATH似乎并没有被自动添加到启动的终端中。我的解决方案是在执行命令之前执行source /etc/profile命令。问题3则应该将launch.json中\u0026quot;request\u0026quot;: \u0026ldquo;launch\u0026quot;改为\u0026quot;request\u0026rdquo;: \u0026ldquo;attach\u0026rdquo;\n以下是我现在使用的配置\ntasks.json\n{ // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format \u0026ldquo;version\u0026rdquo;: \u0026ldquo;2.0.0\u0026rdquo;, \u0026ldquo;tasks\u0026rdquo;: [ { \u0026ldquo;label\u0026rdquo;: \u0026ldquo;echo\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;shell\u0026rdquo;, \u0026ldquo;command\u0026rdquo;: \u0026ldquo;cd \u0026quot;${fileDirname}\u0026quot; \u0026amp;\u0026amp; source /etc/profile \u0026amp;\u0026amp; ~/Applications/Go/bin/dlv debug \u0026ndash;headless \u0026ndash;listen=:2346 \u0026ndash;api-version=2\u0026rdquo;, \u0026ldquo;problemMatcher\u0026rdquo;: [], \u0026ldquo;group\u0026rdquo;: { \u0026ldquo;kind\u0026rdquo;: \u0026ldquo;build\u0026rdquo;, \u0026ldquo;isDefault\u0026rdquo;: true } } ] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 launch.json\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026ldquo;version\u0026rdquo;: \u0026ldquo;0.2.0\u0026rdquo;, \u0026ldquo;configurations\u0026rdquo;: [ { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;Connect to server\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;go\u0026rdquo;, \u0026ldquo;request\u0026rdquo;: \u0026ldquo;attach\u0026rdquo;, \u0026ldquo;mode\u0026rdquo;: \u0026ldquo;remote\u0026rdquo;, \u0026ldquo;remotePath\u0026rdquo;: \u0026ldquo;${workspaceFolder}\u0026rdquo;, \u0026ldquo;port\u0026rdquo;: 2346, \u0026ldquo;host\u0026rdquo;: \u0026ldquo;127.0.0.1\u0026rdquo;, \u0026ldquo;internalConsoleOptions\u0026rdquo;: \u0026ldquo;neverOpen\u0026rdquo; } ] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 调试步骤 因为tasks.json中已经将当前配置isDefault为true,只需要按快捷键cmd+shift+B先启动build任务，再按调试键，即可正常调试。\n以上为macOS的推荐配置，Windows用户可以尝试Windows的推荐解决方案 ———————————————— 版权声明：本文为CSDN博主「微光。」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。 原文链接：https://blog.csdn.net/weixin_42529589/article/details/104583672\nmy dotfile launch.json\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Connect to server\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;attach\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;remote\u0026#34;, \u0026#34;remotePath\u0026#34;: \u0026#34;${workspaceRoot}\u0026#34;, \u0026#34;port\u0026#34;: 2345, \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, } ] } tasks.json\n{ // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;debug server\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;cd ${workspaceRoot} \u0026amp;\u0026amp; dlv debug --headless --listen=:2345 --log --api-version=2\u0026#34;, \u0026#34;problemMatcher\u0026#34;: [], \u0026#34;group\u0026#34;: { \u0026#34;kind\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;isDefault\u0026#34;: true } } ] } See also issues ","date":"2020-05-18","permalink":"http://localhost:1313/posts/20200518-vscode-go-interactive-debug-console/","section":"","summary":"","tags":["",""],"title":"解决Golang在VSCode中调试时无法接收标准输入的问题"},{"categories":[],"contents":"Intent 功能太强大了，比较常用的就是Activity （Service）之间的数据传递。举个简单例百子，在当前Activity1使用startActvity(intent)或者startActivityForResult(intent, code)方法跳转到另一个Activity2之前，如果要传递某度些String类型数据给Activity2，则会执行intent.putExtra(String str, String Key),将专String数据打包到Intent中，并给它一个Key标识。在Activity2当中，getIntent()方法获得这个intent，然后再getStringExtra(Key)，就可以获得你之前打包的那个数据了。这种机制属非常简单，也比较好用。\n对于一个要执行的操作来说，Intent算作是一个抽象描述。比如通过startActivity(Intent)启动一个Activity、sendBroadcast(Intent)发送一个广播或者通过startService bindService和后台服务进行交互。\nIntent为执行在不同应用不同组件之间代码的延时运行绑定提供了灵活的支持。最常见的用于启动activities，可以把Intent看做Activity之间的胶水。除此之外，Intent还持有一个数据结构来保存执行动作的抽象描述。\nIntent 对象 虽说Intent是一个抽象描述，但是对于具体的Intent类来说它可以被归纳为携带一组信息的信使，正是该信使在安卓组件间进行传递才能达到信息传递的效果。\nIntent 结构 一个Intent对象可以包含以下信息： Action\n可以直译为动作，它是Intent的一条‘命令’。具体action以String类型来命名，Intent类中定义了许多action常量来匹配不同的Intent对象。例如ACTION_VIEW ACTION_EDIT ACTION_MAIN等。action的存取可以通过setAction()和getAction()得到。\nData\ndata结构是要往Intent过滤器中添加的，使用data类型（mimeType属性）通常可以解释为一个规格或者说明书，它既可以是一个Uri表达式也可以是一个mimeType。使用URI表达式时，要按顺序书写Uri每一部分的属性，注意:当使用URL属性来指定时，如果不把‘schema’指定清楚的话，所有的URI属性都被忽视。如果‘host’不指定的话，则它的‘port’和‘path’属性都被忽视。\n使用setData()方法只可以设置URI属性的Data，如果设置mimeType属性的Data需要使用setType()方法。对于setDataAndType()方法既可以设置Uri也可以设置MIME，getData()和getType()分别获取URI和MIME类型。\n下面是action/data 的例子：\nACTION_VIEW content://contacts/people/1 显示person表中标识符为1的联系人。 ACTION_DIAL content://contacts/people/1 显示电话拨号界面并且在显示框中显示person表中标识符为1联系人的电话号码 ACTION_VIEW tel:123 显示电话拨号界面并且在显示框中填入123. ACTION_DIAL tel:123 显示电话拨号界面并且在显示框中填入123. ACTION_EDIT content://contacts/people/1 编辑person表中标识符为1的联系人的信息。 ACTION_VIEW content://contacts/people/ 显示people列表 ACTION_SET_WALLPAPER 显示设置选择壁纸 Category\ncategory是Intent中可选部分，以String类型命名并且包含了组件如何操作Intent的额外信息。使用addCategory()方法添加category，使用removeCategory()删除之前添加的category，getCategories()方法可以获取当前设置的category。\nExtras\n以键值对形式添加的一组额外信息，它将通过Intent递交给组件进行处理。extras可以通过putExtras()和getExtras()方法进行存取操作。\nFlags\n这里的标记主要指启动Activity的方式，也是Intent可选部分。要是单独讲解Activity启动方式就要另起篇幅了（以后的任务）。\n组件名字\n这部分也是Intent可选部分，通常是指具体Activity Service和BroadcastReceiver类名。如果设置了，Intent对象将被递交给这个具体的组件进行处理，否则的话，安卓将使用其他信息寻找要启动的组件。组件名字可以通过setComponent(), setClass(), 或者setClassName()来设置，通过getComponent()来获取具体的组件名字。\nIntent类型 显式Intent Intent可以分为显式Intent和隐式Intent。平时我们用的最多就是显式Intent比如说在一个应用中经常要切换Activity就是使用的显式Intent。\n// Explicit Intent by specifying its class name Intent i = new Intent(FirstActivity.this, SecondActivity.class); // Starts TargetActivity startActivity(i); 显式Intent也比较简单只要指定好具体的组件名称即可。在上一节也讲到了通过setComponent(), setClass(), 或者setClassName()方法进行指定组件名，当然也可像上述代码中直接在构造其中指定也是可以的。\n隐式Intent 这类Intent不会具体指定组件名，而是由安卓框架根据Intent设置的其他信息进行自动匹配。例如：\nIntent read1=new Intent(); read1.setAction(android.content.Intent.ACTION_VIEW); read1.setData(ContactsContract.Contacts.CONTENT_URI); startActivity(read1); 上述代码将通过对Intent设置的Action和Data信息启动一个联系人的应用进行显示动作。如果一个手机有多个联系人应用的话将弹出选择器列出所有的联系人应用供用户选择启动。 在安卓模拟器中默认打开了系统的联系人应用，如下图：\n如果想在目标组件中使用Intent中的信息，可以使用getExtras()方法获取extras数据（前提当然是在Intent设置了extras数据）。 // Get bundle object at appropriate place in your code Bundle extras = getIntent().getExtras(); // Extract data using passed keys String value1 = extras.getString(\u0026ldquo;Key1\u0026rdquo;); String value2 = extras.getString(\u0026ldquo;Key2\u0026rdquo;); 好了这部分是安卓开发最基本最简单知识点了，也没什么可以说的难点和重点。只要敲上几次代码就会熟悉。Intent中稍微复杂且很有用的知识点就是下面要讲到的过滤器。\nIntentFilter 匹配规则 对于隐式调用需要Intent能够匹配目标组件的IntentFilter中所设置的过滤信息，如果不匹配将无法启动目标Activity，IntentFilter中的过滤信息包括action、data、category。\n\u003c?xml version=\"1.0\" encoding=\"utf-8\"?\u003e \u0026hellip; 为了匹配过滤列表，需要同时匹配过滤列表中的action、category、data信息，否则匹配失败。一个Activity可以有多个intent-filter，若一个intent只要能匹配任何一组intent-filter即可成功启动对应的Activity。\naction的匹配规则\naction是一个字符串，系统预定义了一些，同时我们也可以在应用中定义自己的action，如上述代码一样。对于action匹配规则可以总结如下：action的匹配要求Intent中的action存在且必须和过滤规则中的其中一个action相同即可匹配成功 另外注意的是action是区分字母大小写的。\ncategory的匹配规则\ncategory是一个字符串，系统预定义了一些，同时我们也可以在应用中定义自己的category，和action不同，我们可以在Intent中不定义category，但是一旦定义了category就要求所有的category和intent-filter中的规则都要匹配才行。我们可以通过intent.addcategory(\u0026ldquo;com.icedcap.category.a\u0026rdquo;)或intent.addcategory(\u0026ldquo;com.icedcap.category.b\u0026rdquo;)亦或不设置category。不设置category也能匹配的原因是系统在调用startActivity或者startActivityResult的时候会默认为Intent添加android.intent.category.DEFAULT这个category，所以这个category可以匹配前面的过滤规则中的第三个category。同时，为了能够通过隐式调用启动该Activity，就必须在intent-filter中指定android.intent.category.DEFAULT这个category。\ndata的匹配规则 data的匹配和action类似，如果过滤规则中定义了data，那么Intent中必须也要定义可匹配的data。例如：\n前文中讲到data可以通过Uri或者MimeType来表达： 对于Uri结构可以如下归置\n://:/[||] 例如： content://com.icedcap.project:200/folder/subfolder/etc http://www.baidu.com 对于MimeType来说可以是image/jpeg、audio/mpeg4-generic等。详细的mime类型可以查看这里。\n对于下面的匹配规则来说\n很明显，data需要匹配一个图片格式的数据，虽然上述代码没有对Uri进行匹配规则的设置，但是默认情况下它会匹配Uri的schema为content或者file的data。 所以通过以下代码可以匹配该Intent intent.setDataAndType(Uri.parse(\u0026ldquo;file://ddd.png\u0026rdquo;), \u0026ldquo;image/png\u0026rdquo;); 以上就是我们Intent的匹配规则。\n最后，我们通过隐式Intent启动一个Activity的时候，最好做一个判断是否有可匹配的Activity可以启动，以免不存在隐式Activity而报错。其做法也非常简单，可以通过PackageManager的resolveActivity方法或者Intent的resolveActivity方法，如果它们找不到可匹配的Activity就会返回null。从而判断是否可被隐式启动。\nSee also https://baike.baidu.com/item/Intent/5468510 ","date":"2020-05-17","permalink":"http://localhost:1313/posts/20200517-android-intent/","section":"","summary":"","tags":[""],"title":"Android Intent"},{"categories":[],"contents":"android-env.sh\n#!/bin/sh # Useful link to keep track of latest API changes: # # https://developer.android.com/ndk/downloads/revision_history _android_arch=$1 if [ -z \u0026#34;${_android_arch}\u0026#34; ]; then _android_arch=armv7a-eabi fi # Minimum Android platform based on: # # http://gs.statcounter.com/os-version-market-share/android/mobile-tablet/worldwide if [ -z \u0026#34;${ANDROID_MINIMUM_PLATFORM}\u0026#34; ]; then export ANDROID_MINIMUM_PLATFORM=24 fi if [ -z \u0026#34;${ANDROID_HOME}\u0026#34; ]; then export ANDROID_HOME=/opt/android-sdk fi if [ -z \u0026#34;${ANDROID_NDK_HOME}\u0026#34; ]; then export ANDROID_NDK_HOME=/opt/android-ndk fi get_last() { ls $1 | sort -V | tail -n 1 } if [ -z \u0026#34;${ANDROID_BUILD_TOOLS_REVISION}\u0026#34; ]; then export ANDROID_BUILD_TOOLS_REVISION=$(get_last ${ANDROID_HOME}/build-tools) fi if [ -z \u0026#34;${ANDROID_API_VERSION}\u0026#34; ]; then export ANDROID_API_VERSION=android-$ANDROID_MINIMUM_PLATFORM fi if [ -z \u0026#34;${ANDROID_NDK_PLATFORM}\u0026#34; ]; then export ANDROID_NDK_PLATFORM=android-$ANDROID_MINIMUM_PLATFORM fi export ANDROID_SDK_PLATFORM=${ANDROID_HOME}/platforms/$ANDROID_API_VERSION export ANDROID_PLATFORM=${ANDROID_NDK_HOME}/platforms/$ANDROID_NDK_PLATFORM export ANDROID_TOOLCHAIN=${ANDROID_NDK_HOME}/toolchains/llvm/prebuilt/linux-x86_64 export ANDROID_SYSROOT=${ANDROID_TOOLCHAIN}/sysroot export ANDROID_CROSS_PREFIX=$ANDROID_TOOLCHAIN/bin export ANDROID_PKGCONFIG=android-${_android_arch}-pkg-config case \u0026#34;$_android_arch\u0026#34; in aarch64) export ANDROID_TOOLS_COMPILER_PREFIX=${ANDROID_CROSS_PREFIX}/aarch64-linux-android${ANDROID_MINIMUM_PLATFORM}- export ANDROID_TOOLS_PREFIX=${ANDROID_CROSS_PREFIX}/aarch64-linux-android- export ANDROID_ABI=arm64-v8a ;; armv7a-eabi) export ANDROID_TOOLS_COMPILER_PREFIX=${ANDROID_CROSS_PREFIX}/armv7a-linux-androideabi${ANDROID_MINIMUM_PLATFORM}- export ANDROID_TOOLS_PREFIX=${ANDROID_CROSS_PREFIX}/arm-linux-androideabi- export ANDROID_ABI=armeabi-v7a ;; x86) export ANDROID_TOOLS_COMPILER_PREFIX=${ANDROID_CROSS_PREFIX}/i686-linux-android${ANDROID_MINIMUM_PLATFORM}- export ANDROID_TOOLS_PREFIX=${ANDROID_CROSS_PREFIX}/i686-linux-android- export ANDROID_ABI=x86 ;; x86-64) export ANDROID_TOOLS_COMPILER_PREFIX=${ANDROID_CROSS_PREFIX}/x86_64-linux-android${ANDROID_MINIMUM_PLATFORM}- export ANDROID_TOOLS_PREFIX=${ANDROID_CROSS_PREFIX}/x86_64-linux-android- export ANDROID_ABI=x86_64 ;; esac export ANDROID_CC=${ANDROID_TOOLS_COMPILER_PREFIX}clang export ANDROID_CXX=${ANDROID_TOOLS_COMPILER_PREFIX}clang++ export ANDROID_AR=${ANDROID_TOOLS_PREFIX}ar export ANDROID_AS=${ANDROID_TOOLS_PREFIX}as export ANDROID_NM=${ANDROID_TOOLS_PREFIX}nm export ANDROID_RANLIB=${ANDROID_TOOLS_PREFIX}ranlib export ANDROID_STRIP=${ANDROID_TOOLS_PREFIX}strip export ANDROID_PREFIX=/opt/android-libs/${_android_arch} export ANDROID_PREFIX_USR=${ANDROID_PREFIX}/usr export ANDROID_PREFIX_BIN=${ANDROID_PREFIX}/bin export ANDROID_PREFIX_INCLUDE=${ANDROID_PREFIX}/include export ANDROID_PREFIX_LIB=${ANDROID_PREFIX}/lib export ANDROID_PREFIX_ETC=${ANDROID_PREFIX}/etc export ANDROID_PREFIX_SHARE=${ANDROID_PREFIX}/share export PKG_CONFIG_SYSROOT_DIR=${ANDROID_PREFIX} export PKG_CONFIG_LIBDIR=${ANDROID_PREFIX_LIB}/pkgconfig:${ANDROID_PREFIX_SHARE}/pkgconfig ndk_version() { grep \u0026#39;Pkg.Revision\u0026#39; ${ANDROID_NDK_HOME}/source.properties | awk \u0026#39;{print $3}\u0026#39; } check_ndk_version_ge_than() { version=$1 ndk_ver=$(ndk_version) if [ \u0026#34;${version}\u0026#34; = \u0026#34;${ndk_ver}\u0026#34; ]; then return 0 fi older_ver=$(printf \u0026#34;${version}\\n${ndk_ver}\u0026#34; | sort -V | head -n 1) if [ \u0026#34;${older_ver}\u0026#34; = \u0026#34;${ndk_ver}\u0026#34; ]; then echo \u0026#34;ERROR: NDK version \u0026gt;= $version required.\u0026#34; return -1 fi return 0 } check_android_platform() { if [ ! -e \u0026#34;${ANDROID_SDK_PLATFORM}/source.properties\u0026#34; ]; then echo \u0026#34;ERROR: Please, install android-platform-${ANDROID_MINIMUM_PLATFORM}.\u0026#34; return -1 fi return 0 } ","date":"2020-05-16","permalink":"http://localhost:1313/files/20200516-android-env/","section":"","summary":"","tags":["","",""],"title":"android env"},{"categories":[],"contents":" # 安装黑暗主题 ~ ❯ sudo pacman -S gnome-themes-extra ~ ❯ cat .gtkrc gtk-icon-theme-name = \u0026#34;Adwaita-dark\u0026#34; gtk-theme-name = \u0026#34;Adwaita-dark\u0026#34; gtk-font-name = \u0026#34;Cantarell 11\u0026#34; ~ ❯ cat .config/gtk-3.0/settings.ini [Settings] gtk-icon-theme-name = Adwaita-dark gtk-theme-name = Adwaita-dark gtk-application-prefer-dark-theme = true gtk-font-name = Cantarell 11 See also https://wiki.archlinux.org/index.php/GTK\n","date":"2020-05-16","permalink":"http://localhost:1313/posts/20200516-enable-dark-mode-in-gtk2/","section":"","summary":"","tags":[""],"title":"GTK开启黑暗模式"},{"categories":[],"contents":"I want to remove the api 16 of jelly bean but there is not remove button how can I do that. image file is very big size file so I need don\u0026rsquo;t many system image file\nGo to Tools / Android / SDK Manager\nTick Show package details in the bottom right.\nUntick the version(s) of Android you want to uninstall and click Ok.\nAndroid Studio 3.6.3 In version 3.6.3 File -\u0026gt; Settings -\u0026gt; Appearance \u0026amp; Behavior -\u0026gt; System Settings -\u0026gt; Android SDK\n","date":"2020-05-15","permalink":"http://localhost:1313/posts/20200515-how-do-i-remove-an-image-system-for-avd-file-in-android-studio/","section":"","summary":"","tags":[""],"title":"How Do I Remove an Image System for Avd File in Android Studio"},{"categories":[],"contents":"今天用一个游戏资源批量解密程序出现错误提示：\nException in thread \u0026#34;main\u0026#34; java.lang.OutOfMemoryError: Java heap space: failed reallocation of scalar replaced objects 工具太多，直接设置一下环境变量就完事儿\n/mnt/win10/Users/zhili/Downloads 15s ❯ export _JAVA_OPTIONS=\u0026#34;-Xms512m -Xmx10G\u0026#34; ","date":"2020-05-14","permalink":"http://localhost:1313/posts/20200514-java-heap-size-error/","section":"","summary":"","tags":[""],"title":"Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space"},{"categories":[],"contents":"UTC in Windows To dual boot with Windows it is recommended to configure Windows to use UTC, rather than Linux to use localtime. (Windows by default uses localtime [1].)\nIt can be done by a simple registry fix: Open regedit and add a DWORD value for 32-bit Windows, or QWORD for 64-bit one, with hexadecimal value 1 to the registry:\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation\\RealTimeIsUniversal You can do this from an Administrator Command Prompt running:\nreg add \u0026#34;HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\TimeZoneInformation\u0026#34; /v RealTimeIsUniversal /d 1 /t REG_QWORD /f (Replace QWORD with DWORD for 32-bit Windows.)\nAlternatively, create a *.reg file (on the desktop) with the following content and double-click it to import it into registry:\nWindows Registry Editor Version 5.00\n[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation] \u0026#34;RealTimeIsUniversal\u0026#34;=qword:00000001 (Replace qword with dword for 32-bit Windows.)\nShould Windows ask to update the clock due to DST changes, let it. It will leave the clock in UTC as expected, only correcting the displayed time.\nThe #Hardware clock and #System clock time may need to be updated after setting this value.\nIf you are having issues with the offset of the time, try reinstalling tzdata and then setting your time zone again:\n$ timedatectl set-timezone America/Los_Angeles # Enable the NTP service on your Linux system with the command $ timedatectl set-ntp true See also https://wiki.archlinux.org/index.php/systemd-timesyncd\nhttps://wiki.archlinux.org/index.php/System_time\n","date":"2020-05-12","permalink":"http://localhost:1313/posts/20200512b-how-to-fix-windows-and-linux-showing-different-times-when-dual-booting/","section":"","summary":"","tags":["","",""],"title":"解决Windows与Ubuntu双系统时间同步问题"},{"categories":[],"contents":"像 =ls=, =df=, =du= 这类命令都带有一个选项可以将数字直接转换成人类容易阅读的形式来展现。 比如,直接执行 =df= 时，容量显示的是多少个块，而当用 =df -h= 时，容量会根据块的数量转换成 G/M/K 的形式。\n[lujun9972@T520 ~]$ df 文件系统 1K-块 已用 可用 已用% 挂载点 dev 1900280 0 1900280 0% /dev run 1906932 868 1906064 1% /run /dev/sda2 41022688 23631300 15277852 61% / tmpfs 1906932 26204 1880728 2% /dev/shm tmpfs 1906932 0 1906932 0% /sys/fs/cgroup tmpfs 1906932 5156 1901776 1% /tmp /dev/sda3 73005440 61682676 7571272 90% /home tmpfs 100 0 100 0% /var/lib/lxd/shmounts tmpfs 100 0 100 0% /var/lib/lxd/devlxd tmpfs 381384 8 381376 1% /run/user/1000 [lujun9972@T520 ~]$ df -h 文件系统 容量 已用 可用 已用% 挂载点 dev 1.9G 0 1.9G 0% /dev run 1.9G 868K 1.9G 1% /run /dev/sda2 40G 23G 15G 61% / tmpfs 1.9G 26M 1.8G 2% /dev/shm tmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup tmpfs 1.9G 5.1M 1.9G 1% /tmp /dev/sda3 70G 59G 7.3G 90% /home tmpfs 100K 0 100K 0% /var/lib/lxd/shmounts tmpfs 100K 0 100K 0% /var/lib/lxd/devlxd tmpfs 373M 8.0K 373M 1% /run/user/1000 不过对于那些没有这类功能的命令该怎么办呢？有单独的一个命令来实现数字和易读形式之间的转换吗？ 答案是，还真有，这就是 =numfmt=. 而且 =numfmt= 是 coreutils 的一部分，无需另行安装，真是良心。\n1000 进制还是 1024 进制？这是个问题 使用 =numfmt= 支持两种转换标准，一种是 1K=1000,1M=1000K\u0026hellip;的: numfmt \u0026ndash;to=si 数字 :: 将数字转换成易读格式\n#+BEGIN_SRC shell :results org numfmt \u0026ndash;to=si 100000\n```sh 100K numfmt \u0026ndash;from=si 易读格式 :: 将易读格式转换成数字\n#+BEGIN_SRC shell :results org numfmt \u0026ndash;from=si 100K\n```sh 100000 还有一种是 1K=1024,1M=1024K\u0026hellip;的:\nnumfmt \u0026ndash;to=iec 数字 :: 将数字转换成易读格式\n#+BEGIN_SRC shell :results org numfmt \u0026ndash;to=iec 100000\n```sh 98K numfmt \u0026ndash;from=iec 易读格式 :: 将易读格式转换成数字\n#+BEGIN_SRC shell :results org numfmt \u0026ndash;from=iec 100K\n```sh 102400 事实上，还有一种格式是 1Ki=1024,1Mi=1024Ki\u0026hellip;的(即在单位后面有个 i)：\nnumfmt \u0026ndash;to=iec-i 数字 :: 将数字转换成易读格式\n#+BEGIN_SRC shell :results org numfmt \u0026ndash;to=iec-i 100000\n```sh 98Ki numfmt \u0026ndash;from=iec-i 易读格式 :: 将易读格式转换成数字\n#+BEGIN_SRC shell :results org numfmt \u0026ndash;from=iec-i 100Ki\n#+RESULTS: ```sh 102400 当将易读格式转换会数字时，可以将格式设置为 =auto=, 这样 =numfmt= 会自动判断应该是按 1000 来转换还是按 1024 来转换，其选择的规则为:\n若格式的单位后面不带 =i= 则使用 1000 进制来转换\n#+BEGIN_SRC shell :results org numfmt \u0026ndash;from=auto 100K\n```sh 100000 若格式的单位后面不带 =i= 则使用 1024 进制来转换\n#+BEGIN_SRC shell :results org numfmt \u0026ndash;from=auto 100Ki\n```sh 102400 一次进行多个转换 =numfmt= 能够一次性进行多个转换，只需要在后面罗列数字或者易读格式就行了。 #+BEGIN_SRC shell :results org numfmt \u0026ndash;to=iec 100000 20000 40000 ```sh 98K 20K 40K #+BEGIN_SRC shell :results org numfmt \u0026ndash;from=iec 98K 20K 40K\n```sh 100352 20480 40960 从中你也可以看出，转换的结果其实并不会特别的精确\n指定数字的单位 使用 =\u0026ndash;from-unit= 可以指定输入数字的单位,比如： #+BEGIN_SRC shell :results org numfmt \u0026ndash;to=si \u0026ndash;from-unit K 1000 ```sh 1.0M 你会发现，输出是 =1M= 而不是 =1K=\n同理，使用 =\u0026ndash;to-unit= 可以指定输出数字的单位: #+BEGIN_SRC shell :results org numfmt \u0026ndash;from=si \u0026ndash;to-unit K 1M\n```sh 1000 可以看到，输出是是 =1000= 而不是 =1000000=\n指定输出的格式 使用 =\u0026ndash;format= 可以指定输出的格式，其格式语法类似于 C 语言中 =printf= 的格式说明，但仅限于格式化一个浮点数。比如：\n输出右对齐，占 10 位字符\n#+BEGIN_SRC shell [lujun9972@T520 ~]$ numfmt \u0026ndash;to=si \u0026ndash;format \u0026ldquo;%10f\u0026rdquo; 1000 1.0K\n输出左对齐，占 10 位字符\n#+BEGIN_EXAMPLE [lujun9972@T520 ~]$ numfmt \u0026ndash;to=si \u0026ndash;format \u0026ldquo;%-10f|\u0026rdquo; 1000 1.0K | #+END_EXAMPLE\n为了清晰，我在字符串最后加了一个 =|=\n输出右对齐，占 10 位字符,不够的位用 0 填充\n#+BEGIN_EXAMPLE [lujun9972@T520 ~]$ numfmt \u0026ndash;to=si \u0026ndash;format \u0026ldquo;%010f\u0026rdquo; 1000 00000001.0K #+END_EXAMPLE\n与其他命令整合 当 =numfmt= 没有指定数字或易读格式来转换时，它会从 stdin 中读取要转换的内容 #+BEGIN_SRC shell :results org echo 1000 |numfmt \u0026ndash;to=si f\n```sh 1.0K 然而，对于像 =df= 这样的命令，除了数字外，还有其他内容怎么办呢？\n这个时候，我们可以使用 =\u0026ndash;header= 来跳过命令输出前面几行的标题,使用 =field= 来指定转换某几列的内容。\n比如，我们可以用下列命令来让 =numfmt= 只转换 =df= 命令从第 3 行开始的 2 到 4 列数字，保持其他内容不变\ndf -B1 | numfmt --header=2 --field 2-4 --to=iec 文件系统 1B-块 已用 可用 已用% 挂载点 dev 1945886720 0 1945886720 0% /dev run 1.9G 868K 1.9G 1% /run /dev/sda2 40G 23G 15G 61% / tmpfs 1.9G 26M 1.8G 2% /dev/shm tmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup tmpfs 1.9G 5.1M 1.9G 1% /tmp /dev/sda3 70G 59G 7.3G 90% /home tmpfs 100K 0 100K 0% /var/lib/lxd/shmounts tmpfs 100K 0 100K 0% /var/lib/lxd/devlxd tmpfs 373M 8.0K 373M 1% /run/user/1000 ","date":"2020-05-12","permalink":"http://localhost:1313/tips/20200507a-numfmt/","section":"","summary":"","tags":["",""],"title":"numfmt:让数字变得更容易理解"},{"categories":[],"contents":"KVM 报错以及处理 删除kvm虚拟机出现cannot undefine domain with nvram 删除Kvm虚拟时，需要先destroy，然后在undefine某台虚拟机，但是在删除其中一台虚拟机时出现以下错误：\nme@ubuntu:~/virtual_machine$ virsh undefine ubuntu_2 error: Failed to undefine domain ubuntu_2 error: Requested operation is not valid: cannot undefine domain with nvram 这个时候可以使用**\u0026ndash;nvram**选项删除， 搜遍全网，并没有找到解决办法，这个最好使。\nme@ubuntu:~/virtual_machine$ virsh undefine ubuntu_2 --nvram Domain ubuntu_2 has been undefined KVM挂载硬盘容量显示不正确 #创建了一个disk文件， 用于给7号VM添加100G的新硬盘 sudo qemu-img create -f qcow2 ubuntu_vm7_disk_100G 100G #挂载这个文件到sdb，sdb需要是虚机上未使用的名字 virsh attach-disk ubuntu_7 /var/lib/libvirt/images/ubuntu_vm7_disk_100G vdb --cache none #提示挂载成功，但是进入虚机查看硬盘设备，看到设备，但是容量明显不对，194k只是文件的大小，虚机里面应该看到100G才对 me@ubuntu7:~$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sr0 11:0 1 1024M 0 rom vda 252:0 0 50G 0 disk ├─vda1 252:1 0 512M 0 part /boot/efi └─vda2 252:2 0 49.5G 0 part / vdb 252:16 0 194K 0 disk #原因是当创建qcow2格式的硬盘时，挂载需要使用--subdriver 制定驱动类型 #先卸载硬盘 virsh detach-disk ubuntu_7 /var/lib/libvirt/images/ubuntu_vm7_disk_100G #再重新挂载 virsh attach-disk ubuntu_7 /var/lib/libvirt/images/ubuntu_vm7_disk_100G vdb --subdriver=qcow2 #进入虚机查看 me@ubuntu7:~$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sr0 11:0 1 1024M 0 rom vda 252:0 0 50G 0 disk ├─vda1 252:1 0 512M 0 part /boot/efi └─vda2 252:2 0 49.5G 0 part / vdb 252:16 0 194K 0 disk ","date":"2020-05-12","permalink":"http://localhost:1313/posts/20200512-virsh-cannot-undefine-domain-with-nvram/","section":"","summary":"","tags":["",""],"title":"删除kvm虚拟机出现cannot undefine domain with nvram"},{"categories":[],"contents":"From what I just found out, it may be unsafe. I was getting this same error\n*************************************************************** Found invalid GPT and valid MBR; converting MBR to GPT format in memory. THIS OPERATION IS POTENTIALLY DESTRUCTIVE! Exit by typing \u0026lsquo;q\u0026rsquo; if you don\u0026rsquo;t want to convert your MBR partitions to GPT format!\nWarning! Secondary partition table overlaps the last partition by 33 blocks! You will need to delete this partition or resize it in another utility.\nAccording to THIS link, zman0900 says:\nGPT writes its partition table to both ends of the disk, unlike MBR which only uses the beginning. So you will need to shrink your last partition by at least 33 blocks (probably 16,896 bytes, assuming 512 byte blocks). If you have or can install gparted, that makes it very easy to do. If boot is the last partition on the drive, then that is the one to shrink.\nI was getting this error because my last partition did not leave any space after it. All I had to do was shrink the partition from the rightmost side a little bit (3Mb but could be less), and the result was the following:\nWhen I ran gdisk afterwards no warning was thrown.\n","date":"2020-05-10","permalink":"http://localhost:1313/posts/20200510b-warning-secondary-partition-overlaps-the-last-partition-by-x-blocks-in-gdisk/","section":"","summary":"","tags":[""],"title":"Warning Secondary Partition Overlaps the Last Partition by X Blocks in Gdisk"},{"categories":[],"contents":"今天虚拟机关机发现出现了Failed unmounting /run/user/1000的红字提示，加上登录注销卡顿等异常，一看就不太正常，cat /etc/fstab 后发现是安装的时候挂载efi分区写错格式导致的，修正一下fstab的挂载信息重启就正常了～\n","date":"2020-05-10","permalink":"http://localhost:1313/posts/20200510a-failed-unmounting-xxx/","section":"","summary":"","tags":[""],"title":"Failed unmounting /run/user/1000 whenever i shutdown or reboot"},{"categories":[],"contents":"很久不用kodexplorer，一堆BUG不修在搞to B商务弄出个kodbox，很久没用PHP出问题我也懒得研究，直接暴力解决问题就完事，以后再找替代品\n--- web.function.php 2020-05-10 13:20:20.472730147 +0800 +++ web.function.new.php 2020-05-10 13:20:09.862832878 +0800 @@ -59,6 +59,7 @@ } function http_type(){ + return \u0026#39;https\u0026#39;; if( (isset($_SERVER[\u0026#39;HTTPS\u0026#39;]) \u0026amp;\u0026amp; $_SERVER[\u0026#39;HTTPS\u0026#39;] !== \u0026#39;off\u0026#39;) || (isset($_SERVER[\u0026#39;HTTP_X_FORWARDED_PROTO\u0026#39;]) \u0026amp;\u0026amp; $_SERVER[\u0026#39;HTTP_X_FORWARDED_PROTO\u0026#39;] == \u0026#39;https\u0026#39;) || $_SERVER[\u0026#39;SERVER_PORT\u0026#39;] === 443 用了一分钟后我发现还是kodexplorer好使，最后一个版本好像是4.40，且用且珍惜\n","date":"2020-05-10","permalink":"http://localhost:1313/posts/20200510-kodbox-always-https/","section":"","summary":"","tags":[""],"title":"Kodbox Always Https"},{"categories":[],"contents":"NVRAM storage in libvirt Libvirt stores pflash/nvram files for privliged users in /var/lib/libvirt/qemu/nvram/ this is a copy of the template var file that is read only. OVMF uses these files to store information such as boot information. The template inforamtion was uesed to be configured in /etc/libvirt/qemu.conf but was moved to json files. [https://bugs.archlinux.org/task/64175]\nLocation of master nvram file This configuration option is obsolete. Libvirt will follow the QEMU firmware metadata specification to automatically locate firmware images. See docs/interop/firmware.json in the QEMU source tree. These metadata files are distributed alongside any firmware images intended for use with QEMU.\n[https://github.com/libvirt/libvirt/blob/fda14dd7821d3e20b1416b90525242b7d4306fe9/src/qemu/qemu_conf.c#L153]\nand for unprivliged users in [https://github.com/libvirt/libvirt/blob/fda14dd7821d3e20b1416b90525242b7d4306fe9/src/qemu/qemu_conf.c#L182] [https://github.com/libvirt/libvirt/blob/2f7d81497b90cd901c159b9e548004b164bec983/src/util/virutil.c#L760]\nif (!(cfg-\u0026gt;configBaseDir = virGetUserConfigDirectory())) virGetXDGDirectory(\u0026ldquo;XDG_CONFIG_HOME\u0026rdquo;, \u0026ldquo;.config\u0026rdquo;); cfg-\u0026gt;nvramDir = g_strdup_printf(\u0026quot;%s/qemu/nvram\u0026quot;, cfg-\u0026gt;configBaseDir);\nFor privliged users the best way to change the storage location seems to be to symlink /var/lib/libvirt/qemu/nvram/ before any vm is installed. This should theoreticly no break the package as the folder would be create programmaticly.\nqemu: Build nvram directory at driver startup [https://github.com/libvirt/libvirt/commit/19425d110b0ca2ea3588dbf880ce48d81edea89c]\nSome usefull links\n[https://lists.gnu.org/archive/html/qemu-devel/2016-01/msg02034.html]\nAs of 2019/12/10 on an arch linux up to date installation this is not enough: ERROR Did not find any UEFI binary path for arch \u0026lsquo;x86_64\u0026rsquo; create /usr/share/qemu/firmware/60-ovmf-x86_64.json with\n[lukashv@hv ~]$ cat 60-ovmf-x86_64.json { \u0026#34;description\u0026#34;: \u0026#34;UEFI OVMF firmware for x86_64\u0026#34;, \u0026#34;interface-types\u0026#34;: [ \u0026#34;uefi\u0026#34; ], \u0026#34;mapping\u0026#34;: { \u0026#34;device\u0026#34;: \u0026#34;flash\u0026#34;, \u0026#34;executable\u0026#34;: { \u0026#34;filename\u0026#34;: \u0026#34;/usr/share/ovmf/x64/OVMF_CODE.fd\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;raw\u0026#34; }, \u0026#34;nvram-template\u0026#34;: { \u0026#34;filename\u0026#34;: \u0026#34;/usr/share/ovmf/x64/OVMF_VARS.fd\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;raw\u0026#34; } }, \u0026#34;targets\u0026#34;: [ { \u0026#34;architecture\u0026#34;: \u0026#34;x86_64\u0026#34;, \u0026#34;machines\u0026#34;: [ \u0026#34;pc-i440fx-*\u0026#34;, \u0026#34;pc-q35-*\u0026#34; ] } ], \u0026#34;features\u0026#34;: [ \u0026#34;acpi-s3\u0026#34;, \u0026#34;amd-sev\u0026#34;, \u0026#34;verbose-dynamic\u0026#34; ], \u0026#34;tags\u0026#34;: [ ] } NOTE: if ANY firmware metadata files are detected, this setting will be COMPLETELY IGNORED.\nBut not setting also setting nvram in qemu.conf results in (root and user) session: ERROR operation failed: unable to find any master var store for loader: /usr/share/ovmf/x64/OVMF_CODE.fd\nto fix add:\n/etc/libvirt/qemu.conf ~/.config/libvirt/qemu.conf nvram = [ \u0026#34;/usr/share/ovmf/x64/OVMF_CODE.fd:/usr/share/ovmf/x64/OVMF_VARS.fd\u0026#34; ] sudo pacman -S ovmf sudo systemctl restart libvirtd Summary needs valid json in /usr/share/qemu/firmware/60-ovmf-x86_64.json_aswell as edited_qemu.conf\n","date":"2020-05-09","permalink":"http://localhost:1313/posts/20200509-nvramdir/","section":"","summary":"","tags":["",""],"title":"NVRAM storage in libvirt"},{"categories":[],"contents":"exclude file Specifies which filenames or wildcarded names must be excluded from the operation.\nMultiple exclude switches are supported.\nSyntax\n-x[\u0026lt;recurse_type\u0026gt;]\u0026lt;file_ref\u0026gt; \u0026lt;recurse_type\u0026gt; ::= r[- | 0] \u0026lt;file_ref\u0026gt; ::= @{listfile} | !{wildcard} See -i (Include) switch description for information about option parameters.\nExamples\n7z a -tzip archive.zip *.txt -x!temp.* adds to the archive.zip all *.txt files, except temp.* files.\n7z a archive.7z Folder1\\ -xr!*.png adds to the archive.7z all files from Folder1 and its subfolders, except *.png files.\nCommands that can be used with this switch a (Add), d (Delete), h (Hash), e (Extract), l (List), t (Test), rn (Rename), u (Update), x (Extract with full paths)\nSee also Switches: -r (Recurse), -i (Include)\n分卷压缩 # 创建1T测试文件 fallocate -l 1t test.img 7z a qyy-src.7z /home/z/qyy/android/src/test.img -v10G 7z a qyy-src.7z /home/z/qyy/android/src -v4294967295 压缩成zip 7z a -tZip test.zip test.img ","date":"2020-05-07","permalink":"http://localhost:1313/tips/20200507-7z-command/","section":"","summary":"","tags":["","","",""],"title":"7z command"},{"categories":[],"contents":"I can start X only by root. If I am using startx using ordinary user I get the error:\nxf86OpenConsole: Cannot open virtual console 1 (Permission denied)\n$ groups lp wheel games video audio optical storage scanner power users $ ls -l /dev/tty1 crw-------- 1 root tty 4, 1 Jan 17 10:21 /dev/tty1 This might help someone. So I am going to post it. If your logged in as a different user and su to the user starting X. You will get an permission denied as tty1 is occupied by the original user. In short reboot or completely log out the current user then issue \u0026ldquo;startx\u0026rdquo;.\n","date":"2020-05-06","permalink":"http://localhost:1313/posts/20200506-xf86openconsole-cannot-open-virtual-console/","section":"","summary":"","tags":[""],"title":"Xf86OpenConsole Cannot Open Virtual Console"},{"categories":[],"contents":"前言 系统搬来linux有两年了，今天突然发现还是需要win10用ida的，虚拟机很不方便\n虚拟机解决方法 google一下在知乎想起原因:\n原因似乎在于windows会执着地把系统分区（大概类似于/boot）放到磁盘0（类似于/dev/sda？）上面。而这个时候磁盘0是U盘……于是傻X了……windows就是傻X解决方法，拔U盘/硬盘，从而使想装系统的盘成为磁盘0……或者直接把想装系统的盘做成安装盘，这样它也是磁盘0了\u0026gt;_\u0026laquo;https://link.zhihu.com/?target=http%3A//jingyan.baidu.com/article/2c8c281df6f2d60009252a7c.html\u0026gt;\n作者：杨微粒 链接：https://www.zhihu.com/question/21117479/answer/86745809 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n所以解决方案就是我们来帮助系统找到它需要安装的分区，我的虚拟机之前忘记干啥也是双系统出这问题，附加win10磁盘就完事\n硬解决 将多余的硬盘拆下来，只留安装的硬盘，（这里不区分机械和固态），就是只留一个硬盘安装系统即可！\n（动手能力弱的朋友请看下面！）\n软解决 在linux下直接复制安装镜像里的 boot sources bootmgr bootmgr.efi\nuefi还需要复制 EFI 文件夹到efi文件夹到efi分区，\n重启安装即可\n安装过程提示help setup cannot continue due to a corrupted # 直接擦写一下这块硬盘 dd if=/dev/zero of=/dev/vdb # fdisk 重新分区 fdisk /dev/vdb # 格式化 mkfs.ntfs /dev/vdb1 ","date":"2020-05-05","permalink":"http://localhost:1313/posts/20200505-we-were-unable-to-create-a-new-partition-now-can-not-find-the-partition/","section":"","summary":"","tags":[""],"title":"安装Win10提示我们无法创建新的分区，也找不到现在的分区"},{"categories":[],"contents":" [Desktop Entry] Type=Application Version=1.0 Encoding=UTF-8 Exec=cp %F /mnt/data/src/yyy/GameServer Name=Copy To Data Store ffmpeg -video_size 1920x1080 -framerate 30 -f x11grab -i :0.0+0,0 -f alsa -i hw:1,1,0 -f alsa -i hw:1,1,1 -filter_complex amerge output.mkv ","date":"2020-04-25","permalink":"http://localhost:1313/posts/20200425-thunar-sftp.desktop/","section":"","summary":"","tags":["",""],"title":"Thunar sftp.desktop"},{"categories":[],"contents":"问题 ~ ❯ vainfo libva error: /usr/lib/dri/iHD_drv_video.so init failed vaInitialize failed with error code 1 (operation failed),exit 解决方法 Everything works as it is supposed to by just adding:\nLIBVA_DRIVER_NAME=i965 # or if using the intel-media-driver which I prefer for newer hardware then it is: LIBVA_DRIVER_NAME=iHD also for intel-media-driver you may want to read the readme and enable guc and huc. I believe it just enables huc though but it uses guc to load huc if I have read correct info. Right now though my i7 9750H with intel UHD 630 seems to be less buggy with libva-intel-driver without the xf86-video-intel and just use modesetting as default plus libva-intel and I have no freezes in kernel 5.5-1. Kernel 5.4 was terrible though. I am marking thread as solved.\n参考 https://wiki.archlinux.org/index.php/Hardware_video_acceleration\n","date":"2020-04-23","permalink":"http://localhost:1313/posts/20200423-problems-with-hardware-acceleration-environment-variables/","section":"","summary":"","tags":[""],"title":"Problems With Hardware Acceleration Environment Variables"},{"categories":[],"contents":" the VS Code debugger console doesn\u0026rsquo;t currently support piping any input through to stdin.\nFYI, you can tell the Code debugger to use an external console in the launch config:\n\u0026quot;externalConsole\u0026quot;: true It has a possible workaround, using remote debug + vscode task, but that is not trivial.\nIt has a possible workaround, using remote debug + vscode task, but that is not trivial.\nlaunch.json\n{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;go\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;attach\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;remote\u0026#34;, \u0026#34;remotePath\u0026#34;: \u0026#34;${workspaceFolder}\u0026#34;, \u0026#34;port\u0026#34;: 4247, \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, } ] } tasks.json\n{ // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format \u0026#34;version\u0026#34;: \u0026#34;2.0.0\u0026#34;, \u0026#34;tasks\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;startgggbdebug\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;cd ${workspaceFolder} \u0026amp;\u0026amp; dlv debug --headless --listen :4247 --api-version=2\u0026#34;, \u0026#34;group\u0026#34;: { \u0026#34;kind\u0026#34;: \u0026#34;build\u0026#34;, \u0026#34;isDefault\u0026#34;: true }, \u0026#34;problemMatcher\u0026#34;: [ \u0026#34;$go\u0026#34; ] }, { \u0026#34;label\u0026#34;: \u0026#34;killgggbdebug\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;command\u0026#34;: \u0026#34;pkill -f --exact \\\u0026#34;dlv debug --headless --listen :4247 --api-version=2\\\u0026#34;\u0026#34;, \u0026#34;presentation\u0026#34;: { \u0026#34;echo\u0026#34;: true, \u0026#34;reveal\u0026#34;: \u0026#34;never\u0026#34;, \u0026#34;focus\u0026#34;: false, \u0026#34;panel\u0026#34;: \u0026#34;shared\u0026#34;, \u0026#34;showReuseMessage\u0026#34;: false, \u0026#34;clear\u0026#34;: false }, \u0026#34;problemMatcher\u0026#34;: [ \u0026#34;$go\u0026#34; ] } ] } ","date":"2020-04-18","permalink":"http://localhost:1313/posts/20200418-how-can-i-simulate-interactive-console-in-vscode-debugger/","section":"","summary":"","tags":["",""],"title":"How can I simulate interactive console in VSCode debugger"},{"categories":[],"contents":"今天早上有在GITHUB下载一个脚本到VPS中的时候有出现\u0026quot;ERROR: The certificate of `github.com’ is not trusted.\u0026ldquo;的错误提示。应该意思是这个证书可能不被信任，反正就这个提示，正式存在的，我换了其他有HTTPS网址也无法wget下载，应该是这个问题。\n解决办法 wget --no-check-certificate github.com # 或者我们可以： apt-get install ca-certificates -y #Debian/Ubuntu yum install ca-certificates -y #CentOS 安装完毕之后应该是可以不用 no-check-certificate 参数。\n","date":"2020-04-15","permalink":"http://localhost:1313/posts/20200415-err-wget-not-trusted/","section":"","summary":"","tags":[""],"title":"解决'ERROR: The certificate of `github.com’ is not trusted.'问题"},{"categories":[],"contents":"ImageMagick Just use this:\nconvert \u0026#34;*.{png,jpeg}\u0026#34; -quality 100 outfile.pdf In general case you can combine more files into one pdf file with including them inside {} and separate them with a single comma.\nadding -quality VALUE to keep quality after conversion(thanks to @iamcreasy)\nconvert \u0026#34;*.{ext1,ext2,ext3,...}\u0026#34; -quality 100 outfile.pdf GhostScript gs\n#!/bin/sh str=\u0026#34;\u0026#34;; count=0; imgs=`ls *.gif | sort -n | tr \u0026#34; \u0026#34; \u0026#34;|\u0026#34;`; for i in $imgs; do i=${i//\u0026#39;|\u0026#39;/\u0026#39; \u0026#39;} count=$(($count + 1)); str=\u0026#34;$str $count.pdf\u0026#34;; convert -background white -alpha remove -alpha off \u0026#34;$i\u0026#34; \u0026#34;$i\u0026#34; mutool draw -F pdf -o $count.pdf \u0026#34;$i\u0026#34;; done gs -q -dNOPAUSE -sDEVICE=pdfwrite -sOUTPUTFILE=final.pdf -dBATCH $str 参考 https://www.imagemagick.org/Usage/masking/#alpha_remove ","date":"2020-04-13","permalink":"http://localhost:1313/posts/20200413-linux-convert-images-to-pdf/","section":"","summary":"","tags":[""],"title":"Linux 图片转pdf"},{"categories":[],"contents":"Without the \u0026ndash;conversion-timeout part, I run into this error: feh: No Imlib2 loader for that file format\nAs suggested in the Arch Linux Wiki, I open SVG images like this:\nfeh --conversion-timeout 1 file.svg This will create a \u0026ldquo;feh\u0026rdquo; theme, which will be loaded by default and which will automatically apply the conversion-timeout option.\necho \u0026#34;feh --conversion-timeout 5\u0026#34; \u0026gt; ~/.config/feh/themes ","date":"2020-04-01","permalink":"http://localhost:1313/posts/20200401-feh-open-svg/","section":"","summary":"","tags":[""],"title":"Feh Open SVG"},{"categories":[],"contents":"Some code runs off the network In some multi-user environments part of the boot-up process can come from the network. For this case systemd defaults to waiting for the network to come on-line before certain steps are taken.\nIt appears that this service simply waits, doing absolutely nothing, until the network is connected, and when this happens, it changes its state so that other services that depend on the network can be launched to start doing their thing.\nSo, it appears that this service is absolutely benign, it does not waste any time during boot, and it actually constitutes an optimization, so you are only going to make things worse if you disable it.\n(Services that need the network will start before the network is up, at a time when many other services are also starting up and contention is high, and these services will be unable to do anything useful, so they will just keep retrying to connect to the network, until the network finally comes up.)\nMajority of Desktop Users Unlike some multi-user environments most Ubuntu desktop users have the Operating System and drivers on their hard disks, SSDs or Live Boot USBs.\nThere is a glitch where some users wait an extremely long time for network to come up during boot. In this case the recommendations is to set the maximum wait time to 30 seconds. A better way is to simply disable the service at boot time.\nFor many users 10 to 15 seconds can be sliced off the parallel boot time by using:\nsudo systemctl disable NetworkManager-wait-online.service # or sudo systemctl disable systemd-networkd-wait-online.service After you sign on you will likely get a message bubble stating you\u0026rsquo;ve now been connected to the network (WiFi or Ethernet access to Internet).\n","date":"2020-04-01","permalink":"http://localhost:1313/posts/20200401-what-does-networkmanager-wait-online-service-do/","section":"","summary":"","tags":[""],"title":"What Does Networkmanager Wait Online Service Do"},{"categories":[],"contents":"这两个东西是什么，我相信至今还有很多人搞不清，只会死记硬背的写一个word-wrap:break-word;word-break:break-all;这样的东西来强制断句，又或者是因为这两个东西实在是太拗口了，长得又差不多，导致连背都很难背下来。\n那它们到底是什么呢？我在mozilla的官网上找到如下的解释：\nword-wrap\nword-wrap\nword-break\nword-break\n我们看到两个解释中都出现了 break lines within words 这样的词汇，说明它们都跟单词内断句又关。然后我们试着翻译一下上面的两段英文：\nword-wrap:\ncss的 word-wrap 属性用来标明是否允许浏览器在单词内进行断句，这是为了防止当一个字符串太长而找不到它的自然断句点时产生溢出现象。\nword-break:\ncss的 word-break 属性用来标明怎么样进行单词内的断句。\n貌似从上面两个读着都蛋疼的翻译中找到了一些区别：word-wrap 强调的是是否允许单词内断句，而word-break强调的则是怎么样来进行单词内的断句。\n说到这里，好像依然不是很明朗，好吧，表达能力差的孩纸真是伤不起啊，只能用些实例来补救了。\n首先，何谓单词内断句？当然这里指的都是西文单词。\n01\n这是没有单词内断句的情况，我们看到那个单词是在是太长了，所以它溢出了包裹它的容器。\n01\n这是进行了单词内断句的情况，就是一个单词被断作了两行。\n先要明确一点，不加word-wrap或word-break的时候，就是浏览器默认的时候，如果有一个单词很长，导致一行中剩下的空间已经放不下它时，则浏览器会把这个单词挪到下一行去：\n01\nword..d 这个我们创造出来的单词本来应该紧接在 long 后面的，但是long后剩下的空间已经不够了，而单词默认是不能断开的，所以浏览器就只好把它屈尊下移了。\n这个长单词还不算变态的，因为至少它没有长到超过包裹它的元素的长度，但是如果超过了呢？\n01\n如果超过了就像前面我们提到过的，它会溢出它的父容器外，因为这时它是不允许被截断的，那就只能冲出去咯。\n这个时候word-wrap就能派上用场了。我们给这段文字加上word-wrap:break-word看看会怎么样\n01\n01\n哈哈，你给我滚回去吧，变态的长单词，即使你断了也无所谓。\n这样，为了防止长单词溢出，就在它的内部断句了。这就是 word-wrap:break-word 的功能。\n在看看word-wrap的浏览器支持情况：\n01\n很好，几乎所有浏览器都支持。\n好吧，你现在可以说了，都有了word-wrap这个东西，那还要 word-break 来干什么鸟？\n万恶的资本家总是想要榨干劳动者的一切，你看，下图中的long后面不是还有一段空间吗，难道就这样放着？太浪费了。。。\n01\n是啊，long后面那里足可以放好几个短的单词了，都是那个臭变态的长单词！\n所以IE真的很体贴，不要再骂它啦，考虑到不浪费一点点空间的问题，它创造出了 word-break 这个东西。现在我们来看看使用 word-break:break-all; 后会怎么样。\n01\n01\n看看发生什么了？那个变态的长单词并没有被挪到下一行，而是直接放在了long后面，然后在父容器的右边界断开了。所以，它没有浪费空间了哦。\n再看下word-break:break-all的浏览器支持情况：\n01\n除了opera外，其他都支持耶（火狐也从不支持改为支持了）!\n最开始我们说了，word-wrap 是用来决定允不允许单词内断句的，如果不允许的话长单词就会溢出。最重要的一点是它还是会首先尝试挪到下一行，看看下一行的宽度够不够，不够的话就进行单词内的断句。\n而word-break:break-all则更变态，因为它断句的方式非常粗暴，它不会尝试把长单词挪到下一行，而是直接进行单词内的断句。这也可以解释为什么说它的作用是决定用什么方式来断句的，那就是——用了word-break:break-all，就等于使用粗暴方式来断句了。总之一句话，如果您想更节省空间，那就用word-break:break-all就对了！\n但无论如何，单词内的断句都会对西文的可读性产生一定的影响，有时候这点就要注意了。\nps:网上有些文章说，word-wrap:break-word 对长串英文不起作用，其实这是非常错误的，word-wrap:break-word照样能把一个长串英文或数字拆成多行。事实上，word-wrap:break-word与word-break:break-all共同点是都能把长单词强行断句，不同点是word-wrap:break-word会首先起一个新行来放置长单词，新的行还是放不下这个长单词则会对长单词进行强制断句；而word-break:break-all则不会把长单词放在一个新行里，当这一行放不下的时候就直接强制断句了。\n以上都是废话直接运行代码就完事 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;p style=\u0026#34; background:#000; width:100px; color:#F00; word-wrap:break-word\u0026#34; data-mce-style=\u0026#34; background: #000; width: 100px; color: #f00; word-wrap: break-word;\u0026#34;\u0026gt; haha 555555555555555555555555555555555 \u0026lt;/p\u0026gt; \u0026lt;p style=\u0026#34; background:#000; width:100px; color:#F00; margin-top:10px; word-break:break-all\u0026#34; data-mce-style=\u0026#34;background: #000; width: 100px; color: #f00; margin-top: 10px; word-break: break-all;\u0026#34;\u0026gt; haha 555555555555555555555555555555555 \u0026lt;/p\u0026gt; ","date":"2020-04-01","permalink":"http://localhost:1313/posts/20200401-difference-between-word-wrap-and-word-break/","section":"","summary":"","tags":[""],"title":"word-wrap和word-break的区别"},{"categories":[],"contents":" ","date":"2020-03-28","permalink":"http://localhost:1313/posts/20200328-boot-download-background-image/","section":"","summary":"","tags":["",""],"title":"Boot Download Background Image"},{"categories":[],"contents":" am using Ubuntu Linux. How to force Linux to reacquire a new IP address from the DHCP server? What is the command of Linux equivalent to Windows’s “ipconfig /renew” command?\nYou need to use Dynamic Host Configuration Protocol Client i.e., dhclient command. The client normally doesn’t release the current lease as it is not required by the DHCP protocol. Some cable ISPs require their clients to notify the server if they wish to release an assigned IP address. The dhclient command, provides a means for configuring one or more network interfaces using the Dynamic Host Configuration Protocol, BOOTP protocol, or if these protocols fail, by statically assigning an address. Advertisements\nLinux renew ip command using dhcp The -r flag explicitly releases the current lease, and once the lease has been released, the client exits. For example, open terminal application and type the command:\n$ sudo dhclient -r Now obtain fresh IP address using DHCP on Linux:\n$ sudo dhclient How can I renew or release an IP in Linux for eth0? To renew or release an IP address for the eth0 interface, enter:\n$ sudo dhclient -r eth0 $ sudo dhclient eth0 In this example, I am renewing an IP address for my wireless interface:\nsudo dhclient -v -r eth0 sudo dhclient -v eth0 Sample outputs: The -v option shows information on screen about dhcp server and obtained lease.\nOther options in Linux to renew dhcp There is no need to restart network service. Above command should work with any Linux distro such as RHEL, Fedora, CentOS, Ubuntu and others. On a related note you can also try out the following commands:\n# ifdown eth0 # ifup eth0 ### RHEL/CentOS/Fedora specific command ### # /etc/init.d/network restart OR ### Debian / Ubuntu Linux specific command ### # /etc/init.d/networking restart nmcli command (NetworkManager) to renew IP address in Linux The NetworkManager daemon attempts to make networking configuration and operation as painless and automatic as possible by managing the primary network connection and other network interfaces, like Ethernet, WiFi, and Mobile Broadband devices command-line tool for controlling NetworkManager. The nmcli is a command-line tool for controlling NetworkManager and getting its status. To renew IP address using nmcli for connection named ‘nixcraft_5G’ (use ‘nmcli con‘ command to get list of all connections):\nnmcli con nmcli con down id \u0026#39;nixcraft_5G\u0026#39; nmcli con up id \u0026#39;nixcraft_5G\u0026#39; Sample outputs: Linux Force dhclient to renew IP address on a CentOS 7/Ubuntu/Debian and other Linux-based server Most modern Linux-based system uses the systemd as a init system and here is how to force Linux to renew IP address using DHCP. Use the ip command to find out the current IP address:\nip a ip a s eth0 Run:\ndhclient-v -r eth0 OR use the systemctl command to restart network service on a CentOS 7: systemctl restart network.service systemctl status network.service\nLinux Force DHCP Client to renew IP address\nConclusion: Linux force DHCP client to release and renew an IP address Command Command to release/renew a DHCP IP address in Linux ip a Get ip address and interface information on Linux ip a s eth0 Find the current ip address for the eth0 interface in Linux dhclient -v -r eth0 Force Linux to renew IP address using a DHCP for eth0 interface systemctl restart network.service Restart networking service and obtain a new IP address via DHCP on Ubuntu/Debian Linux systemctl restart networking.service Restart networking service and obtain a new IP address via DHCP on a CentOS/RHEL/Fedora Linux systemctl restart systemd-networkd Restart networking service and obtain a new IP address via DHCP on a Arch Linux nmcli con Use NetworkManager to obtain info about Linux IP address and interfaces nmcli con down id \u0026rsquo;enp6s0' Take down Linux interface enp6s0 and release IP address in Linux nmcli con up id \u0026rsquo;enp6s0' Obtian a new IP address for Linux interface enp6s0 and release IP address using DHCP dhcpcd 在 SuSE distribution 里面，他仅有 dhcpcd 这支程序，他与 dhclient 是相同的命令。 ifconfig enp3s0 10.6.6.6 set static IP Man pages: dhclient(8)\n","date":"2020-03-24","permalink":"http://localhost:1313/posts/20200324-linux-force-dhcp-client-to-renew-ip/","section":"","summary":"","tags":[""],"title":"Linux Force DHCP Client to Renew IP"},{"categories":[],"contents":"在自定义设置 - 按钮/LED 红灯无法关闭 有的固件有BUG只能在路由器启动后执行以下命令\nmtk_gpio -w 13 0 #关红灯 ","date":"2020-03-23","permalink":"http://localhost:1313/posts/20200323-pandavan-off-led-indicator/","section":"","summary":"","tags":[""],"title":"Pandavan Off LED Indicator"},{"categories":[],"contents":"近日在 Linux 环境中做版本迁移的时候遇到一个问题：需要将一个目录遍历拷贝到另一个目录中，但需要忽略其中的某些文件，由于目录中东西比较多，忽略的项也不好一一指定。普通的 cp 命令并没有排除某个文件或文件夹的参数，比较丑陋点可以 cp -r 拷贝完目录之后再去删除无用的，但如果做批量脚本操作就不爽了，经过实际试验之后暂时找到两个比较好的方法。\n使用 rsync 进行拷贝 rsync 本来是文件同步备份的工具，相对于普通的 cp 命令，rsync 在控制方面就强多了，而且 rsync 对遍历目录也支持，有 \u0026ndash;exclude 参数可以忽略指定的文件或文件夹。\nrsync -vaP --exclude=\u0026#34;.*\u0026#34; --exclude=\u0026#34;Makefile\u0026#34; dir1 /home/dir2 如上面演示的就可以排除掉隐藏文件和 Makefile 文件，-a 参数已经包含遍历处理参数 -r。\n使用 find 加 cpio 进行拷贝 备注：此方法来自 Advanced Bash-Scripting Guide，需要了解的童鞋自己去参考了。\n用过 find 的童鞋都知道，find 对文件的过滤那是非常强大的，配合 cpio 来进行目录的遍历拷贝就可以实现过滤指定的文件或文件夹，当然也可以做到只备份特定的文件或文件夹，你可以用 find 的各种过滤参数达到拷贝哪天的文件，拷贝近期更改的文件等特殊效果，而且 find 支持正则表达式，这种方式想比第一种使用 rsync 跳过文件的方式更加灵活，因此非常推荐使用此方式进行目录拷贝。\ncd dir1 find . -regextype posix-egrep -mindepth 1 ! -regex \u0026#39;./(dev|tmp)($|/.*)\u0026#39; ! -name Makefile -a ! -name .svn | cpio -admvp /home/dir2 小解释下：\nfind 的 -regextype 参数指定正则表达式类型，posix-egrep 为 egrep 用的扩展正则表达式，-mindepth 使 find 的输出中不包括目录本身，-regex 参数指定过滤的文件的正则表达式，-regex 前面的感叹号表示跳过，'./(dev|tmp)($|/.*)' 这个正则表达式即表示跳过目录中的第一层 dev 和 tmp 目录以及下面所有的文件和文件夹，最后两个 -name 指定要跳过文件名为 Makefile 和 .svn 的文件，这样在备份版本库的时候非常有用。\ncpio 命令将 find 的输出文件列表依次拷贝到 /home/dir2 目标目录中，-a 表示不更新文件的访问时间，-d 指定自动创建目录，-m 指定保留文件的修改时间，-p 指定 cpio 工作在 Copy-pass 模式，这是专门用来拷贝目录树的一种模式。\nPS：如果有更加简单的方法，欢迎提出指正哦~~~ ^_^\n","date":"2020-03-20","permalink":"http://localhost:1313/posts/20200320-linux-copy-directory-ignore-files/","section":"","summary":"","tags":[""],"title":"Linux中拷贝目录跳过指定文件的方法"},{"categories":[],"contents":"今天滚完系统就没网络，startx报内核模块错误，当场裂开了，开机显示加载驱动失败，先来看看加载日志吧\nsudo systemctl status systemd-modules-load 报错全是类似Module Vboxdrv Not Found in Directory xx这种\n再查看下内核模块相关目录发现了端倪\n❯ uname -a Linux arch 5.5.8-arch1-1 ~/site/blog ❯ ls /lib/modules 5.5.9-arch1-2 原来是没加载新内核\n解决方法 根据经验最好别排查原因，估计就是软件包BUG，懒得折腾再安装一次旧内核再滚就完事了\n升级内核，系统挂了，可以通过降级内核的方法来修复系统\n内核的安装包会缓存在/var/cache/pacman/pkg，文件名以 “linux-版本号”开头\n使用命令pacman -Udd xxx.zst来安装\n如果提示有文件存在的错误，删除掉提示的文件，再执行上面的命令，就可以了\n提示：要养成升级前先看wiki的习惯，如果仓库最新软件有bug，wiki会有公示\n","date":"2020-03-18","permalink":"http://localhost:1313/posts/20200318-module-vboxdrv-not-found-in-directory/","section":"","summary":"","tags":[""],"title":"archlinux升级内核后，系统挂了，修复方法"},{"categories":[],"contents":"由于众所周知的原因，现在即使断网安装来自Flash Player安装问题 页面下载的离线安装包，也会在联网使用的时候提示“此Flash Player 与您的地区不兼容，请重新安装 Adobe Flash Player”。 为了防止有人既不想使用Adobe Download Manager, 又不想动自己的hosts(比如我)，本人把Flash 中国特供版的离线安装包下载地址给挖出来了，以尽可能地避免中国特供版ADM后期再加其他猛料。同时提供国际EXE安装版本和MSI安装版本。\n国际版下载地址请使用代理访问，否则会被跳转回2144网页。\n中国特供版 (30.0.0.113) Flash Player NPAPI https://www.flash.cn/flashplayer/3000113/install_flash_player_cn.exe\nFlash Player PPAPI https://www.flash.cn/flashplayer/3000113/install_flash_player_ppapi_cn.exe\nFlash Player ActiveX https://www.flash.cn/flashplayer/3000113/install_flash_player_ax_cn.exe\n国际版 (exe 格式, 30.0.0.113) Flash Player NPAPI https://fpdownload.macromedia.com/pub/flashplayer/latest/help/install_flash_player.exe\nFlash Player PPAPI https://fpdownload.macromedia.com/pub/flashplayer/latest/help/install_flash_player_ppapi.exe\nFlash Player ActiveX https://fpdownload.macromedia.com/pub/flashplayer/latest/help/install_flash_player_ax.exe\nFlash Player 独立播放器 (Standalone Projector) https://fpdownload.macromedia.com/pub/flashplayer/updaters/30/flashplayer_30_sa.exe\n国际版 (Windows Installer 格式, 30.0.0.113) Flash Player NPAPI https://fpdownload.adobe.com/get/flashplayer/distyfp/current/win/install_flash_player_30_plugin.msi\nFlash Player PPAPI https://fpdownload.adobe.com/get/flashplayer/distyfp/current/win/install_flash_player_30_ppapi.msi\nFlash Player ActiveX https://fpdownload.adobe.com/get/flashplayer/distyfp/current/win/install_flash_player_30_active_x.msi\n国际版 (exe 格式, 32.0.0.344) Flash Player PPAPI https://fpdownload.adobe.com/get/flashplayer/pdc/32.0.0.344/install_flash_player_ppapi.exe\n百度云下载地址 链接: https://pan.baidu.com/s/1DOs3aAyLpEDg2o7H-9a3_Q 提取码: a625\n","date":"2020-03-13","permalink":"http://localhost:1313/posts/20200313-flash-download/","section":"","summary":"","tags":[],"title":"Flash Download"},{"categories":[],"contents":" 百度网盘无限“扩容”方法这里说的扩容是非正常途径，存在一定的风险！\n操作步骤 新建一个文件夹111111 移动或转存一些文件到该文件夹111111 （假设这个文件夹占用容量是A） 删除该文件夹111111 （网盘占用容量减少A） 再新建一个同名空文件夹111111，不放入文件，直接删除。（占用容量无变化） 到回收站还原第一次删除的文件夹111111[里面有一些文件] 正常结果：还原该文件夹后，网盘使用容量应该增加A 不正常结果：网盘容量并没有增加A，也就是说，还原后的文件夹111111占用的容量A成了漏网之鱼，重复操作即可扩容 若没有复现这个bug，重新操作以上步骤 不过需要更换文件名，比如：222222，3333，234fwef，808080 使用说明 一个标准容量是5T的SVIP个人账号，要扩容100T，我们就提前在账号内存入100T的占位文件，此时系统显示使用空间为0，可用空间为5T。\n1)用户转入4T资源后，系统显示使用空间为4T，可用空间为1T。 2)用户删除4T以上的占位文件，系统又显示使用空间为0T，可用空间为5T。 3)循环1~2的操作，直到消耗完占位文件。 补充说明 如果数据被同步，网盘占用容量正常了，就需要修复操作\n扩容的步骤 新建一个文件夹123456【标记：A】， 删除之后，还原存入N个占位文件。 再删除。 新建一个同名文件夹123456 【标记：B】 删除后，到回收站还原文件夹123456【标记：A】。 若提示：容量不足提示还原失败，或者还原成功后，占用容量增加了。说明“扩容”失败了! 继续上面的操作步骤，换一个文件夹名比如23456789 继续操作直至成功。有时候需要多次尝试才可以成功！“扩容”成功后：\n注意1. 不要删除或重命名这个文件夹【标记：A】 里面最多不存放入超过500个数量的（占位）文件，否则删除后就无法还原。 如果“占用容量被后台同步” 就需要不断的删除和还原文件夹【标记：A】来修复占用容量【这里要注意一下：网盘占用容量会出现“卡住”的情况，等半个小时左右就正常显示了】 注意2. 必须保留回收站的同名文件夹【标记：B】，不能清空回收站。 注意3. 登录客户端或者上传、转存、下载后，第二天占用容量就会被同步，当然什么都不操作也会出现容量被同步的情况。按照1中操作 重新“扩容即可”，为了修复顺利，不要删除文件夹【标记：A】 和保留一些占位文件。 若占位文件和文件夹【标记：A】 都被删除了，也可以修复，重新操作步骤1-6。区别是不能从专辑转存占位文件了，就需要用网盘里的文件替代，还原成功后，就存入一些大容量的文件，数量不能超过500.做删除和还原。这样循环下去，理论可以做到无限多的内存。 很多人说不行，3月5日我自己试了下，用脚本去执行操作，很快扩出了100T的占位文件。 ","date":"2020-03-13","permalink":"http://localhost:1313/posts/20200313-baidu-wangpan-grow/","section":"","summary":"","tags":[""],"title":"百度网盘扩容到100t以上"},{"categories":[],"contents":"在chrome首页的链接https://www.google.com/chrome后加上?system=true\u0026amp;standalone=1，一般默认下载稳定版，如果需要指定下载的版本就再加上\u0026amp;extra=[版本名称]（版本有stablechannel、betachannel、devchannel、canarychannel）。修改完链接后回车，就能下载离线包了。\n","date":"2020-03-13","permalink":"http://localhost:1313/posts/20200313-chrome-standalone/","section":"","summary":"","tags":[""],"title":"Google Chrome 离线安装包的官方下载"},{"categories":[],"contents":"前言 以前一直用类似rename \u0026quot;s/_/-/\u0026quot; *这样的命令正则替换一些文件名，不过系统切换到Archlinux后用rename一直失败，用man看了下说明才发现并不支持正则，只能这样用，并且不能全局替换\nrename 123 456 * 其实几乎所有情况下, rename用不到正则表达式的. 你最多不过是通过正则确定要改名的文件列表而已. 这通过管道太容易了. 例如我在shell下, 会这样使用\nf \u0026#39;bak$\u0026#39; |x rename \u0026#39;.bak\u0026#39; \u0026#39;\u0026#39; 在管道之前, 可以通过各种方式搭配, 来生成所需的文件列表\n而rename也可以分多个步骤完成, man帮助中就有示例.\n原因 最近有空查了很多资料才发现很多发行版默认的rename是util-linux里很弱的那个rename，比如Archlinux\n解决方法 Archlinux可以装perl-rename这个包，命令就是perl-rename。Mac下可以用brew 安装rename。好久没用Ubuntu，记得以前Ubuntu 是prename 这个命令。\n其实不只是s命令，所有有效的perl命令都能用，文件名会作为$_ 传入，命令执行完后的$_作为新文件名。比如全部改成小写：\nrename \u0026#39;y/A-Z/a-z/\u0026#39; * ","date":"2020-03-12","permalink":"http://localhost:1313/posts/20200312-rename-regex/","section":"","summary":"","tags":[""],"title":"rename使用正则表达式"},{"categories":[],"contents":" :w !sudo tee % 命令:w !{cmd}，让vim执行一个外部命令{cmd}，然后把当前缓冲区的内容从stdin传入。 tee是一个把stdin保存到文件的小工具。 而%，是vim当中一个只读寄存器的名字，总保存着当前编辑文件的文件路径。 所以执行这个命令，就相当于从vim外部修改了当前编辑的文件，好完工。\n","date":"2020-03-12","permalink":"http://localhost:1313/posts/20200312-how-does-the-vim-write-with-sudo-trick-work/","section":"","summary":"","tags":[""],"title":"如何在vim保存时获得sudo权限"},{"categories":[],"contents":"使用vim时无意间触碰到q键，左下角出现“recording”这个标识，觉得好奇，遂在网上查了一下，然后这是vim的一个强大功能。他可以录 制一个宏（Macro)，在开始记录后，会记录你所有的键盘输入，包括在insert模式下的输入、正常模式下使用的各种命令等。\n具体使用：\n第一步：在正常模式下（非insert模式、非visual模式）按下q键盘\n第二步：选择a-z或0-9中任意一个作为缓冲器的名字，准备开始录制宏\n第三步：正常的操作，此次所有的操作都会被记录在上一步中定义的缓冲器中\n第四步：在非insert模式下输入q停止宏的录制\n第五步：使用@ + 第二步中定义的缓冲器的名字即可。\n例如想把下面的文字\nline1 line-2 line3-1 l4 line1 line-2 line3-1 l4 变成如下的文字\nSystem.out.println(line1); System.out.println(line1); System.out.println(line-2); System.out.println(line3-1); System.out.println(L4); System.out.println(line1); System.out.println(line1); System.out.println(line-2); System.out.println(line3-1); System.out.println(L4); 观察可以发现他们的规律，在每行文字的开头添加“System.out.println(”，结尾添加“);”就变成下面的信息了。下面简单介绍一下如何使用recording来完成这样的操作。 首先把光标移动line1上，输入qt，准备开始录制，缓冲器的名字为t，录制的动作为：shift + ^ 回到行首、按下i键进入insert模式、输入“System.out.println(”、按下esc键回到正常模式、shift + $ 回到行尾部、按下i键进入insert模式、输入“);”按下esc键回到正常模式，按下q停止录制。然后把光标移动到下面一行的任意位置输入 @ + t 即可。\nrecording还可以和查询结合起来使用，例如想把一个文件中含有特定字符串的行注释，可以通过这样的宏来实现。在正常模式下输入/search string + enter、shift + ^、i、#、esc、shift + $。\n让定制的宏自动执行多次的方法是先输入一个数字，然后在输入@ + 缓冲器的名字。 例如 100@t，表示执行100次。\n","date":"2020-03-12","permalink":"http://localhost:1313/posts/20200312-vim-recording/","section":"","summary":"","tags":[""],"title":"vim recording的使用方法"},{"categories":[],"contents":"首先看一段代码\nimport { Vue, Component, Prop } from \u0026#39;vue-property-decorator\u0026#39; @Component export default class YourComponent extends Vue { @Prop(Number) propA!: number @Prop({ default: \u0026#39;default value\u0026#39; }) propB!: string @Prop([String, Boolean]) propC: string | boolean } 这是vue组件的ts写法，仔细观察，里面有一段这样的代码@Prop(Number) propA!: number，这是什么鬼？\n查了一下ts的文档说明，原来感叹号是非null和非undefined的类型断言，所以上面的写法就是对propA这个属性进行非空断言。文档的相关说明在这里。\n官方文档上的一个例子很好的说明了这个问题\ninterface Entity { name: string } // Compiled with --strictNullChecks function validateEntity(e?: Entity) { // Throw exception if e is null or invalid entity } function processEntity(e?: Entity) { validateEntity(e); let s = e!.name; // Assert that e is non-null and access name } 如果直接使用let s = e.name;，编译器会抛出e可能不存在的错误，但是使用非空断言，则表示e肯定是存在的，从而不会产生编译问题。\n","date":"2020-03-10","permalink":"http://localhost:1313/posts/20200310-what-does-the-exclamation-point-behind-the-ts-attribute-mean/","section":"","summary":"","tags":[""],"title":"ts属性后面的感叹号有什么用处？"},{"categories":[],"contents":" ❯ git clone https://github.com/Zhili/GameServer Cloning into \u0026#39;GameServer\u0026#39;... fatal: unable to access \u0026#39;https://github.com/Zhili/GameServer/\u0026#39;: Couldn\u0026#39;t resolve host name (Just a little reminder) If you want the hostname also be resolved by the proxy (that means passing everything through the proxy), especially when you are cloning a gist, you can use the following setting (the key is that it uses socks5h instead of socks5):\ngit config --global http.proxy socks5h://127.0.0.1:1080 ","date":"2020-03-06","permalink":"http://localhost:1313/posts/20200306-git-clone-not-resolve-host/","section":"","summary":"","tags":[""],"title":"git 出现错误Could not resolve host: github.com"},{"categories":[],"contents":"Installation The package you will need to install depends on the browser you use.\nThe NPAPI version can be installed with the flashplugin package. The PPAPI version can be installed with the pepper-flash package. Standalone version can be installed with the flashplayer-standaloneAUR package. ","date":"2020-03-04","permalink":"http://localhost:1313/posts/20200304-browser-plugins/","section":"","summary":"","tags":["","","",""],"title":"Browser plugins"},{"categories":[],"contents":"在看书的时候，搜void 0时，看到有人列出过类似的例子，所以延伸着搜索了一堆简写的例子整理出来。\n这里的简写，包括比如void 0代替undefined这类值替代，\n也包括了箭头函数替代普通函数、for循环各种写法中性能最好的这类写法替代，\n还想到了以前面试的时候看到的es6面试题，数组去重，最简单的方法是用set和Array.from。\n类似的都会整理出来，以后遇到了新的也会更新上来。\n2018/12/22\n（1）取整，位运算更快。原因介绍：参考：位运算实现的原因\n位运算取整（更快）\n位运算取整：下述，都可以\n~~a; //双非位操作符 a|0; 。。。 （2）四舍五入（0.5规定向上取整），位运算更快\n位运算的四舍五入，负数不适配\n位运算适合正数的四舍五入，但是负数只能舍，不能入。\na+0.5|0; ~~(a+0.5); 。。。 （3）内置值 undefined\nundefined替代\nvoid 0; // 快 0[0]; // 略慢 （4）内置值 Infinity\nInfinity替代\n1/0; （5）布尔值短写法\n布尔值短写法\n!0; // true !1; //false （6）十进制指数（想当初，刚学c的时候，我一直都用pow(10,n)） 10000000000 === 1e10\n（7）三元运算符 ? : 还用于简化函数的调用。\nfunction x() { console.log(\u0026lsquo;x\u0026rsquo;) }; function y() { console.log(\u0026lsquo;y\u0026rsquo;) }; let z = 3; 简化前：\nif (z == 3) { x(); } else { y(); } 简化后：\n(z==3?x:y)(); //x （8）短路求值 \u0026amp;\u0026amp; || 当给一个变量分配另一个值时，想确定源始值不是null，undefined或空值。可以写撰写一个多重条件的if语句。\nif (variable1 !== null || variable1 !== undefined || variable1 !== \u0026lsquo;\u0026rsquo;) { let variable2 = variable1; } 或者可以使用短路求值方法：\nconst variable2 = variable1 || \u0026lsquo;backupValue\u0026rsquo;; （9）声明变量简写 let x; let y; let z = 3; 简写方法：\nlet x, y, z=3; （10）if存在条件简写 if ( a ) { } if ( !a ) { } （11）js循环简写 虽说，有for (variable in object) {} 用于遍历对象属性名，\nfor (variable of iterable) {} 用于遍历对象属性值（但不适用于普通自定义对象），\nfor ( var key of Object.keys( someObject ) ) { } for-of结合Object.keys可以遍历普通对象属性值，\nArray.prototype.forEach遍历数组和类数组对象，\n但是，从性能上来讲还是最原始的for( ; ; )运行最快，所以非必要的时候还是使用原始for循环。\n//性能最优化，但是可读性低 var i; //优化变量声明 var divs = document.getElementsByTagName(\u0026ldquo;div\u0026rdquo;); for( i = divs.length-1; i \u0026gt;= 0; i -= 1 ){ //优化循环中动态集合读取、减值迭代、用i-=1 代替 i\u0026ndash; } //合理的循环优化，以优化性能的前提下兼顾可读性 var i,len; var divs = document.getElementsByTagName(\u0026ldquo;div\u0026rdquo;); for( i = 0, len = divs.length; i \u0026lt; len; i++ ){ } 参考：各种循环遍历对比\n（12）对象属性简写 如果属性名与key名相同，则可以采用ES6的方法：\nconst obj = { x: x, y: y }; 简写：\nconst obj = { x, y }; （13）箭头函数简写 要注意箭头函数的特性：\n1）this指向定义时的环境。2）不可new实例化。3）this不可变。4）没有arguments对象。\n常用于内部函数，增强可读性。\nfunction sayHello(name) { console.log(\u0026lsquo;Hello\u0026rsquo;, name); } setTimeout(function() { console.log(\u0026lsquo;Loaded\u0026rsquo;); }, 2000); list.forEach(function(item) { console.log(item); }); 简写：\nsayHello = name =\u0026gt; console.log(\u0026lsquo;Hello\u0026rsquo;, name); setTimeout(() =\u0026gt; console.log(\u0026lsquo;Loaded\u0026rsquo;), 2000); list.forEach(item =\u0026gt; console.log(item)); （14）箭头函数中的省略return写法 (参数1,参数2,…,参数N) =\u0026gt; 表达式（单一）\n// 相当于：(参数1, 参数2, …, 参数N) =\u0026gt; { return 表达式; }\nfunction calcCircumference(diameter) { return Math.PI * diameter } var func = function func() { return { foo: 1 }; }; 简写：\ncalcCircumference = diameter =\u0026gt; (Math.PI * diameter); var func = () =\u0026gt; ({ foo: 1 }); （15）默认参数值 为了给函数中参数传递默认值，通常使用if语句来编写，但是使用ES6定义默认值，则会很简洁：\nfunction volume(l, w, h) { if (w === undefined) w = 3; if (h === undefined) h = 4; return l * w * h; } 简写：\nvolume = (l, w = 3, h = 4 ) =\u0026gt; (l * w * h); volume(2) // 24 （16）强制参数简写 JavaScript中如果没有向函数参数传递值，则参数为undefined。为了增强参数赋值，可以使用if语句来抛出异常，或使用强制参数简写方法。\nfunction foo(bar) { if(bar === undefined) { throw new Error(\u0026lsquo;Missing parameter!\u0026rsquo;); } return bar; } 简写：\nmandatory = () =\u0026gt; { throw new Error(\u0026lsquo;Missing parameter!\u0026rsquo;); } foo = (bar = mandatory()) =\u0026gt; { return bar; } （17）模板字符串简写 es6中的模板字符串可以保留空白符（换行、空格、制表符）和传参。\n模板字符串中的传参、换行、空格\nconst db = \u0026lsquo;Our database is\\n\\t\u0026rsquo;\n\u0026lsquo;http://\u0026rsquo; + host + \u0026lsquo;:\u0026rsquo; + port + \u0026lsquo;/\u0026rsquo; + database; 简写： const db = Our database is http://${host}:${port}/${database}; （18）解构赋值简写 在web框架中，经常需要从组件和API之间来回传递数组或对象字面形式的数据，然后需要解构它\nconst observable = require(\u0026lsquo;mobx/observable\u0026rsquo;); const action = require(\u0026lsquo;mobx/action\u0026rsquo;); const runInAction = require(\u0026lsquo;mobx/runInAction\u0026rsquo;);\nconst store = this.props.store; const form = this.props.form; const loading = this.props.loading; const errors = this.props.errors; const entity = this.props.entity; 简写：\nimport { observable, action, runInAction } from \u0026lsquo;mobx\u0026rsquo;; const { store, form, loading, errors, entity } = this.props; 也可以分配变量名：\nconst { store, form, loading, errors, entity:contact } = this.props; //最后一个变量名为contact （19）扩展运算符简写，数组，对象\n// joining arrays const odd = [1, 3, 5]; const nums = [2 ,4 , 6].concat(odd); // cloning arrays const arr = [1, 2, 3, 4]; const arr2 = arr.slice() 简写：\n// joining arrays const odd = [1, 3, 5 ]; const nums = [2 ,4 , 6, ...odd]; // [ 2, 4, 6, 1, 3, 5 ] // cloning arrays const arr = [1, 2, 3, 4]; const arr2 = [...arr]; // [1, 2, 3, 4] 还使用扩展运算符来在一个数组中任意处插入另一个数组： const odd = [1, 3, 5]; const nums = [2, ...odd, 4 , 6]; // [2, 1, 3, 5, 4 , 6] 也可以使用扩展运算符解构： const { a, b, ...z } = { a: 1, b: 2, c: 3, d: 4 }; console.log(a) // 1 console.log(b) // 2 console.log(z) // { c: 3, d: 4 } （20）从对象数组中查找某个值 es6数组的新方法 Array.find() ，但是只能返回一个值，找到多个返回第一个。\narr.find(callback[,thisArg]) function callback(element, index, array){} const pets = [ { type: \u0026#39;Dog\u0026#39;, name: \u0026#39;Max\u0026#39;}, { type: \u0026#39;Cat\u0026#39;, name: \u0026#39;Karl\u0026#39;}, { type: \u0026#39;Dog\u0026#39;, name: \u0026#39;Tommy\u0026#39;}, ] function findDog(name) { for(let i = 0; i\u0026lt;pets.length; ++i) { if(pets[i].type === \u0026#39;Dog\u0026#39; \u0026amp;\u0026amp; pets[i].name === name) { return pets[i]; } } } 简写：\nvar pet = pets.find(pet =\u0026gt; pet.type ===\u0026#39;Dog\u0026#39; \u0026amp;\u0026amp; pet.name === \u0026#39;Tommy\u0026#39;); console.log(pet); // { type: \u0026#39;Dog\u0026#39;, name: \u0026#39;Tommy\u0026#39; } （21）数组去重 es6新增数据结构set，元素不重复。\n往常需要循环的代码在这里只有两行。\nvar arr = [1,2,2,3,4]; // 需要去重的数组 var set = newSet(arr); // {1,2,3,4} var newArr =Array.from(set); // 再把set转变成array console.log(newArr); // [1,2,3,4] 参考：为什么js中要用void 0 代替undefined，还是有特别的含义呢\n分享19个JavaScript 有用的简写写法\n课外：在搜索的时候，看到有人觉得object[\u0026quot;key\u0026quot;]和object.key也是简写，个人觉得这就是个不一样的写法。object[keyValue]中的值是属性名字符串，object.key中的key是object下的已知属性。\n有人遇到过 for ( var key in someObject ) { } 导致的在循环体中 someObject.key 取不到值。\n这个for-in语句，相当于 for ( var key of Object.keys( someObject ) ) { }，\nObject.keys()返回的是属性名字符串，for-in中的key返回的也是字符串。\nvar json = {a: 1}; for(var key in json ){ typeof key; //\u0026#34;string\u0026#34; } ","date":"2020-02-28","permalink":"http://localhost:1313/posts/20200228-javascript-shorthand/","section":"","summary":"","tags":[""],"title":"javascript中的各种简写总结（不断更新）"},{"categories":[],"contents":"Try this:\necho \u0026#39;foo\u0026#39; | openssl aes-256-cbc -pbkdf2 -a -salt echo \u0026#39;U2FsdGVkX1/QGdl4syQE8bLFSr2HzoAlcG299U/T/Xk=\u0026#39; | openssl aes-256-cbc -pbkdf2 -a -d -salt Run\nopenssl list-cipher-commands to list all available ciphers.\n","date":"2020-02-28","permalink":"http://localhost:1313/posts/20200228-encrypt-string-using-openssl/","section":"","summary":"","tags":["",""],"title":"Encrypt string using Openssl"},{"categories":[],"contents":"https://y2mate.guru/en1/\n","date":"2020-02-27","permalink":"http://localhost:1313/posts/20200227-youtube-video-download/","section":"","summary":"","tags":[""],"title":"youtube视频下载"},{"categories":[],"contents":"获取查询条件的值 validateFields form.validateFields / validateFieldsAndScroll 校验并获取一组输入域的值与 Error，若 fieldNames 参数为空，则校验全部组件\n获取表单的所有数据 this.props.form.validateFieldsAndScroll((err, values) =\u0026gt; { if(err){ return; } console.log(\u0026#39;_values\u0026#39;, values); }); 获取表单的部分字段数据 this.props.form.validateFieldsAndScroll([`timeUnit${num}`, `Time${num}`,`deviceTypeId${num}`], (err, values) =\u0026gt; { if(err){ return; } console.log(\u0026#39;_values\u0026#39;, values); let t1,t2; if(values[`Time${num}`] === undefined){ t1= undefined; t2= undefined; }else{ t1= values[`Time${num}`][0].unix()*1000; t2= values[`Time${num}`][1].unix()*1000; } const _q ={ startTime: t1, endTime: t2, timeUnit: values[`timeUnit${num}`], deviceSN: \u0026#34;\u0026#34; , //设备编号 modulleNo: \u0026#34;\u0026#34;, //(POCT BOX模块名称) projectNo: \u0026#34;\u0026#34;, //项目名称 type: \u0026#34;\u0026#34;, //模块类型、error、open/close、 subType: \u0026#34;\u0026#34;, //(预留字段) } }); ","date":"2020-02-27","permalink":"http://localhost:1313/posts/20200227-react-validate/","section":"","summary":"","tags":["",""],"title":"React关于form的取部分字段数据"},{"categories":[],"contents":"I have the folowing part of code:\nprivate rootRef = React.createRef\u0026lt;HTMLDivElement\u0026gt;(); const target = ( \u0026lt;div\u0026gt; \u0026lt;Icon design=\u0026#39;accepted\u0026#39; size=\u0026#39;xl\u0026#39; /\u0026gt; \u0026lt;/div\u0026gt; ); return ( \u0026lt;React.Fragment\u0026gt; {React.cloneElement(target, { ref: this.rootRef, onMouseOver: this.handleMouseOver, onMouseLeave: this.handleMouseLeave, })} {open \u0026amp;\u0026amp; this.renderTooltip()} \u0026lt;/React.Fragment\u0026gt; ); When target with div element (or any other instead of div) everything is ok, but when target is:\nconst target = ( \u0026lt;Icon design=\u0026#39;accepted\u0026#39; size=\u0026#39;xl\u0026#39; /\u0026gt; ); I get error: Warning: Function components cannot be given refs. Attempts to access this ref will fail. Did you mean to use React.forwardRef()?\nIcon is a span element inside of which is svg.\ngetFieldDecorator If getFieldDecorator receives components that are already connected by @connect and other components (such as InputGroup), it will receive a warning.\nA temporary solution is:\n// Item.js // ... // export default Item; // eslint-disable-next-line react/no-multi-comp export default class ItemWrapper extends Component { render() { const {children, ...props} = this.props return \u0026lt;Item {...props}\u0026gt;{children}\u0026lt;/Item\u0026gt; } } ","date":"2020-02-27","permalink":"http://localhost:1313/posts/20200227-tippy-warning/","section":"","summary":"","tags":["",""],"title":"Tippy_warning"},{"categories":[],"contents":"百度云 请低调使用\u0026hellip;\n都是选微博登录 选微博登录 选微博登录 选微博登录!!! 验证码全部大写填写 确认用鼠标点 登录后如遇到重试页面, 点击几次重试即可. 请不要删除网盘里的文件!!! 请不要删除网盘里的文件!!! 请不要删除网盘里的文件!!! 并不保证当你看到时账号都是可以用的, 但是分享的时候肯定都是可以的. 如果有失效账号, 麻烦告知一下, 我会及时处理.\n账号越来越难弄, 且用且珍惜.\nAccount Expire UserName 账号：jiao36662855@163.com密码：2i1dyc 2020-03-23 账号：17109223297密码：hz834931 2020-03-23 账号：bizoulong982@163.com密码：3d55qbk7 （2.22当天有效） 账号：17898611960密码：aayu805 2020-03-23 账号：15096085029密码：yqpfem278 2020-03-23 账号：16534101337密码：mianfeivip.com3 2020-03-23 账号：18857395243密码：aaaa1111 2020-03-23 账号mpbncy09@touzi580.com密码1ht4esfgd6 2020-03-23 輳河yqdae 账号mw5w30u6@touzi580.com密码4bloms02sl 2020-03-13 到期 c0a52mx6 账号dym7lmrg@touzi580.com密码2omyuhw4tw 2020-03-12 到期 沾辗njpuv 微博登录账号：15088561466 密码：625006620 CH素材库4 账号13715007275密码a123456 day大陆男裱丶 再次提醒,选择微博账号登录.\n如有账号密码错误, 请告知, 以便及时删除失效账号.\n爱奇艺 Account Expire UserName 账号：ey_jc@qq.com密码：soeasy233 账号：14745975134密码：pg123456 （也是奇异果电视会员） 账号：15278573040密码：199797.xing 迅雷（一般失效快） Account Expire UserName 账号：sreqba242密码：tc111222 账号：dbq7nnj840密码：q88628 账号：ho1uagtx33密码：r85509 账号：yflon1ga9y密码：t83729 账号：pyc78ey893密码：g1j3vh 账号：ick5a48uki密码：n81403 优酷 Account Expire UserName 账号：362852914@qq.com密码：abc147258 腾讯视频 Account Expire UserName 账号：1703448680密码：wuaipojie123 （QQ登陆） api列目录 http://pcs.baidu.com/rest/2.0/pcs/file?app_id=265486\u0026amp;method=list\u0026amp;path=%2F\n其它账号随缘分享。 百度云账号密码 U2FsdGVkX1/85ZnsNKKBENCYGROw/8vqBHFXFjm4+a9q6DdNx2pb2kC3p2xaD4GoBId9l4qdM4cP9ydDtGaZUw== icff10\n百度云cookie 用户名 ixz071 过期时间 2020-04-02\nBDUSS=0FCbnN-LVVvRTl1SXVScUQxVzRQdUVES2JXfjlRc3Y5NXU3OEJ0bDVYU2hSNFJlRUFBQUFBJCQAAAAAAAAAAAEAAAA~UE-SaXh6MDcxAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKG6XF6hulxeV; STOKEN=eead9e64ed6e5a7e9196182619b5e52b8971149448871f88a82da76a1d3954d5\n用户名 EmotionaFzz 过期时间 2020-05-01\nSTOKEN=acd28b38c76c427bb64fc11452ba911ffb339adcd96d9c9717d9167e7938413d;BDUSS=RmeE5EOFQ1UX5jVnNQS0Y0SEdoS0p1LTJMU1Y4TzZpLVdEaDRHYVNGUWl3YXBlSUFBQUFBJCQAAAAAAAAAAAEAAAD3vFqmRW1vdGlvbmFGenoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACI0g14iNINeMH\n","date":"2020-02-27","permalink":"http://localhost:1313/posts/20200227-baidu-svip/","section":"","summary":"","tags":[""],"title":"百度网盘超级会员账号分享"},{"categories":[],"contents":"给datepicker赋值 可以输出赋值,datepicker赋值需要moment格式的数据,如果赋值了string类型的会报错 需要进行moment格式化moment(dateString)\n给普通字符串赋值 如果赋值了moment类型的数据 可以通过moment(date).format(XXX)来解决,如果还不行的话可以使用date\u0026amp;\u0026amp; moment(date).lacale(‘en’).format(XXX)\n","date":"2020-02-26","permalink":"http://localhost:1313/posts/20200226-react-datepicker/","section":"","summary":"","tags":["","",""],"title":"出现value.locale is not a function问题解决办法"},{"categories":[],"contents":" 全称 缩写 event evt connect conn server srv address addr request req response rep lenght len collection col signal sig error of last number erron field field property props defines defs object obj system sys message msg number num directory dir dictionory dict protocol proto button btn table tbl label lbl Image img Sprite sp texture tex tween tw transform trans animation anim material mat vecter vec position pos delegate del callback cb 2020/02/25 update 缩写 全称 acc accessibility auto automatic eval evaluate impl implementation info in num number of min minimum max maximum nav navigation regexp regular expression util utility req request resp response res resource app application auth authorization/authentication 这点非常不认可，同一个常见缩写居然能代表两个不同的词。 dev develop env environment db database pkg package svr server i18n internationalization cert certificate msg message addr address tmp/temp temporary var/def variable/define 其实 var/def 已经是很多语言的关键字了 calc calculate/calculation src source dest destination min/max minimum/maximum 应该已经不算了吧。。。 doc document dir directory ","date":"2020-02-25","permalink":"http://localhost:1313/posts/20200225-abbreviations/","section":"","summary":"","tags":[""],"title":"约定俗成的常见缩写"},{"categories":[],"contents":"GNU cp(1) has a backup option:\ncp --backup SOURCE [SOURCE...] [DESTINATION] This has the following effects which can be controlled with other options as described in the manual page of cp(1):\n--backup[=CONTROL] make a backup of each existing destination file -b like --backup but does not accept an argument -S, --suffix=SUFFIX override the usual backup suffix The backup suffix is ~, unless set with --suffix or SIMPLE_BACKUP_SUFFIX. The version control method may be selected via the --backup option or through the VERSION_CONTROL environment variable. Here are the values:\nnone, off: never make backups (even if --backup is given) numbered, t: make numbered backups existing, nil: numbered if numbered backups exist, simple otherwise simple, never: always make simple backups\nExample cp --backup=existing --suffix=.orig ~/Music/* ~/Videos This will copy all files in ~/Music to ~/Videos. If a file of the same name exists at the destination, it is renamed by appending .orig to its name as a backup. If a file with the same name as the backup exists, the backup is instead renamed by appending .1 and, if that exists as well, .2 and so forth. Only then is the source file copied to the destination.\nIf you want to copy files in subdirectories recursively use -R:\ncp -R --backup=existing --suffix=.orig ~/Music ~/Videos ","date":"2020-02-25","permalink":"http://localhost:1313/posts/20200225-cp-backup/","section":"","summary":"","tags":["",""],"title":"Copying all files inside subdirectories and renaming instead of overwriting"},{"categories":[],"contents":"更新 IDE 和 SDK 工具 安装 Android Studio 后，您可以轻松通过自动更新和 Android SDK 管理器让 Android Studio IDE 和 Android SDK 工具保持最新状态。\n更新 IDE 和变更版本 若有可用的 IDE 更新，Android Studio 将通过小气泡对话框通知您，不过您也可以依次点击 Help \u0026gt; Check for Update（在 Mac 上，依次点击 Android Studio \u0026gt; Check for Updates）手动检查更新。\n您可以通过以下发布版本获取 Android Studio 更新：\nCanary 版：这些是前沿版本，大约每周更新一次，可在 developer.android.com/studio/preview 下载。 除了接收 Android Studio 的 Canary 版之外，您还将接收其他 SDK 工具的预览版，包括 Android 模拟器。\n虽然这些版本存在较多的错误，但它们已经过测试，我们希望为您提供这些版本，以便您尝试新功能并提供反馈。此版本不推荐用于生产开发。\n开发者版：这些是精心挑选的 Canary 版本，已经过全面的内部测试。 测试版：这些是基于稳定 Canary 版的候选版本，这类版本会先收集反馈，然后再作为稳定版进行发布。 稳定版：官方稳定版，可在 developer.android.com/studio 下载。 如果您想要在生产 Android 项目中仍然使用稳定版的同时试用预览版（Canary 版、开发者版或测试版），可以并排安装两个版本。\n要更改现有安装的更新版本，请执行以下操作：\n依次点击 File \u0026gt; Settings（在 Mac 上，依次点击 Android Studio \u0026gt; Preferences）打开 Preferences 窗口。 在左侧面板中，依次点击 Appearance \u0026amp; Behavior \u0026gt; System Settings \u0026gt; Updates。 确保已选中 Automatically check for updates，然后从下拉列表中选择一个版本（参见图 1）。 点击 Apply 或 OK。\n图 1. Android Studio 中的 Updates 偏好设置\n删除未使用的 Android Studio 目录\n当您首次运行 Android Studio 的主要版本时，它会查找包含缓存、设置、索引和日志的目录，以确定找不到对应安装内容的 Android Studio 的版本。然后，Delete Unused Android Studio Directories 对话框中会显示这些未使用目录的位置、大小和最后修改时间，并提供删除它们的选项。\nAndroid Studio 考虑删除的目录如下所示：\nLinux：/.AndroidStudio[Preview]version Mac：/Library/{Preferences, Caches, Logs, Application Support}/AndroidStudio[Preview]version Windows：%USER%.AndroidStudio[Preview]version 使用 SDK 管理器更新工具 Android SDK 管理器可以帮助您下载 SDK 工具、平台和开发应用所需的其他组件。下载后，您可以在标示为 Android SDK Location 的目录中找到每个软件包，如图 2 所示。\n要从 Android Studio 打开 SDK 管理器，请依次点击 Tools \u0026gt; SDK Manager 或点击工具栏中的 SDK Manager 。如果您没有使用 Android Studio，则可以使用 sdkmanager 命令行工具下载工具。\n已安装的软件包如有更新，其旁边的复选框中会显示短划线 。\n要更新某个项目或安装新项目，请点击复选框使其显示对勾。 要卸载某个软件包，请点击以清除该复选框。 待下载的更新在左侧列中以下载图标 表示。待执行的移除以红色叉号 表示。\n要更新所选的软件包，请点击 Apply 或 OK，然后同意所有许可协议。\n图 2. Android SDK 管理器。\n推荐的软件包 您应该特别考虑 SDK Tools 标签中的以下工具：\nAndroid SDK Build-Tools 必选。 包含编译 Android 应用的工具。请参阅 SDK 编译工具版本说明。 Android SDK Platform-Tools 必选。 包含 Android 平台所需的各种工具，包括 adb 工具。 Android SDK Tools 必选。 包括 ProGuard 等基本工具。请参阅 SDK 工具版本说明。 Android Emulator 推荐。基于 QEMU 的设备模拟工具，可用于在实际的 Android 运行时环境中调试和测试应用。请参阅 Android Emulator 版本说明。 注意：以前由支持代码库软件包提供的大多数 API 库（例如 Android 支持库、约束布局、Google Play 服务和 Firebase）现在可以从 Google 的 Maven 代码库中获得。采用 Android Studio 3.0 及更高版本创建的项目将在编译配置中自动包含此代码库。如果您使用的是之前的项目，则必须手动向您的 build.gradle 文件中添加 Google 的 Maven 代码库。\n在 SDK Platforms 标签下，您还必须安装至少一个版本的 Android 平台。每个版本均提供多种不同的软件包。要仅下载所需版本，请点击相应版本名称旁的复选框。\n要查看各 Android 平台的所有可用软件包，请点击窗口底部的 Show Package Details。各版本的平台中均提供以下软件包：\nAndroid SDK Platform 必选。 您的开发环境中必须至少有一个平台，这样您才能编译应用。为了在最新设备上提供最佳用户体验，请使用最新版本的平台作为编译目标。您的应用仍然可以在旧版系统上运行，但您必须以最新版本为目标编译应用，以便在安装最新版 Android 的设备上运行应用时能够使用新功能。 Intel 或 ARM 系统映像 推荐。运行 Android Emulator 需要系统映像。每个版本的平台均包含受支持的系统映像。您也可以之后在从 AVD Manager 创建 Android 虚拟设备 (AVD) 时下载系统映像。根据开发计算机的处理器选择 Intel 或 ARM。 注意：如果您计划使用 Google Play 服务（包括 Firebase）的 API，则必须使用 Google API 系统映像或 Google Play 系统映像（后者包括 Play 商店应用）。\n以上列表并不详尽，您可以添加其他网站，以便从第三方网站下载更多软件包。\n在某些情况下，某个 SDK 软件包可能需要另一个工具的特定最低修订版。如果存在这种情况，SDK 管理器将发出警告通知您，并将依赖项添加到您的下载列表。\n提示：您还可以自定义 build.gradle 文件，使每个项目均使用特定的编译链和编译选项。如需了解详情，请参阅配置 Gradle 编译。\n修改或添加 SDK 工具网站 要管理 Android Studio 用于检查 Android 工具和第三方工具更新的 SDK 网站，请点击 SDK Update Sites 标签。您可以添加其他提供自有工具的网站，然后从这些网站下载软件包。\n例如，某个移动运营商或设备制造商可能会为其自有基于 Android 系统的设备提供额外的 API 库。要使用他们的库开发应用，您可以在 SDK Update Sites 标签中将其 SDK 工具网址添加到 SDK 管理器，以安装他们的 Android SDK 软件包。\n如果运营商或设备制造商在其网站上提供了 SDK 附加项代码库文件，请按照以下步骤将其网站添加到 Android SDK 管理器：\n点击 SDK Update Sites 标签。 点击窗口底部的 Add 。 输入第三方网站的名称和网址，然后点击 OK。 确保已选中 Enabled 列中相应的复选框。 点击 Apply 或 OK。 该网站提供的所有 SDK 软件包都将视情况显示在 SDK Platforms 或 SDK Tools 标签中。\nGradle 自动下载缺失软件包 在从命令行运行编译或者使用 Android Studio 3.3 或更高版本时，只要已经使用 SDK 管理器接受了相应的 SDK 许可协议，Gradle 就会自动下载项目依赖的缺失 SDK 软件包。\n在您使用 SDK 管理器接受许可协议后，Android Studio 会在 SDK 主目录内部创建 licenses 目录。此 licenses 目录是 Gradle 自动下载缺失软件包所必需的。\n注意：使用 android 命令行工具接受许可协议不会创建此 licenses 目录。您必须先使用 SDK 管理器接受协议才能够使用此功能。\n如果您已经在一个工作站上接受许可协议，但希望在另一个工作站上编译项目，则可以通过复制已接受的 licenses 目录来导出 licenses。要将 licenses 复制到另一台计算机，请按以下步骤执行操作：\n在安装了 Android Studio 的计算机上，依次点击 Tools \u0026gt; Android \u0026gt; SDK Manager。在窗口顶部，记下 Android SDK Location。 转到该目录，并在此目录下找到 licenses/ 目录（如果您没有看到 licenses/ 目录，请返回到 Android Studio 并更新 SDK 工具，确保接受许可协议。返回到 Android SDK 主目录后，您现在应该会看到该目录）。 复制整个 licenses/ 目录，并将其粘贴到您希望编译项目所用计算机上的 Android SDK 主目录中。 Gradle 现在会自动下载项目依赖的缺失软件包。\n请注意，对于从 Android Studio 运行的编译，此功能自动处于停用状态，因为 SDK 管理器会处理 IDE 缺失软件包的下载任务。您还可以手动停用此功能，方法是在项目的 gradle.properties 文件中设置 android.builder.sdkDownload=false。\neumlator 命令行启动 https://developer.android.com/studio/run/emulator-commandline\n原文 https://developer.android.com/studio/intro/update\n","date":"2020-02-24","permalink":"http://localhost:1313/posts/20200224-android-studio-preview/","section":"","summary":"","tags":["",""],"title":"Android Studio preview"},{"categories":[],"contents":" Any way to remove the black box behind the emulator? Should run a compositor, something like compton Should try to use xprop WM_CLASS\nFor the border, likely a compositor is needed or you can start the AVD without a device frame.\nFor making it floating, add this to your config Floating all windows with \u0026ldquo;android emulator\u0026rdquo; header:\nfor_window [title=\u0026#34;.*Emulator.*\u0026#34;] floating enable ","date":"2020-02-24","permalink":"http://localhost:1313/posts/20200224-android-studio-emulator-ugly-black-borders/","section":"","summary":"","tags":["","",""],"title":"Android Studio emulator ugly black borders"},{"categories":[],"contents":"总有人问我 Vim 中能不能查找，当然能！而且是超级强的查找！ 这篇文章来详细介绍 Vim 中查找相关的设置和使用方法。 包括查找与替换、查找光标所在词、高亮前景/背景色、切换高亮状态、大小写敏感查找等。\n查找 在normal模式下按下/即可进入查找模式，输入要查找的字符串并按下回车。 Vim会跳转到第一个匹配。按下n查找下一个，按下N查找上一个。\nVim查找支持正则表达式，例如/vim$匹配行尾的\u0026quot;vim\u0026quot;。 需要查找特殊字符需要转义，例如/vim$匹配\u0026quot;vim$\u0026quot;。\n注意查找回车应当用\\n，而替换为回车应当用\\r（相当于）。\n大小写敏感查找 在查找模式中加入\\c表示大小写不敏感查找，\\C表示大小写敏感查找。例如：\n/foo\\c 将会查找所有的\u0026quot;foo\u0026quot;,\u0026ldquo;FOO\u0026rdquo;,\u0026ldquo;Foo\u0026quot;等字符串。\n大小写敏感配置 Vim 默认采用大小写敏感的查找，为了方便我们常常将其配置为大小写不敏感：\n\u0026quot; 设置默认进行大小写不敏感查找 set ignorecase \u0026quot; 如果有一个大写字母，则切换到大小写敏感查找 set smartcase 将上述设置粘贴到你的~/.vimrc，重新打开Vim即可生效。\n查找当前单词 在normal模式下按下*即可查找光标所在单词（word）， 要求每次出现的前后为空白字符或标点符号。例如当前为foo， 可以匹配foo bar中的foo，但不可匹配foobar中的foo。 这在查找函数名、变量名时非常有用。\n按下g*即可查找光标所在单词的字符序列，每次出现前后字符无要求。 即foo bar和foobar中的foo均可被匹配到。\n其他设置 :set incsearch 可以在敲键的同时搜索，按下回车把移动光标移动到匹配的词； 按下 Esc 取消搜索。\n:set wrapscan 用来设置到文件尾部后是否重新从文件头开始搜索。\n查找与替换 :s（substitute）命令用来查找和替换字符串。语法如下：\n:{作用范围}s/{目标}/{替换}/{替换标志} 例如:%s/foo/bar/g会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）。\n作用范围 作用范围分为当前行、全文、选区等等。\n当前行：\n:s/foo/bar/g 全文：\n:%s/foo/bar/g 选区，在Visual模式下选择区域后输入:，Vim即可自动补全为 :\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;。\n:\u0026rsquo;\u0026lt;,\u0026rsquo;\u0026gt;s/foo/bar/g 2-11行：\n:5,12s/foo/bar/g 当前行.与接下来两行+2：\n:.,+2s/foo/bar/g 替换标志 上文中命令结尾的g即是替换标志之一，表示全局global替换（即替换目标的所有出现）。 还有很多其他有用的替换标志：\n空替换标志表示只替换从光标位置开始，目标的第一次出现：\n:%s/foo/bar i表示大小写不敏感查找，I表示大小写敏感：\n:%s/foo/bar/i\n等效于模式中的\\c（不敏感）或\\C（敏感） :%s/foo\\c/bar c表示需要确认，例如全局查找\u0026quot;foo\u0026quot;替换为\u0026quot;bar\u0026quot;并且需要确认：\n:%s/foo/bar/gc 回车后Vim会将光标移动到每一次\u0026quot;foo\u0026quot;出现的位置，并提示\nreplace with bar (y/n/a/q/l/^E/^Y)? 按下y表示替换，n表示不替换，a表示替换所有，q表示退出查找模式， l表示替换当前位置并退出。^E与^Y是光标移动快捷键，参考： Vim中如何快速进行光标移动。\n高亮设置 高亮颜色设置 如果你像我一样觉得高亮的颜色不太舒服，可以在 ~/.vimrc 中进行设置：\nhighlight Search ctermbg=yellow ctermfg=black highlight IncSearch ctermbg=black ctermfg=yellow highlight MatchParen cterm=underline ctermbg=NONE ctermfg=NONE 上述配置指定 Search 结果的前景色（foreground）为黑色，背景色（background）为灰色； 渐进搜索的前景色为黑色，背景色为黄色；光标处的字符加下划线。\n更多的CTERM颜色可以查阅：http://vim.wikia.com/wiki/Xterm256_color_names_for_console_Vim\n禁用/启用高亮 有木有觉得每次查找替换后 Vim 仍然高亮着搜索结果？ 可以手动让它停止高亮，在normal模式下输入：\n:nohighlight \u0026quot; 等效于 :nohl 其实上述命令禁用了所有高亮，只禁用搜索高亮的命令是:set nohlsearch。 下次搜索时需要:set hlsearch再次启动搜索高亮。\n延时禁用 怎么能够让Vim查找/替换后一段时间自动取消高亮，发生查找时自动开启呢？\n\u0026quot; 当光标一段时间保持不动了，就禁用高亮 autocmd cursorhold * set nohlsearch \u0026quot; 当输入查找命令时，再启用高亮 noremap n :set hlsearchn noremap N :set hlsearchN noremap / :set hlsearch/ noremap ? :set hlsearch? noremap * *:set hlsearch 将上述配置粘贴到~/.vimrc，重新打开vim即可生效。\n一键禁用 如果延时禁用搜索高亮仍然不够舒服，可以设置快捷键来一键禁用/开启搜索高亮：\nnoremap n :set hlsearchn noremap N :set hlsearchN noremap / :set hlsearch/ noremap ? :set hlsearch? noremap * *:set hlsearch\nnnoremap :call DisableHighlight() function! DisableHighlight() set nohlsearch endfunc 希望关闭高亮时只需要按下 Ctrl+H，当发生下次搜索时又会自动启用。\n参考阅读 XTERM 256色：http://vim.wikia.com/wiki/Xterm256_color_names_for_console_Vim Vim Wikia - 查找与替换：http://vim.wikia.com/wiki/Search_and_replace 用 Vim 打造 IDE 环境：https://harttle.land/2015/11/04/vim-ide.html\n","date":"2020-02-24","permalink":"http://localhost:1313/posts/20200224-vim-search-in-file/","section":"","summary":"","tags":["","",""],"title":"Vim_search_in_file"},{"categories":[],"contents":"百度云加速NS接入是最简单的方式，不过还是很多站长管理员不大懂，今天教大家如何NS接入。\n首先点域名继续接入 添加子域名，A记录、主机名: WWW，记录值写你的服务器的IP，如果你有其它子域名的也一并添加创建。 创建完子域名后，点一步，查看云加速DNS 复制加速DNS n3060.ns.yunjiasu.com、n333.ns.yunjiasu.com 进入域名注册商管理处，修改NS记录，比如阿里云 修改完成后，等生效即可。需要注意的是，域名修改DNS一般全国生效为24小时左右，所以需要耐心等待了。\n好了以上就是百度云加速NS接入的全部教程了，希望可以帮到大家。\n","date":"2020-02-23","permalink":"http://localhost:1313/posts/20200223-baidu-cdn/","section":"","summary":"","tags":["","",""],"title":"百度云加速NS接入流程"},{"categories":[],"contents":"Emptying the buffers cache If you ever want to empty it you can use this chain of commands.\nfree \u0026amp;\u0026amp; sync \u0026amp;\u0026amp; echo 3 \u0026gt; /proc/sys/vm/drop_caches \u0026amp;\u0026amp; free total used free shared buffers cached Mem: 1018916 980832 38084 0 46924 355764 -/+ buffers/cache: 578144 440772 Swap: 2064376 128 2064248 total used free shared buffers cached Mem: 1018916 685008 333908 0 224 108252 -/+ buffers/cache: 576532 442384 Swap: 2064376 128 2064248 You can signal the Linux Kernel to drop various aspects of cached items by changing the numeric argument to the above command.\nTo free pagecache:\necho 1 \u0026gt; /proc/sys/vm/drop_caches To free dentries and inodes:\necho 2 \u0026gt; /proc/sys/vm/drop_caches To free pagecache, dentries and inodes:\necho 3 \u0026gt; /proc/sys/vm/drop_caches The above are meant to be run as root. If you\u0026rsquo;re trying to do them using sudo then you\u0026rsquo;ll need to change the syntax slightly to something like these:\n$ sudo sh -c \u0026#39;echo 1 \u0026gt;/proc/sys/vm/drop_caches\u0026#39; $ sudo sh -c \u0026#39;echo 2 \u0026gt;/proc/sys/vm/drop_caches\u0026#39; $ sudo sh -c \u0026#39;echo 3 \u0026gt;/proc/sys/vm/drop_caches\u0026#39; NOTE: There\u0026rsquo;s a more esoteric version of the above command if you\u0026rsquo;re into that:\n$ echo \u0026#34;echo 1 \u0026gt; /proc/sys/vm/drop_caches\u0026#34; | sudo sh Why the change in syntax? The /bin/echo program is running as root, because of sudo, but the shell that\u0026rsquo;s redirecting echo\u0026rsquo;s output to the root-only file is still running as you. Your current shell does the redirection before sudo starts.\nSeeing what\u0026rsquo;s in the buffers and cache Take a look at linux-ftools if you\u0026rsquo;d like to analyze the contents of the buffers \u0026amp; cache. Specifically if you\u0026rsquo;d like to see what files are currently being cached.\nfincore # With this tool you can see what files are being cached within a give directory. fincore [options] files... --pages=false Do not print pages --summarize When comparing multiple files, print a summary report --only-cached Only print stats for files that are actually in cache. For example, /var/lib/mysql/blogindex: root@xxxxxx:/var/lib/mysql/blogindex## fincore --pages=false --summarize --only-cached * stats for CLUSTER_LOG_2010_05_21.MYI: file size=93840384 , total pages=22910 , cached pages=1 , cached size=4096, cached perc=0.004365 stats for CLUSTER_LOG_2010_05_22.MYI: file size=417792 , total pages=102 , cached pages=1 , cached size=4096, cached perc=0.980392 stats for CLUSTER_LOG_2010_05_23.MYI: file size=826368 , total pages=201 , cached pages=1 , cached size=4096, cached perc=0.497512 stats for CLUSTER_LOG_2010_05_24.MYI: file size=192512 , total pages=47 , cached pages=1 , cached size=4096, cached perc=2.127660 stats for CLUSTER_LOG_2010_06_03.MYI: file size=345088 , total pages=84 , cached pages=43 , cached size=176128, cached perc=51.190476 stats for CLUSTER_LOG_2010_06_04.MYD: file size=1478552 , total pages=360 , cached pages=97 , cached size=397312, cached perc=26.944444 stats for CLUSTER_LOG_2010_06_04.MYI: file size=205824 , total pages=50 , cached pages=29 , cached size=118784, cached perc=58.000000 stats for COMMENT_CONTENT_2010_06_03.MYI: file size=100051968 , total pages=24426 , cached pages=10253 , cached size=41996288, cached perc=41.975764 stats for COMMENT_CONTENT_2010_06_04.MYD: file size=716369644 , total pages=174894 , cached pages=79821 , cached size=326946816, cached perc=45.639645 stats for COMMENT_CONTENT_2010_06_04.MYI: file size=56832000 , total pages=13875 , cached pages=5365 , cached size=21975040, cached perc=38.666667 stats for FEED_CONTENT_2010_06_03.MYI: file size=1001518080 , total pages=244511 , cached pages=98975 , cached size=405401600, cached perc=40.478751 stats for FEED_CONTENT_2010_06_04.MYD: file size=9206385684 , total pages=2247652 , cached pages=1018661 , cached size=4172435456, cached perc=45.321117 stats for FEED_CONTENT_2010_06_04.MYI: file size=638005248 , total pages=155763 , cached pages=52912 , cached size=216727552, cached perc=33.969556 stats for FEED_CONTENT_2010_06_04.frm: file size=9840 , total pages=2 , cached pages=3 , cached size=12288, cached perc=150.000000 stats for PERMALINK_CONTENT_2010_06_03.MYI: file size=1035290624 , total pages=252756 , cached pages=108563 , cached size=444674048, cached perc=42.951700 stats for PERMALINK_CONTENT_2010_06_04.MYD: file size=55619712720 , total pages=13579031 , cached pages=6590322 , cached size=26993958912, cached perc=48.533080 stats for PERMALINK_CONTENT_2010_06_04.MYI: file size=659397632 , total pages=160985 , cached pages=54304 , cached size=222429184, cached perc=33.732335 stats for PERMALINK_CONTENT_2010_06_04.frm: file size=10156 , total pages=2 , cached pages=3 , cached size=12288, cached perc=150.000000 --- total cached size: 32847278080 With the above output you can see that there are several *.MYD, *.MYI, and *.frm files that are currently being cached. Swap If you want to clear out your swap you can use the following commands.\n$ free total used free shared buffers cached Mem: 7987492 7298164 689328 0 30416 457936 -/+ buffers/cache: 6809812 1177680 Swap: 5963772 609452 5354320 Then use this command to disable swap:\n$ swapoff -a You can confirm that it\u0026rsquo;s now empty:\n$ free total used free shared buffers cached Mem: 7987492 7777912 209580 0 39332 489864 -/+ buffers/cache: 7248716 738776 Swap: 0 0 0 And to re-enable it:\n$ swapon -a And now reconfirm with free:\n$ free total used free shared buffers cached Mem: 7987492 7785572 201920 0 41556 491508 -/+ buffers/cache: 7252508 734984 Swap: 5963772 0 5963772 ","date":"2020-02-16","permalink":"http://localhost:1313/posts/20200216-how-do-you-empty-the-buffers-and-cache-on-linux-system/","section":"","summary":"","tags":[""],"title":"linux中如何手动清零缓冲"},{"categories":[],"contents":"玩虚拟机的同学都知道，对于那些设定为动态配分的虚拟机，一开始装完系统时可能只有几个G，但是随着你不断的使用，体积空间就会越来越大，随便就是几十个G了。也就是说动态扩展的VDI文件只会大，不会小。这期间，就算你去虚拟机里面删除一些文件，整个虚拟机的镜像文件VDI文件的大小依然不会变小，使其所占用的实际硬盘空间过大，给备份和分享都带来麻烦。因此，今天我们就来研究一下如何解决这个问题，其实很简单。\n以下方法，在我自己的64位Ubuntu 14.04和64位win10虚拟机中亲测有效！\n步骤1：碎片整理 第一步要做的是碎片整理，整理过程需要一个特定的工具，win系统和linux系统各自有别：\n1、linux系统下 打开虚拟机，执行下面的命令：\nsudo dd if=/dev/zero of=/free bs=1M sudo rm -f /free 一般来说，大约5-10分钟清理完毕，取决于你的系统大小和磁盘空间混乱程度。于是关闭虚拟机，进入下一步。\n2、win系统下 需要下载一个特定的工具，点击此处进入官方下载，如果链接失效，也可以点击此处直接下载我整理好的版本。\n下载后解压，取出其中的diskext.exe（针对32位系统）或者diskext64.exe（针对64位系统），将其复制到虚拟机的C盘根目录下，然后以管理员身份在虚拟机中启动命令行cmd，输入以下命令：\nC:\\sdelete64.exe -z c:\t# c表示清理c盘 便会自动开始清理磁盘，大约5-10分钟左右方能清理完毕，于是便可关闭虚拟机，进入下一步。\n步骤2：镜像压缩 关闭虚拟机，然后通过Virtualbox自带的神器vboxmanage modifyhd中的–compact命令来进行VDI镜像文件的压缩。具体步骤是：\n打开cmd命令窗口，并进入Virtualbox所安装的目录（一般是C:\\Program Files\\Oracle\\VirtualBox）目录，然后启动VBoxManage.exe进行VDI镜像文件的压缩，并等待命令结束即可：\ncd \u0026#34;C:\\Program Files\\Oracle\\VirtualBox\u0026#34; VBoxManage.exe modifyhd \u0026#34;E:\\V_VtSystem\\A_Systems\\Ubuntu 14.04.vdi\u0026#34; --compact 实际测试我ubuntu系统由35G压缩成只有20G，win10系统由40G压缩成25G，效果还是非常明显的。\n","date":"2020-02-16","permalink":"http://localhost:1313/posts/20200216-virtualbox-vdi-shrink/","section":"","summary":"","tags":["",""],"title":"如何清理Virtualbox虚拟机VDI镜像文件的空间大小"},{"categories":[],"contents":"systemd-analyze简介 systemd-analyze是Linux自带的分析系统启动性能的工具。\nsystemd-analyze可使用的命令：\nsystemd-analyze [OPTIONS…] [time]\nsystemd-analyze [OPTIONS…] blame\nsystemd-analyze [OPTIONS…] critical-chain [UNIT…]\nsystemd-analyze [OPTIONS…] plot [\u0026gt; file.svg]\nsystemd-analyze [OPTIONS…] dot [PATTERN…] [\u0026gt; file.dot]\nsystemd-analyze [OPTIONS…] dump\nsystemd-analyze [OPTIONS…] set-log-level LEVEL\nsystemd-analyze [OPTIONS…] set-log-target TARGET\nsystemd-analyze [OPTIONS…] get-log-level\nsystemd-analyze [OPTIONS…] get-log-target\nsystemd-analyze [OPTIONS…] syscall-filter [SET…]\nsystemd-analyze [OPTIONS…] verify [FILES…]\nsystemd-analyze命令具体含义：\nsystemd-analyze 可以显示系统启动过程中的性能统计数据、 获取 systemd 系统管理器的状态与跟踪信息、 校验单元文件的正确性。\nsystemd-analyze time 可以显示如下时间： (1)在启动第一个用户态进程(init)之前，内核运行了多长时间； (2)在切换进入实际的根文件系统之前，initrd(initial RAM disk)运行了多长时间； (3)进入实际的根文件系统之后，用户空间启动完成花了多长时间。 注意，上述时间只是简单的计算了系统启动过程中到达不同标记点的时间， 并没有计入各单元实际启动完成所花费的时间以及磁盘空闲的时间。\nsystemd-analyze blame 按照每个单元花费的启动时间从多到少的顺序，列出所有当前正处于活动(active)状态的单元。 这些信息有助于用户优化系统启动速度。 不过需要注意的是，这些信息也可能具有误导性， 因为花费较长时间启动的单元，有可能只是在等待另一个依赖单元完成启动。 systemd-analyze critical-chain [UNIT…] 为指定的单元(省略参数表示默认启动目标单元)以树状形式显示时间关键链(time-critical chain)。 “@”后面的时刻表示该单元的启动时刻； “+”后面的时长表示该单元总计花了多长时间才完成启动。 不过需要注意的是， 这些信息也可能具有误导性， 因为花费较长时间启动的单元， 有可能只是在等待另一个依赖单元完成启动。\nsystemd-analyze plot 输出一个 SVG 图像，详细显示每个单元的启动时刻， 并高亮显示每个单元总计花了多长时间才完成启动。 systemd-analyze dot 按照 GraphViz dot(1) 格式输出单元间的依赖关系图。 在实践中，通常使用 systemd-analyze dot | dot -Tsvg \u0026gt; systemd.svg 命令来最终生成描述单元间依赖关系的 SVG 图像。 除非使用了 –order 或 –require 选项限定仅显示特定类型的依赖关系， 否则将会显示所有的依赖关系。如果指定了至少一个 PATTERN 参数(例如 *.target 这样的 shell 匹配模式)， 那么将会仅显示所有匹配这些模式的单元的直接依赖关系。\nsystemd-analyze dump 按照人类易读的格式输出全部单元的状态(一般都有几千数万行)。 因为它的输出格式经常在未通知的情况下发生变化， 所以切勿将此输出用于程序分析。\nsystemd-analyze set-log-level LEVEL 将 systemd 守护进程的日志等级更改为 LEVEL (可使用的值参见 systemd(1) 的 –log-level= 选项)\nsystemd-analyze set-log-target TARGET 将 systemd 守护进程的日志目标更改为 TARGET (可使用的值参见 systemd(1) 的 –log-target= 选项)\nsystemd-analyze get-log-level 打印出 systemd 守护进程当前的日志等级。\nsystemd-analyze get-log-target 打印出 systemd 守护进程当前的日志目标。\nsystemd-analyze syscall-filter [SET…] 如果指定了至少一个 SET 参数，那么仅显示指定的集合所包含的系统调用列表； 否则显示全部系统调用集合的详情。注意，必须在 SET 参数中包含 “@” 前缀。\nsystemd-analyze verify 校验指定的单元文件以及被指定的单元文件引用的其他单元文件的正确性，并显示发现的错误。 FILES 参数可以是单元文件的精确路径(带有上级目录)，也可以仅仅是单元文件的名称(没有目录前缀)。 对于那些仅给出了文件名(没有目录前缀)的单元，将会优先在其他已经给出精确路径的单元文件的所在目录中搜索， 如果没有找到，将会继续在常规的单元目录中搜索(详见unit(5) 手册)。 可以使用 $SYSTEMD_UNIT_PATH 环境变量来更改默认的单元搜索目录。\n如果没指定任何命令，那么等价于使用 systemd-analyze time 命令。\nsystemd-analyze实战 ➜~ systemd-analyze Startup finished in 3.220s (kernel) + 23.420s (userspace) = 26.641s graphical.target reached after 23.111s in userspace 可以看到开机用了23秒以上。接下来查询下这锅应该谁背：\n➜~ systemd-analyze blame 21.594s NetworkManager-wait-online.service 680ms systemd-logind.service 587ms lvm2-monitor.service 570ms lightdm.service 534ms dev-sdc2.device 371ms upower.service 309ms tlp.service 292ms systemd-timesyncd.service 260ms systemd-udevd.service 252ms ModemManager.service 217ms systemd-journald.service 131ms systemd-journal-flush.service 121ms boot-efi.mount 117ms avahi-daemon.service 115ms bluetooth.service 111ms polkit.service 111ms NetworkManager.service 110ms udisks2.service 102ms systemd-modules-load.service 可以看到NetworkManager-wait-online.service耗时 最长，花了21秒。这里的记时有可能是等待其他服务器启动的，再来看看其关联服务的启动时间：\n➜ ~ systemd-analyze critical-chain NetworkManager-wait-online.service The time when unit became active or started is printed after the \u0026#34;@\u0026#34; character. The time the unit took to start is printed after the \u0026#34;+\u0026#34; character. NetworkManager-wait-online.service +21.594s └─NetworkManager.service @1.398s +111ms └─dbus.service @1.390s └─basic.target @1.389s └─sockets.target @1.389s └─dbus.socket @1.389s └─sysinit.target @1.384s └─systemd-backlight@backlight:intel_backlight.service @1.313s +71ms └─system-systemd\\x2dbacklight.slice @1.312s └─system.slice @207ms └─-.slice @207ms 可这一看到这里它在等待其他的服务，但是也没有花21秒怎么多。\n发现了影响启动的服务，最简单的方式是禁用此服务：\n➜ ~ sudo systemctl disable NetworkManager-wait-online.service 方案二：编辑/lib/systemd/system/NetworkManager-wait-online.service文件，将文件中的\n[Service] Type=oneshot ExecStart=/usr/bin/nm-online -s -q --timeout=30 超时时间由30改为10\n另外，我们来看下还有哪些开机启动的服务可被优化：\n➜ ~ systemctl list-unit-files --type=service | grep enabled autovt@.service enabled avahi-daemon.service enabled bluetooth.service enabled bumblebeed.service enabled cronie.service enabled dbus-org.bluez.service enabled dbus-org.freedesktop.Avahi.service enabled dbus-org.freedesktop.ModemManager1.service enabled dbus-org.freedesktop.NetworkManager.service enabled dbus-org.freedesktop.nm-dispatcher.service enabled dbus-org.freedesktop.timesync1.service enabled display-manager.service enabled getty@.service enabled lightdm.service enabled ModemManager.service enabled NetworkManager-dispatcher.service enabled NetworkManager.service enabled org.cups.cupsd.service enabled systemd-fsck-root.service enabled-runtime systemd-remount-fs.service enabled-runtime systemd-timesyncd.service enabled tlp-sleep.service enabled tlp.service enabled ufw.service enabled 相关服务对应的功能：\nNetworkManager-wait-online.service：网络服务管理器，禁用后不影响正常的网络使用 autovt@.service：登陆相关 保留 avahi-daemon.service：让程序自动发现本地网络服务。除非你有兼容的设备或使用 zeroconf 协议的服务，否则应该关闭它。 service：蓝牙服务，如果使用也可以禁用 service：显卡驱动，保留 service：预定日程和时间触发事件的守护进程。保留 dbus-org.bluez.service：蓝牙守护进程，可禁止 dbus-org.freedesktop.Avahi.service：让程序自动发现本地网络服务。除非你有兼容的设备或使用 zeroconf 协议的服务，否则应该关闭它。 dbus-org.freedesktop.ModemManager1.service：用于提供移动宽频broadband（2G/3G/4G）接口。可禁用 dbus-org.freedesktop.NetworkManager.service：桌面网卡管理可禁用 dbus-org.freedesktop.nm-dispatcher.service：网卡守护进程，可禁用 dbus-org.freedesktop.timesync1.service：时间同步，可禁用 display-manager.service： 用来管理显示的生命周期，它决定如何根据当前连接的物理显示设备控制其逻辑显示，保留 getty@.service enabled：tty控制台相关，保留 service enabled：图形化界面显示，保留 service： 被 dbus 激活的守护进程，用于提供移动宽频broadband（2G/3G/4G）接口。可禁用 NetworkManager-dispatcher.service：网卡守护进程，可禁用 service：检测网络、自动连接网络的程序。建议保留 cups.cupsd.service：通用UNIX打印系统守护进程.，可禁用 systemd-fsck-root.service：负责对根文件系统进行检查，建议保留 systemd-remount-fs.service：在系统启动早期启动的服务，它会根据 fstab(5) 中设置的挂载选项，重新挂载根目录与 /usr 目录， 以及虚拟文件系统。这是一个必需的动作， 因为这些文件系统在能够读取 /etc/fstab 文件之前，就已经被预先挂载了， 例如在初始内存盘(initial RAM disk)中挂载、或在进入容器环境前挂载。保留 systemd-timesyncd.service：跨网络同步系统时钟的守护服务，可禁用 tlp-sleep.service：电池优化，电源管理，建议保留 service：电池优化，电源管理，建议保留 service： 防火墙服务，建议保留 ","date":"2020-02-16","permalink":"http://localhost:1313/posts/20200216-systemd-analyze/","section":"","summary":"","tags":[""],"title":"使用systemd-analyze优化系统启动时间"},{"categories":[],"contents":"What happens? [...effects] has been deprecated in favor of all([...effects]), please update your code it does not effect dva.js, its redux saga api update, you just need to do this\neffects: { * query(action, {call, put, all}) { yield all([]) } } Redux saga apis: ","date":"2020-02-15","permalink":"http://localhost:1313/posts/20200215-saga-deprecated-warning/","section":"","summary":"","tags":["","","",""],"title":"Saga deprecated 警告"},{"categories":[],"contents":"Visual Studio Code 提供了极大的弹性让我们自订想要的编辑器样式，端看使用者设定（User Setting）中，就超过 800 项设定可以让开发者自由调整，而且还有扩充套件能够增强 VS Code 的开发能力。\n这篇主要是我个人偏好的设定，完整 setting.json 请参考 gist。\n首先可以使用快速键 Ctrl +, 开启 settings.json 使用者设定档，或从选单列中点选档案 \u0026gt; 喜好设定 \u0026gt; 设定。\nGlobal 常用设定 editor editor.fontFamily // 设定字型偏好 唯一选择 Source Code Pro 连字符号字型可选择 FiraCode 或 Hasklig 择一使用(个人偏好 FiraCode) 设定值：\u0026quot;editor.fontFamily\u0026quot;: \u0026quot;'Fira Code', 'Source Code Pro', Consolas, 'Microsoft JhengHei', 'Courier New', monospace\u0026quot;, \u0026#34;editor.fontLigatures\u0026#34;: true // 开启连字符号 // FiraCode 字型有提供连字符号的功能，例如 =\u0026gt; 会变成箭头符号 \u0026#34;editor.formatOnSave\u0026#34;: false /* 存档时不进行自动排版 - 可用 Alt + Shift + F 手动执行自动排版*/ \u0026#34;editor.minimap.enabled\u0026#34;: true // 在捲轴上开启 MiniMap 功能 \u0026#34;editor.minimap.renderCharacters\u0026#34;: false // MiniMap 不渲染实际字元 \u0026#34;editor.renderWhitespace\u0026#34;: \u0026#34;boundary\u0026#34; // 显示空白字元 \u0026#34;editor.renderIndentGuides\u0026#34;: true // 显示缩排线 \u0026#34;editor.wordWrap\u0026#34;: \u0026#34;on\u0026#34; // 断行显示 files \u0026#34;files.autoSave\u0026#34;: \u0026#34;onWindowChange\u0026#34; // 离开视窗焦点时自动储存 \u0026#34;files.autoGuessEncoding\u0026#34;: true /* 猜测档案编码 - 解决 VS Code 不支援判读档案是 ASCII 编码的问题*/ \u0026#34;files.defaultLanguage\u0026#34;: \u0026#34;markdown\u0026#34; // 设定预设文件语言类型,想要把 VS Code 当作预设的 Markdown 编辑器，一定不能错过这个设定 \u0026#34;files.insertFinalNewline\u0026#34;: true // 新增一行作为档案结束 开发 Python 时建议开启(PEP 8) others \u0026#34;explorer.openEditors.visible\u0026#34;: 0 // 设定已开启的编辑器预设是否显示 已经有「页籤」可以看已开启的档案，用 Ctrl+E 也可以快速找档案，这个功能想的多馀，建议设成 0 关闭他 terminal.integrated.shell.windows 指定使用哪种终端机\nCMD \u0026ldquo;C:\\Windows\\sysnative\\cmd.exe\u0026rdquo; PowerShell \u0026ldquo;C:\\Windows\\sysnative\\WindowsPowerShell\\v1.0\\powershell.exe\u0026rdquo; Bash on Ubuntu \u0026ldquo;C:\\Windows\\sysnative\\bash.exe\u0026rdquo; \u0026#34;window.titleBarStyle\u0026#34;: \u0026#34;custom\u0026#34; // 让你的 VSCode 变得漂亮一点 :) git \u0026#34;git.autofetch\u0026#34;: true // 让 VSCode 在背景自动执行 git fetch \u0026#34;git.enableSmartCommit\u0026#34;: true // 如果所有变更都还没有 git add ( Stage ) 的话，预设会自动全部 Commit，不会再先问过 \u0026#34;git.confirmSync\u0026#34;: false // 当要同步 Git 远端储存库时，不需要再提问 language \u0026#34;typescript.referencesCodeLens.enabled\u0026#34;: true // 开启超好用的 TypeScript 专案 Code Review 工具，CodeLens \u0026#34;typescript.updateImportsOnFileMove.enabled\u0026#34;: \u0026#34;always\u0026#34; // 当档案移动时，自动更新汇入的路径 \u0026#34;tslint.enable\u0026#34;: true // 开启 TS-Lint \u0026#34;tslint.autoFixOnSave\u0026#34;: true // 自动修复所有能修复的 TSLint 问题 \u0026#34;html.suggest.angular1\u0026#34;: false \u0026#34;html.suggest.ionic\u0026#34;: false // 不写 AngularJS 1.x 与 Ionic 的人，建议可以把内建的 Code Snippets 关闭。 extension \u0026#34;prettier.singleQuote\u0026#34;: true // 这是使用 Prettier 扩充套件一定要设定的 Workspace 常用设定 我们也可以针对工作目录下做额外的设定 `files.exclude` // 排除指定档案 .spec 是前端专案常见的测试档，可藉此设定暂时隐藏，让工作目录乾淨一些 \u0026quot;files.exclude\u0026quot;: { \u0026quot;**/*.spec.*\u0026quot;: true }, Code Snippet 自订程式码片段（snippet）能够帮助我们在写程式时，快速产生程式码，加速写程式的速度。\nWindows 版，自订程式码片段的功能位置：档案 \u0026gt; 喜好设定 \u0026gt; 使用者程式码片段 自订程式码片段会放在 C:\\Users\\12258\\AppData\\Roaming\\Code\\User\\snippets Mac 版，自订程式码片段的功能位置：Code \u0026gt; 喜好设定 \u0026gt; 使用者程式码片段 程式码基本架构如下： \u0026#34;程式码片段名称\u0026#34;: { \u0026#34;prefix\u0026#34;: \u0026#34;程式码片段的缩写\u0026#34;, \u0026#34;body\u0026#34;: [ \u0026#34;程式码片段内容\u0026#34;, \u0026#34;（使用 $1 表示插入后游彪停留的位置）\u0026#34; ], \u0026#34;description\u0026#34;: \u0026#34;描述程式码片段的用途\u0026#34; } 官方说明文件请参考Creating your own Snippets。\n参考资料： Visual Studio Code User and Workspace Settings Customize VS Code - Vedio Will 保哥的 VSCode 使用者设定档\n","date":"2020-02-15","permalink":"http://localhost:1313/posts/20200215-my-vscode-config/","section":"","summary":"","tags":[""],"title":"Visual Studio Code 偏好设置"},{"categories":[],"contents":"背景 React 项目使用umi时发报：\nUncaught Invariant Violation: React.Children.only expected to receive a single React element child. The above error occurred in the component ui socket init CloseEvent {type: \u0026ldquo;close\u0026rdquo;, bubbles: false, cancelable: false, timeStamp: 1571127775342, wasClean: false, …}\n异常代码 \u0026lt;DocumentTitle title={this.renderPageTitle()}\u0026gt; \u0026lt;ContainerQuery query={query}\u0026gt; {(params: any) =\u0026gt; \u0026lt;div className={classNames(params)}\u0026gt;{layout}\u0026lt;/div\u0026gt;} \u0026lt;/ContainerQuery\u0026gt; \u0026lt;/DocumentTitle\u0026gt; DocumentTitle组件内部最外层只能接受一个元素，而代码中有多个元素，所以报错。\n解决方案 用\u0026lt;div\u0026gt;\u0026lt;/div\u0026gt;或者\u0026lt;\u0026gt;\u0026lt;/\u0026gt;在外部包裹后就OK，不再报错，页面可正常显示。\n","date":"2020-02-10","permalink":"http://localhost:1313/posts/20200210-umi-ui-bug-using-react-document-title/","section":"","summary":"","tags":["","",""],"title":"umi-ui bug using react-document-title"},{"categories":[],"contents":"git clone 不指定分支 git clone http://10.1.1.11/service/tmall-service.git git clone 指定分支 git clone -b dev_jk http://10.1.1.11/service/tmall-service.git 命令中：多了一个 -b dev-jk,这个dev_jk就是分支，http://10.1.1.11/service/tmall -service.git为源码的仓库地址\n","date":"2020-02-10","permalink":"http://localhost:1313/posts/20200210-git-clone-branch/","section":"","summary":"","tags":[""],"title":"git clone 指定分支拉代码"},{"categories":[],"contents":"React Router v5.1.0 with hooks There is a new useHistory hook in React Router \u0026gt;5.1.0 if you are using React \u0026gt;16.8.0 and functional components.\nimport { useHistory } from \u0026#34;react-router-dom\u0026#34;; function HomeButton() { const history = useHistory(); function handleClick() { history.push(\u0026#34;/home\u0026#34;); } return ( \u0026lt;button type=\u0026#34;button\u0026#34; onClick={handleClick}\u0026gt; Go home \u0026lt;/button\u0026gt; ); } React Router v4 With v4 of React Router, there are three approaches that you can take to programmatic routing within components.\nUse the withRouter higher-order component. Use composition and render a \u0026lt;Route\u0026gt; Use the context. React Router is mostly a wrapper around the history library. history handles interaction with the browser\u0026rsquo;s window.history for you with its browser and hash histories. It also provides a memory history which is useful for environments that don\u0026rsquo;t have a global history. This is particularly useful in mobile app development (react-native) and unit testing with Node.\nA history instance has two methods for navigating: push and replace. If you think of the history as an array of visited locations, push will add a new location to the array and replace will replace the current location in the array with the new one. Typically you will want to use the push method when you are navigating.\nIn earlier versions of React Router, you had to create your own history instance, but in v4 the \u0026lt;BrowserRouter\u0026gt;, \u0026lt;HashRouter\u0026gt;, and \u0026lt;MemoryRouter\u0026gt; components will create a browser, hash, and memory instances for you. React Router makes the properties and methods of the history instance associated with your router available through the context, under the router object.\nUse the withRouter higher-order component The withRouter higher-order component will inject the history object as a prop of the component. This allows you to access the pushand replace methods without having to deal with the context. import { withRouter } from \u0026#39;react-router-dom\u0026#39; // this also works with react-router-native const Button = withRouter(({ history }) =\u0026gt; ( \u0026lt;button type=\u0026#39;button\u0026#39; onClick={() =\u0026gt; { history.push(\u0026#39;/new-location\u0026#39;) }} \u0026gt; Click Me! \u0026lt;/button\u0026gt; )) Use composition and render a \u0026lt;Route\u0026gt; The \u0026lt;Route\u0026gt; component isn\u0026rsquo;t just for matching locations. You can render a pathless route and it will always match the current location. The \u0026lt;Route\u0026gt; component passes the same props as withRouter, so you will be able to access the history methods through the history prop. import { Route } from \u0026#39;react-router-dom\u0026#39; const Button = () =\u0026gt; ( \u0026lt;Route render={({ history}) =\u0026gt; ( \u0026lt;button type=\u0026#39;button\u0026#39; onClick={() =\u0026gt; { history.push(\u0026#39;/new-location\u0026#39;) }} \u0026gt; Click Me! \u0026lt;/button\u0026gt; )} /\u0026gt; ) Use the context* But you probably should not The last option is one that you should only use if you feel comfortable working with React\u0026rsquo;s context model. Although context is an option, it should be stressed that context is an unstable API and React has a section Why Not To Use Context in their documentation. So use at your own risk!\nconst Button = (props, context) =\u0026gt; ( \u0026lt;button type=\u0026#39;button\u0026#39; onClick={() =\u0026gt; { // context.history.push === history.push context.history.push(\u0026#39;/new-location\u0026#39;) }} \u0026gt; Click Me! \u0026lt;/button\u0026gt; ) // you need to specify the context type so that it // is available within the component Button.contextTypes = { history: React.PropTypes.shape({ push: React.PropTypes.func.isRequired }) } 1 and 2 are the simplest choices to implement, so for most use cases, they are your best bets.\n1、直接点击跳转页面： // 方法一： \u0026lt;a href=\u0026#34;跳转路径\u0026gt;点击跳转\u0026lt;/a\u0026gt; // 方法二： \u0026lt;Link to=\u0026#34;跳转路径\u0026#34;\u0026gt;点击跳转\u0026lt;/Link\u0026gt; 2、点击按钮之后跳转： 引入：\nimport { hashHistory } from \u0026#39;react-router\u0026#39;; // 在方法里面加入： hashHistory.push(\u0026#39;跳转路径\u0026#39;) 3、browserHistory带参数跳转 import{browserHistory}from\u0026#39;dva/router\u0026#39;; browserHistory.push(\u0026#39;/orders/orderdetail?oderId=\u0026#39;+item.order); 在router里面设置路径的时候不需要加入参数\npath:\u0026#39;orders/orderdetail\u0026#39;, 4、关于路由获取参数的问题： code Description location.pathname 设置或获取对象指定的文件名或路径。 location.href 设置或获取整个 URL 为字符串。 location.port 设置或获取与 URL 关联的端口号码。 location.protocol 设置或获取 URL 的协议部分。 location.hash 设置或获取 href 属性中在井号“#”后面的分段。 location.host 设置或获取 location 或 URL 的 hostname 和 port 号码。 location.search 设置或获取 href 属性中跟在问号后面的部分。 routerRedux路由跳转 1、不带参数跳转： dispatch(routerRedux.push({ pathname : \u0026#39;/couponDetail\u0026#39;, })) 2、带参数跳转 dispatch(routerRedux.push({ pathname : \u0026#39;/couponDetail\u0026#39;, query:要携带的参数object })) 注意：通过location.query.参数字段来获取参数值\n3、在effect里面跳转 yield put (routerRedux.replace({ pathname: \u0026#39;/domains/buy/pay\u0026#39;, query: payload })); ","date":"2020-02-09","permalink":"http://localhost:1313/posts/20200209-programmatically-navigate-using-react-router/","section":"","summary":"","tags":["",""],"title":"Programmatically_navigate_using_react_router"},{"categories":[],"contents":"npm和yarn查看源和换源： npm config get registry # 查看npm当前镜像源 npm config set registry https://registry.npm.taobao.org/ # 设置npm镜像源为淘宝镜像 yarn config get registry # 查看yarn当前镜像源 yarn config set registry https://registry.npm.taobao.org/ # 设置yarn镜像源为淘宝镜像 镜像源地址部分如下： npm --- https://registry.npmjs.org/ cnpm --- https://r.cnpmjs.org/ taobao --- https://registry.npm.taobao.org/ nj --- https://registry.nodejitsu.com/ rednpm --- https://registry.mirror.cqupt.edu.cn/ npmMirror --- https://skimdb.npmjs.com/registry/ deunpm --- http://registry.enpmjs.org/ ","date":"2020-02-06","permalink":"http://localhost:1313/posts/20200206-yarn-accelerate-and-modify-mirror-source-in-china/","section":"","summary":"","tags":["","",""],"title":"npm和yarn如何查看源和换源"},{"categories":[],"contents":"listen tcp :443: bind: permission denied If you want to bind to a privileged port (ports less than 1024). You either need to be root or have the CAP_NET_BIND_SERVICE capability.\n","date":"2020-02-05","permalink":"http://localhost:1313/posts/20200205-linux-privileged-port/","section":"","summary":"","tags":[""],"title":"Socket programing Permission denied"},{"categories":[],"contents":" 精简系统后自带的输入法不显示候选词 懒得折腾直接切换成老版本就完事，位置在输入法-设置-常规-使用以前版本的微软拼音输入法 ","date":"2020-02-05","permalink":"http://localhost:1313/posts/20200205-win10-input-method-display-candidate-words/","section":"","summary":"","tags":["",""],"title":"win10输入法不显示候选词解决方法"},{"categories":[],"contents":" 又一个酸奶：Arch Linux的一个实用程序，用于从Arch User Repository构建和安装软件包。\n另见pacman。\n从repos和AUR交互式搜索和安装包： yay {{package_name|search_term}} 同步和更新repos和AUR中的所有包： yay 仅同步和更新AUR包： yay -Sua 从repos和AUR安装新包： yay -S {{package_name}} 在包数据库中搜索repos和AUR中的关键字： yay -Ss {{keyword}} 显示已安装包和系统运行状况的统计信息： yay -Ps 2020-04-20更新\ncurl: (33) HTTP server doesn\u0026rsquo;t seem to support byte ranges. Cannot resume. 选择清空之前下载就可以\n或者执行：\nrm -rf ~/.cache/yay/* ","date":"2020-02-05","permalink":"http://localhost:1313/posts/20200205-linux-yay/","section":"","summary":"","tags":["",""],"title":"Linux yay 命令"},{"categories":[],"contents":"IPv6被认为是IPv4的替代产品，它用来解决现有IPv4地址空间即将耗尽的问题。 但目前，开启IPv6可能会导致一些问题。因此有时我们需要关闭IPv6。 下面是IPv6的关闭方法应该适用于所有主流的Linux发行版包括Ubuntu、Debian、CentOS。\nIPv6在CentOS6.5系统中默认是启用状态，通过以下方式可以确认IPv6的状态\n1.1.查看系统IPv6的启用状态 以下命令返回值为0表示IPv6启用，1表示禁用\ncat /proc/sys/net/ipv6/conf/all/disable_ipv6 cat /proc/sys/net/ipv6/conf/default/disable_ipv6 ifconfig ip address list netstat -anptl 1.2.查看内核模块调用 有返回结果，说明IPv6模块已启用，可以看出那些程序进行了调用，反之没有启用\nlsmod | grep ipv6\n2.禁用IPv6 2.1.临时禁用IPv6 命令行调整内核参数，临时禁用IPv6\necho 1 \u0026gt;/proc/sys/net/ipv6/conf/all/disable_ipv6 echo 1 \u0026gt;/proc/sys/net/ipv6/conf/default/disable_ipv6 # 或着 sysctl -w net.ipv6.conf.all.disable_ipv6=1 sysctl -w net.ipv6.conf.default.disable_ipv6=1 2.2.永久禁用IPv6 echo \u0026#34; \u0026#34;\u0026gt;\u0026gt;/etc/sysctl.conf echo \u0026#34;# made for disabled IPv6 in $(date +%F)\u0026#34;\u0026gt;\u0026gt;/etc/sysctl.conf echo \u0026#39;net.ipv6.conf.all.disable_ipv6 = 1\u0026#39;\u0026gt;\u0026gt;/etc/sysctl.conf echo \u0026#39;net.ipv6.conf.default.disable_ipv6 = 1\u0026#39;\u0026gt;\u0026gt;/etc/sysctl.conf echo \u0026#39;net.ipv6.conf.lo.disable_ipv6 = 1\u0026#39;\u0026gt;\u0026gt;/etc/sysctl.conf tail -5 /etc/sysctl.conf sysctl -p netstat -anptl 也可以直接编辑系统内核配置文件\nvim /etc/sysctl.conf ------------------------------------------------------ # Made for disabled IPv6 . net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 ------------------------------------------------------- 如果想要为特定的网卡禁止IPv6，比如eth1，改为添加下面的行。 net.ipv6.conf.eth1.disable_ipv6 = 1\n注意检查修改network配置文件中的IPv6配置 vim /etc/sysconfig/network -------------------------------------- NETWORKING_IPV6=no -------------------------------------- # 注意修改ifcfg-eth0 vim /etc/sysconfig/network-scripts/ifcfg-eth0 ---------------------------------- IPV6INIT=no ---------------------------------- 2.3.拓展：禁用IPV6后，可能会导致某些服务无法启动 修改ssh配置，只监听IPv4地址 vim /etc/ssh/sshd_config ---------------------------------------- # 在第15行的前面去掉注释(#)： ListenAddress 0.0.0.0 AddressFamily inet ---------------------------------------- service sshd restart netstat -anptl 注意：inet为仅IPv4，inet6为仅IPv6，any为都支持 mysql配置问题 mysql安装后默认会监听IPv6地址，关闭IPv6后，需要编辑，在[mysqld]中添加\nvim /etc/my.cnf ---------------------------------------- bind-address=0.0.0.0 ---------------------------------------- 修改完重启mysql即可\n配置redis，监听IPv4地址 vim /usr/local/redis/conf/redis.conf ---------------------------------------- bind 127.0.0.1 ---------------------------------------- 配置memcached，监听IPv4地址 配置memcached，监听地址需要使用IP，使用localhost无法启动memcached memcached /usr/local/memcached/bin/memcached -u root -p 12001 -l 127.0.0.1 -d -P /tmp/memcached1.pid\n配置VSFTP vim /etc/vsftpd/vsftpd.conf ---------------------------------------- listen=YES listen_ipv6=NO ---------------------------------------- 配置postfix监听IPv4地址 vim /etc/postfix/main.cf ---------------------------------------- inet_interfaces = 127.0.0.1 ---------------------------------------- 配置dovecot监听IPv4地址 vim /etc/dovecot/dovecot.conf ---------------- listen * ---------------- 配置xinetd # xinetd.conf第32行修改为： vim /etc/xinetd.conf ------------------------ bind = 0.0.0.0 ------------------------ # 重新载入配置文件 service xinetd reload 以上是禁用IPv6之后可能会受到影响的程序，可以根据自己的实际情况进行配置\n3.配置启用IPv6 3.1.查看linux系统的IPv6状态 cat /proc/sys/net/ipv6/conf/all/disable_ipv6 cat /proc/sys/net/ipv6/conf/default/disable_ipv6 3.2.调整内核参数立即启用IPv6 echo 0 \u0026gt;/proc/sys/net/ipv6/conf/all/disable_ipv6 echo 0 \u0026gt;/proc/sys/net/ipv6/conf/default/disable_ipv6 # or sysctl -w net.ipv6.conf.all.disable_ipv6=0 sysctl -w net.ipv6.conf.default.disable_ipv6=0 修改完是临时的，重启失效\n3.3. 修改内核参数，启用IPv6配置 vim /etc/sysctl.conf net.ipv6.conf.all.disable_ipv6 = 0 net.ipv6.conf.default.disable_ipv6 = 0 net.ipv6.conf.lo.disable_ipv6 = 0 sysctl -p 3.4.手动调用系统ipv6内核 modprobe ipv6\n3.5.报错处理 [root@zstest ~]# modprobe ipv6 FATAL: Module off not found. 失败原因：未启用IPv6模块\n解决方法： 需要编辑配置文件，启用IPv6内核模块，在禁用状态下无法调用ipv6模块 该处理需要重启系统，启动后ipv6模块自动调用\nvim /etc/modprobe.d/disable_ipv6.conf #alias net-pf-10 off #alias ipv6 off options ipv6 disable=0 [root@zstest ~]# lsmod |grep ipv6 ipv6 335781 14 ","date":"2020-01-31","permalink":"http://localhost:1313/posts/20200131-linux-disable-ipv6/","section":"","summary":"","tags":["",""],"title":"Linux_disable_IPv6"},{"categories":[],"contents":" windows下格式化u盘很简单，要么直接右键格式化，要么进入硬盘分区去格式化。那么Linux下呢？ 其实Linux下格式化u盘也十分简单，只需要几条命令就可以了：\n查看磁盘情况 sudo fdisk -l 可以看到有一个/dev/sdb的磁盘就是我们插入的u盘了，大小为28.8GB，类型为NTFS。\n2. 删除分区 sudo fdisk /dev/sdb m # 获取帮助命令 d # 删除分区 n # 新建分区 p # 打印分区表 w # 写入分区表并退出 一定要记得最后的w命令。\n3. 格式化分区 格式化分区只需要使用mkfs.+（format）命令,例如格式化为fat格式，则在终端输入以下命令：\nsudo mkfs.vfat -L labelname /dev/sdb1 # -L命令是可选，为你的u盘重新命名 # 最后的/dev/sdb1一定要是设备名 在windows下，我们常用的格式是ntfs，但是Linux默认是不支持ntfs格式的，所以我们需要安装另一个包NTFS-3G：\nsudo pacman -S ntfs-3g sudo mkfs.ntfs -Q -L labelname /dev/sdb1 现在我们就将u盘格式化为ntfs格式了，可以轻松的在windows下使用了。\numount is too slow Are you using a 64-bit version of Linux with a lot of memory and the attached disk is a relatively slow one (any USB 2 will qualify)?\nIn that case the problem could be that Linux can locks/delay for long time on big writes on slow devices; it depends on caching too much data during writes. It\u0026rsquo;s a known bug that should be fixed in newer kernels.\nSee http://lwn.net/Articles/572911/\nWorkaround: enter a shell root (do that with care \u0026mdash; you are now root for every command)\nsudo -i and issue: echo $((16*1024*1024)) \u0026gt; /proc/sys/vm/dirty_background_bytes echo $((48*1024*1024)) \u0026gt; /proc/sys/vm/dirty_bytes If it works, you can add the two lines above to your /etc/rc.local file.\n(This is a repost of my answer in U\u0026amp;L SE).\nMemory management and tuning options in Red Hat Enterprise Linux - Red Hat Customer Portal # Will take into account highmem along with lowmem when calculating dirty_ratio and # dirty_background_ratio. This will will make page reclaiming faster # echo 1 \u0026gt; /proc/sys/vm/highmem_is_dirtyable or sysctl vm.highmem_is_dirtyable=1 writing 10240000000 bytes to: /mnt/disk1/test.dd 1107451904 bytes (1.1 GB) copied, 5.03617 s, 220 MB/s 2107810816 bytes (2.1 GB) copied, 10.0765 s, 209 MB/s 2964157440 bytes (3.0 GB) copied, 15.1043 s, 196 MB/s 3495265280 bytes (3.5 GB) copied, 20.1945 s, 173 MB/s 3585582080 bytes (3.6 GB) copied, 25.4044 s, 141 MB/s 3694973952 bytes (3.7 GB) copied, 30.3444 s, 122 MB/s 3805021184 bytes (3.8 GB) copied, 35.3244 s, 108 MB/s 3878126592 bytes (3.9 GB) copied, 40.5544 s, 95.6 MB/s 3923067904 bytes (3.9 GB) copied, 45.5843 s, 86.1 MB/s 4013892608 bytes (4.0 GB) copied, 50.5743 s, 79.4 MB/s 4122543104 bytes (4.1 GB) copied, 55.5265 s, 74.2 MB/s 4218172416 bytes (4.2 GB) copied, 60.5679 s, 69.6 MB/s 4326061056 bytes (4.3 GB) copied, 65.6173 s, 65.9 MB/s 4455662592 bytes (4.5 GB) copied, 70.9542 s, 62.8 MB/s 4554470400 bytes (4.6 GB) copied, 75.7641 s, 60.1 MB/s 4642759680 bytes (4.6 GB) copied, 81.3641 s, 57.1 MB/s 4729955328 bytes (4.7 GB) copied, 85.9541 s, 55.0 MB/s 4839564288 bytes (4.8 GB) copied, 91.154 s, 53.1 MB/s 4947799040 bytes (4.9 GB) copied, 95.8979 s, 51.6 MB/s 5031826432 bytes (5.0 GB) copied, 101.214 s, 49.7 MB/s 5147431936 bytes (5.1 GB) copied, 106.154 s, 48.5 MB/s 5258511360 bytes (5.3 GB) copied, 111.064 s, 47.3 MB/s 5366772736 bytes (5.4 GB) copied, 116.234 s, 46.2 MB/s 5476918272 bytes (5.5 GB) copied, 121.174 s, 45.2 MB/s 5559445504 bytes (5.6 GB) copied, 126.234 s, 44.0 MB/s 5654553600 bytes (5.7 GB) copied, 131.264 s, 43.1 MB/s 5719061504 bytes (5.7 GB) copied, 136.584 s, 41.9 MB/s 5720445952 bytes (5.7 GB) copied, 141.784 s, 40.3 MB/s 5811733504 bytes (5.8 GB) copied, 146.984 s, 39.5 MB/s 5903823872 bytes (5.9 GB) copied, 151.604 s, 38.9 MB/s 5995934720 bytes (6.0 GB) copied, 156.454 s, 38.3 MB/s 6085051392 bytes (6.1 GB) copied, 161.584 s, 37.7 MB/s 6179431424 bytes (6.2 GB) copied, 166.565 s, 37.1 MB/s 6252450816 bytes (6.3 GB) copied, 171.734 s, 36.4 MB/s 6352212992 bytes (6.4 GB) copied, 176.784 s, 35.9 MB/s 6454244352 bytes (6.5 GB) copied, 181.844 s, 35.5 MB/s 6579989504 bytes (6.6 GB) copied, 186.736 s, 35.2 MB/s 6678868992 bytes (6.7 GB) copied, 191.964 s, 34.8 MB/s 6772200448 bytes (6.8 GB) copied, 196.853 s, 34.4 MB/s 6878163968 bytes (6.9 GB) copied, 201.984 s, 34.1 MB/s 6960870400 bytes (7.0 GB) copied, 207.283 s, 33.6 MB/s 7039201280 bytes (7.0 GB) copied, 211.972 s, 33.2 MB/s 7140676608 bytes (7.1 GB) copied, 217.123 s, 32.9 MB/s 7234837504 bytes (7.2 GB) copied, 222.076 s, 32.6 MB/s 7328699392 bytes (7.3 GB) copied, 227.153 s, 32.3 MB/s 7436080128 bytes (7.4 GB) copied, 232.166 s, 32.0 MB/s 7513248768 bytes (7.5 GB) copied, 237.563 s, 31.6 MB/s 7634260992 bytes (7.6 GB) copied, 242.593 s, 31.5 MB/s 7724561408 bytes (7.7 GB) copied, 247.403 s, 31.2 MB/s 7835747328 bytes (7.8 GB) copied, 252.403 s, 31.0 MB/s 7902901248 bytes (7.9 GB) copied, 257.423 s, 30.7 MB/s 8018326528 bytes (8.0 GB) copied, 262.563 s, 30.5 MB/s 8135921664 bytes (8.1 GB) copied, 267.437 s, 30.4 MB/s 8216900608 bytes (8.2 GB) copied, 272.513 s, 30.2 MB/s 8301011968 bytes (8.3 GB) copied, 277.653 s, 29.9 MB/s 8368538624 bytes (8.4 GB) copied, 282.743 s, 29.6 MB/s 8453365760 bytes (8.5 GB) copied, 287.635 s, 29.4 MB/s 8548049920 bytes (8.5 GB) copied, 293.063 s, 29.2 MB/s 8654702592 bytes (8.7 GB) copied, 297.754 s, 29.1 MB/s 8755459072 bytes (8.8 GB) copied, 302.913 s, 28.9 MB/s 8861316096 bytes (8.9 GB) copied, 307.973 s, 28.8 MB/s 8949744640 bytes (8.9 GB) copied, 313.423 s, 28.6 MB/s 9030812672 bytes (9.0 GB) copied, 318.113 s, 28.4 MB/s 9132983296 bytes (9.1 GB) copied, 323.203 s, 28.3 MB/s 9211621376 bytes (9.2 GB) copied, 328.045 s, 28.1 MB/s 9333068800 bytes (9.3 GB) copied, 333.113 s, 28.0 MB/s 9474348032 bytes (9.5 GB) copied, 338.203 s, 28.0 MB/s 9572865024 bytes (9.6 GB) copied, 343.553 s, 27.9 MB/s 9679008768 bytes (9.7 GB) copied, 348.216 s, 27.8 MB/s 9840333824 bytes (9.8 GB) copied, 353.272 s, 27.9 MB/s 9981170688 bytes (10 GB) copied, 358.413 s, 27.8 MB/s 10128851968 bytes (10 GB) copied, 363.423 s, 27.9 MB/s 10240000000 bytes (10 GB) copied, 367.252 s, 27.9 MB/s write complete, syncing reading from: /mnt/disk1/test.dd 10240000000 bytes (10 GB) copied, 14.7586 s, 694 MB/s removing: /mnt/disk1/test.dd removed `/mnt/disk1/test.dd\u0026#39; ","date":"2020-01-26","permalink":"http://localhost:1313/posts/20200126-linux%E4%B8%8B%E6%A0%BC%E5%BC%8F%E5%8C%96u%E7%9B%98/","section":"","summary":"","tags":[""],"title":"Linux下格式化U盘"},{"categories":[],"contents":" Introduction This fix makes your Java apps use your GTK+ theme (colours \u0026amp; such) \u0026amp; your chosen font settings. Here is how it looks like:\nJava default look Java GTK+ look How do you do it? Set the variable _JAVA_OPTIONS by running this command in a terminal:\nexport _JAVA_OPTIONS=\u0026#34;-Dawt.useSystemAAFontSettings=on -Dswing.aatext=true -Dswing.defaultlaf=com.sun.java.swing.plaf.gtk.GTKLookAndFeel -Dswing.crossplatformlaf=com.sun.java.swing.plaf.gtk.GTKLookAndFeel ${_JAVA_OPTIONS}\u0026#34; First test to see if the outcome is what you expect by running your Java app from the same terminal window.\nIf the result looks good to you, let us make the changes permanent:\nAppend the above definition of the _JAVA_OPTIONS variable to ~/.profile (for your user only) or /etc/profile.d/90-java_ops.sh and /etc/environment (system-wide). In both cases, if the file does not exist, create it.\nSee Also How can I get a java apps to use the GTK+ theme?(askubuntu)\nRelated forum post\n","date":"2020-01-22","permalink":"http://localhost:1313/posts/20200122-set-all-java-apps-to-use-gtk+-font--theme-settings/","section":"","summary":"","tags":["",""],"title":"Set_all_Java_apps_to_use_GTK+_font_\u0026_theme_settings"},{"categories":[],"contents":" PowerShell\u0026rsquo;s own history mechanism (Get-History, Clear-History) is host-independent, which is why - somewhat unexpectedly - you also need to clear the hosts\u0026rsquo;s command history separately.\nAs for the console host\u0026rsquo;s own history feature:\ndoskey-style history feature, before module PSReadline shipped with PowerShell (see below):\nThere is no saved history - a history is kept only for the duration of the current session. Alt+F7 must be used to clear the console\u0026rsquo;s history, with no (obvious) programmatic way to do it (in a cmd.exe console window you could use doskey /reinstall, but that doesn\u0026rsquo;t work in PS). CB.\u0026rsquo;s answer shows you how to simulate this keyboard combination; remember: this must be used in addition to Clear-History. The PSReadline module comes with PowerShell v5 on Windows 10 and will also ship with Windows Server 2016; it replaces the doskey-style line-editing and command-history features with more sophisticated functionality; it is also possible to retrofit older Windows editions / PS versions (\u0026gt;= v3) versions with it, using the PowerShell Gallery (PSv3 and PSv4 must first install PowerShellGet).\nCommand history is now saved across sessions, in file (Get-PSReadlineOption).HistorySavePath. [Microsoft.PowerShell.PSConsoleReadLine]::ClearHistory() can be used to clear the current session\u0026rsquo;s history (note that v1.2+ also supports Alt+F7 for interactive clearing of the current history. CAVEAT: With PSReadline\u0026rsquo;s default history-saving style, SaveIncrementally, any sensitive commands have already been saved by the time to you call [Microsoft.PowerShell.PSConsoleReadLine]::ClearHistory(), and will reappear in the next session. The only way to handle this is remove the saved-history file, as demonstrated in JVimes\u0026rsquo;s answer which, however, invariably wipes out the entire history. IF you set up your profile to call Set-PSReadlineOption -HistorySaveStyle SaveAtExit every time a session starts - the setting apparenly does NOT \u0026ldquo;stick\u0026rdquo; by itself - you should be able to get away with only calling [Microsoft.PowerShell.PSConsoleReadLine]::ClearHistory() (in addition to Clear-History) without also having to delete the saved-history file, in which case you won\u0026rsquo;t lose your saved history from previous sessions. HOWEVER, AS OF v1.2, SaveAtExit is BROKEN ALTOGETHER - no history is saved at all; see https://github.com/lzybkr/PSReadLine/issues/262 The following advanced function bundles all commands necessary to clear the command history (both for PowerShell itself and the console), both for doskey-style and PSReadline-module PowerShell console windows:\nNote:\nBecause it\u0026rsquo;s (currently) the only safe option, PSReadline\u0026rsquo;s saved-history file is deleted as well, which means the entire history, including from previous sessions, is cleared.\nTherefore, a confirmation prompt is shown by default.\n偷懒的话直接运行命令 Remove-Item (Get-PSReadlineOption).HistorySavePath 即可。\n参考 https://stackoverflow.com/questions/13257775/powershell-clear-history-doesnt-clear-history\n","date":"2020-01-20","permalink":"http://localhost:1313/posts/20200120-historysavepath/","section":"","summary":"","tags":["",""],"title":"Win10 清除 PowerShell 历史记录"},{"categories":[],"contents":"如果你打算创建安装映像以部署到不同的计算机上，则必须运行带有 /generalize 选项的 Sysprep 命令，即使其他计算机具有相同的硬件配置。Sysprep /generalize 命令从 Windows 安装删除唯一性信息，这使得你可以在不同的计算机上重复使用映像。下次启动 Windows 映像时，将运行 specialize 配置阶段。\nSysprep 命令行选项 下列命令行选项可用于 Sysprep：\nSysprep.exe [/oobe | /audit] [/generalize] [/mode:vm] [/reboot | /shutdown | /quit] [/quiet] [/unattend:\u0026lt;answerfile\u0026gt;] 下表列出了 Sysprep 命令行选项：\n选项 描述 /audit 重新启动计算机进入审核模式。审核模式使你可以将其他驱动程序或应用程序添加到 Windows。你还可以在将 Windows 安装发送给最终用户前对其进行测试。例如： Sysprep /audit 如果指定了应答文件，则 Windows 安装程序的审核模式将运行 auditSystem 和 auditUser 配置阶段。 /generalize 准备要作为映像的 Windows 安装。Sysprep 工具会从 Windows 安装中删除所有唯一的系统信息。Sysprep 将重置安全 ID (SID)，清除所有系统还原点，并删除事件日志。例如： Sysprep /generalize /shutdown 下次计算机启动时，将运行 specialize 配置阶段。该配置阶段将创建一个新安全 ID (SID)。 /oobe 重新启动计算机进入 OOBE 模式。例如： Sysprep /generalize /shutdown /oobe OOBE 允许最终用户自定义其 Windows 操作系统、创建用户帐户、命名计算机和执行其他任务。Sysprep 在 OOBE 启动前，将处理应答文件中 oobeSystem 配置阶段的所有设置。 /mode:vm Windows(R) 8 的新增内容。一般化虚拟硬盘 (VHD)，这样可以将其部署为相同虚拟机 (VM) 或虚拟机监控程序上的 VHD。VM 重新启动后，该 VM 可以引导到 OOBE。例如： Sysprep /generalize /oobe /mode:vm 仅有的适用于 VM 模式的额外交换机为“/reboot”、“/shutdown”和“/quit”。必须使用相同的硬件配置文件在虚拟机或虚拟机监控程序上部署 VHD。例如，如果你已在 Microsoft Hyper-V 中创建 VHD，仅可以使用匹配的硬件配置文件将 VHD 部署到 Microsoft Hyper-V VM。使用不同的硬件配置文件将 VHD 部署到不同的 VM 可能会导致意外的问题。 /reboot 重新启动计算机。可以使用该选项审核计算机并确保首次运行体验正确工作。 /shutdown 在 sysprep 命令完成运行后关闭计算机。 /quiet 运行 Sysprep 工具而不显示屏幕确认消息。如果自动运行 Sysprep 工具，则可以使用该选项。 /quit Sysprep 运行指定命令后，无需重新启动或关闭计算机即可关闭 Sysprep 工具。 /unattend: 在无人参与的安装过程中，将应答文件中的设置应用到 Windows，其中 指定要使用的应答文件的路径和文件名。例如：Sysprep /audit /reboot /unattend:F:\\Unattend.xml 其中 F 是应答文件 (Unattend.xml) 所在的便携存储设备的驱动器号。 Important重要事项 必须使用 Sysprep /generalize 命令对完整的 Windows 安装一般化，才可以使用该安装对新计算机进行部署，无论是使用映像、硬盘复制，还是其他方法均可。不运行 Sysprep /generalize 命令而将 Windows 映像移动或复制到其他计算机的做法不受支持。\n命令行 sysprep.exe /generalize /reboot /oobe\nFailure occurred while executing \u0026lsquo;Sysprep_Clean_Validate_Opk\u0026rsquo; from C:\\Windows\\System32\\spopk.dll Take ownership of the file: takeown /f C:\\Windows\\System32\\spopk.dll\nGrant ability to modify file: icacls C:\\Windows\\System32\\spopk.dll /Grant Administrators:f\n预设appx删除 Get-AppxProvisionedPackage -online | Out-GridView -PassThru | Remove-AppxProvisionedPackage -online Get-AppxPackage -AllUsers | Out-GridView -PassThru | Remove-AppxPackage From https://docs.microsoft.com/en-us/windows-hardware/manufacture/desktop/sysprep\u0026ndash;generalize\u0026ndash;a-windows-installation\nhttp://www.edugeek.net/forums/windows-10/207219-problem-sysprep-windows-10-1903-a.html\n","date":"2020-01-20","permalink":"http://localhost:1313/posts/20200120-sysprep/","section":"","summary":"","tags":["",""],"title":"Sysprep命令详解"},{"categories":[],"contents":" # 查看当前设置 wmic pagefile list /format:list # 取消自动管理分页文件大小 wmic computersystem where name=\u0026#34;%computername%\u0026#34; set AutomaticManagedPagefile=False # 修改页面文件大小 最小1024MB，最大4096MB wmic pagefileset where name=\u0026#34;C:\\\\pagefile.sys\u0026#34; set InitialSize=1024,MaximumSize=4096 # 重启生效 shutdown -r -t 0 ","date":"2020-01-20","permalink":"http://localhost:1313/posts/20200120-pagefile/","section":"","summary":"","tags":["",""],"title":"cmd命令行修改windows虚拟内存pagefile.sys"},{"categories":[],"contents":"由于最近加班，俺的高清下载机中，已经累积了200G+的高清电影了，嘿嘿，看来平时的带宽没浪费，充分利用了。在这之前，由于懒于配置Samba，我都是偷懒，用的SFTP，通过Linux帐号来登录下载机，然后把要看的电影，一个一个的用SFTP的方式，给拖到我的电脑上，再欣赏。其实这样的效率挺低的，而且又浪费硬盘，又浪费时间。\nLinux的Samba，为Linux与Linux之间，还有Linux与Windows之间，提供了一种很好的文件共享的方式。周末了，抽了点时间，把Samba给配置好了。这样，就可以直接在我的电脑上，通过共享目录的方式，来访问高清下载机中的高清电影了，还可以直接播放，方便多了……\n下面记录一下ArchLinux中配置Samba的过程，留作备份。\n首先，是安装Samba，ArchLinux可以直接从源中获取并安装Samba：\npacman -S samba 等待数秒，安装成功后，你会在/etc中找到一个叫samba的目录，进入这个目录，有一个默认的配置文件样本，叫做smb.conf.default。这是官方的范本配置文件，里面有详细的注释，和每一个配置项的解释。不过这文件挺长，建议你有空的时候，可以详细看看每个参数的含义。这里俺就不累述了，还是来个简洁点的配置吧：\n在/etc/samba目录中，直接建立一个空的smb.conf，然后将如下内容粘贴过去：\n[global] workgroup = WORKGROUP security = user [Movies] path = /home/transmission/Downloads valid users = samba public = no writable = yes printable = no create mask = 0644 这个够简洁了吧？简单说明一下，global配置节，是一个全局配置节，里面配置了两项：\nworkgroup，这个顾名思义，计算机的工作组名称，比如我是和我的Win7来共享文件，最好把工作组和我的Win7设成通一个工作组，这样方便Win7通过网络发现来找到我的下载机。这里，我的win7工作组名字，就叫做：WORKGROUP了\nsecurity，这是指共享目录的安全认证形式，security的值，有两种可以设置：\n第一种，是设成上面例子中的user，意思是在访问共享目录的时候，需要通过用户名和密码的方式来认证，可以给共享目录提供一定的安全性保护。\n第二种，是设成share，这样的话，网络中的任何人都可以通过共享目录的方式来访问你共享的内容了。\n在这里，我选择了用户名与密码认证的方式，所以设成了user\n下面的Movies节点，可以有多个(如果你想设置多个共享目录的话)\n[Movies] 这里设置的名字，就是能够在Windows中看到的名字，可以随意更改\n下面的path，就是你想共享的Linux目录了，我设成了我的Transmission的下载目录。\n后面的valid users，是一个用户帐号，也即通过用户名和密码来访问共享目录的那个帐号，如果你把security设成share，这一项可以去掉。\n下面是一些权限的设置，以及是否允许访问者有写入共享目录的权限，各个参数可以查看Samba文档，就不一一介绍了。\n最后，说一下security设成user后，帐号的设置问题。\n首先，你可以添加一个新的Linux帐号，专门用来访问共享目录用。比如，我就添加了一个帐号，叫做Samba\n然后就是给帐号设置访问共享目录的密码，这里需要注意，密码不是通过Linux命令passwd来设置的。这里的密码，是指Samba的密码，而不是Linux密码。\n所以，得用命令 pdbedit -a -u (username)来修改Samba密码。\n设置好后，就可以启动Samba服务了，如果需要开机自动启动Samba，记得把Samba加入到/etc/rc.conf中。\n最后一步，直接访问Win7的网络，如果你的设置没问题，就能一次性成功了…… 启用了Samba服务的高清下载机，能被Win7立马发现：\n双击进入，需要输入Samba用户名与密码验证，最后，高清电影就出现在眼前了：\n双击电影，即可通过家里的局域网在线播放了…… 打完收工，看电影去！\n参考 官方smb.conf说明\n","date":"2020-01-19","permalink":"http://localhost:1313/posts/20200119-share-movie-between-archlinux-and-win7-via-samba/","section":"","summary":"","tags":["","",""],"title":"ArchLinux配置Samba服务与Windows共享文件"},{"categories":[],"contents":"1.首先介绍一下指令和相关配置文件 启动指令:service iptables start\n重启指令:service iptables restart\n关闭指令:service iptables stop\n然后是相关配置:/etc/sysconfig/iptables\n如何操作该配置呢？\nvim /etc/sysconfig/iptables\n然后进去修改即可，修改完了怎么办？这里很多人会想到/etc/rc.d/init.d/iptables save指令，但是一旦你这么干了你刚才的修改内容就白做了。。。\n具体方法是：\n只修改/etc/sysconfig/iptables 使其生效的办法是修改好后先service iptables restart，然后才调用/etc/rc.d/init.d/iptables save，\n因为/etc/rc.d/init.d/iptables save会在iptables服务启动时重新加载，要是在重启之前直接先调用了/etc/rc.d/init.d/iptables save那么你\n的/etc/sysconfig/iptables 配置就回滚到上次启动服务的配置了，这点必须注意！！！\n2.下面介绍一些指令用法（主要还是man iptables看下相关资料才行）\n-A：指定链名\n-p：指定协议类型\n-d：指定目标地址\n\u0026ndash;dport：指定目标端口（destination port 目的端口）\n\u0026ndash;sport：指定源端口（source port 源端口）\n-j：指定动作类型\n3.如果我不像修改文件直接打命令可以吗，当然没问题，步骤如下:\n例如我给SSH加放行的语句：\n添加input记录： iptables -A INPUT -p tcp \u0026ndash;dport 22 -j ACCEPT\n添加output记录： iptables -A OUTPUT -p tcp \u0026ndash;sport 22 -j ACCEPT\n最后注意需要再执行一下 /etc/init.d/iptables save，这样这两条语句就保存到刚才那个/etc/sysconfig/iptables 文件中了。\n4.接下来说明一下步骤，如果机器不在我身边，我只能SSH进去做iptables规则，那么我必须注意每一步，千万别搞错了，否则就SSH链接不上都有可能！\n首先要做的是给咱的SSH进行ACCEPT配置，以免直接无法连接的情况发生:\n1.如果SSH端口是22（这里不建议用默认端口最好改掉SSH端口）\niptables -A INPUT -p tcp \u0026ndash;dport 22 -j ACCEPT\niptables -A OUTPUT -p tcp \u0026ndash;sport 22 -j ACCEPT\n注意要/etc/rc.d/init.d/iptables save，以下每一步都最好执行一遍此语句，以下不再累述。\n2.vim /etc/sysconfig/iptables确定是否已经加入配置，可以的话执行service iptables restart重启后生效\n3.下面是很危险的操作，如果你第一步没做就会直接可能导致你连不上SSH，此步骤前切记执行第一步！！！\niptables -P INPUT DROP iptables -P OUTPUT DROP iptables -P FORWARD DROP\n这个步骤是把所有不符合自己配置的规则ACCEPT的连接全部DROP掉，执行完以后如果咱SSH还没掉，那么谢天谢地，安全了，重启下iptables后继续下面的配置！\n4.下面咱就不细说了，具体就是看自己服务器要开放哪些端口或者是要访问哪些端口来做具体的配置，下面是我自己的机器的配置：\n/etc/sysconfig/iptables文件配置如下:\nGenerated by iptables-save v1.4.7 on Fri Mar 2 19:59:43 2012 *filter\n:INPUT DROP [0:0]\n:FORWARD DROP [0:0]\n:OUTPUT DROP [8:496]\n-A INPUT -m state \u0026ndash;state RELATED,ESTABLISHED -j ACCEPT\n#ping使用的端口\n-A INPUT -p icmp -j ACCEPT\n-A INPUT -i lo -j ACCEPT\n-A INPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -j ACCEPT\n-A INPUT -s 192.168.2.200/32 -d 192.168.2.200/32 -j ACCEPT\n#允许服务器自己的SSH（对外部请求来说服务器是目标所以使用\u0026ndash;dport）\n-A INPUT -p tcp -m tcp \u0026ndash;dport 22 -j ACCEPT\n#80端口不用说了吧，服务器网站访问端口\n-A INPUT -p tcp -m tcp \u0026ndash;dport 80 -j ACCEPT\n-A INPUT -p tcp -m tcp \u0026ndash;dport 3306 -j ACCEPT\n-A INPUT -p tcp -m tcp \u0026ndash;dport 11211 -j ACCEPT\n-A INPUT -p tcp -m tcp \u0026ndash;dport 11212 -j ACCEPT\n-A FORWARD -j REJECT \u0026ndash;reject-with icmp-host-prohibited\n#53端口是DNS相关，TCP和UDP都要配置\n-A INPUT -p tcp -m tcp \u0026ndash;dport 53 -j ACCEPT\n-A INPUT -p udp -m udp \u0026ndash;dport 53 -j ACCEPT\n#ping使用的端口\n-A OUTPUT -p icmp -j ACCEPT\n-A OUTPUT -s 127.0.0.1/32 -d 127.0.0.1/32 -j ACCEPT\n-A OUTPUT -s 192.168.2.200/32 -d 192.168.2.200/32 -j ACCEPT\n#允许服务器SSH到其他机器（使用外部端口就使用\u0026ndash;dport）\n-A OUTPUT -p tcp -m tcp \u0026ndash;dport 22 -j ACCEPT\n#允许服务器自己的SSH（自已为源输出就使用\u0026ndash;sport）\n-A OUTPUT -p tcp -m tcp \u0026ndash;sport 22 -j ACCEPT\n#访问外部网站80端口（使用外部端口就使用\u0026ndash;dport）\n-A OUTPUT -p tcp -m tcp \u0026ndash;dport 80 -j ACCEPT\n#如果服务器需要访问外部网站，那么OUTPUT也需要配置53端口（使用外部端口就使用\u0026ndash;dport）\n-A OUTPUT -p tcp -m tcp \u0026ndash;dport 53 -j ACCEPT\n-A OUTPUT -p udp -m udp \u0026ndash;dport 53 -j ACCEPT\n#如果有访问外部邮箱，那么打开邮箱相关端口（使用外部端口就使用\u0026ndash;dport）\n-A OUTPUT -p tcp -m tcp \u0026ndash;dport 465 -j ACCEPT\n-A OUTPUT -p tcp -m tcp \u0026ndash;dport 25 -j ACCEPT\n-A OUTPUT -p tcp -m tcp \u0026ndash;dport 110 -j ACCEPT\n#服务器网站访问端口（自已为源输出就使用\u0026ndash;sport）\n-A OUTPUT -p tcp -m tcp \u0026ndash;sport 80 -j ACCEPT\n-A OUTPUT -p tcp -m tcp \u0026ndash;sport 3306 -j ACCEPT\n-A OUTPUT -p tcp -m tcp \u0026ndash;sport 11211 -j ACCEPT\n-A OUTPUT -p tcp -m tcp \u0026ndash;sport 11212 -j ACCEPT\nCOMMIT\nCompleted on Fri Mar 2 19:59:43 2012 5.可能有时候需要删除规则，最简单就是修改一下/etc/sysconfig/iptables然后service iptables restart,最后/etc/rc.d/init.d/iptables save即可。\n当然也可以使用指令完成:\n在网上找了一下，删除规则的方法：\n语法是： iptables -D chain rulenum [options]\n其中： chain 是链的意思，就是INPUT FORWARD 之类的\nrulenum 是规则的编号。从1 开始。可以使用 \u0026ndash;line-numbers 列出规则的编号\n所以，例如上面要删除一个INPUT链的规则的话可以这样：iptables -D INPUT 3\n意思是删除第3条规则。\n还有第二种方法。第二种办法是 -A 命令的映射，不过用-D替换-A。当你的链中规则很复杂，而你不想计算它们的编号的时候这就十分有用了。也就是说，你如何用iptables -A\u0026hellip;. 语句定义了一个规则，则删除此规则时就用 -D 来代替- A 其余的都不变即可。 说一下上面的 \u0026ndash;line-numbers 选项，如下面的命令：\niptables -L INPUT \u0026ndash;line-numbers 列出INPUT 链所有的规则\nnum target prot opt source destination 1 REJECT tcp \u0026ndash; anywhere anywhere tcp dpt:microsoft-ds reject-with icmp-port-unreachable\n2 REJECT tcp \u0026ndash; anywhere anywhere tcp dpt:135 reject-with icmp-port-unreachable\n3 REJECT tcp \u0026ndash; anywhere anywhere tcp dpt:netbios-ssn reject-with icmp-port-unreachable\n\u0026hellip;\n\u0026hellip;\n删除指定行规则：\n[root@localhost rc.d]# iptables -D INPUT 4\n6.最后补充一下，如果想针对某IP进行单独开放端口可以如下配置：\n如果我需要对内网某机器单独开放mysql端口，应该如下配置：\niptables -A INPUT -s 192.168.2.6 -p tcp -m tcp \u0026ndash;dport 3306 -j ACCEPT\niptables -A OUTPUT -s 192.168.2.6 -p tcp -m tcp \u0026ndash;sport 3306 -j ACCEPT\n7.彻底禁止某IP访问:\n#屏蔽单个IP的命令是\niptables -I INPUT -s 123.45.6.7 -j DROP\n#封整个段即从123.0.0.1到123.255.255.254的命令\niptables -I INPUT -s 123.0.0.0/8 -j DROP\n#封IP段即从123.45.0.1到123.45.255.254的命令\niptables -I INPUT -s 124.45.0.0/16 -j DROP\n#封IP段即从123.45.6.1到123.45.6.254的命令是\niptables -I INPUT -s 123.45.6.0/24 -j DROP\n指令I是insert指令 但是该指令会insert在正确位置并不像A指令看你自己的排序位置，因此用屏蔽因为必须在一开始就要加载屏蔽IP，所以必须使用I命令加载，然后注意执行/etc/rc.d/init.d/iptables save进行保存后重启服务即可\n1、关闭所有的 INPUT FORWARD OUTPUT 只对某些端口开放。 下面是命令实现：\niptables -P INPUT DROP iptables -P FORWARD DROP iptables -P OUTPUT DROP\n再用命令 iptables -L -n 查看 是否设置好， 好看到全部 DROP 了 这样的设置好了，我们只是临时的， 重启服务器还是会恢复原来没有设置的状态 还要使用 service iptables save 进行保存 看到信息 firewall rules 防火墙的规则 其实就是保存在 /etc/sysconfig/iptables 可以打开文件查看 vi /etc/sysconfig/iptables 2、 下面我只打开22端口，看我是如何操作的，就是下面2个语句\niptables -A INPUT -p tcp \u0026ndash;dport 22 -j ACCEPT iptables -A OUTPUT -p tcp \u0026ndash;sport 22 -j ACCEPT\n再查看下 iptables -L -n 是否添加上去, 看到添加了\nChain INPUT (policy DROP) target prot opt source destination ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:22\nChain FORWARD (policy DROP) target prot opt source destination\nChain OUTPUT (policy DROP) target prot opt source destination ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp spt:22\n现在Linux服务器只打开了22端口，用putty.exe测试一下是否可以链接上去。 可以链接上去了，说明没有问题。\n最后别忘记了保存 对防火墙的设置 通过命令：service iptables save 进行保存\niptables -A INPUT -p tcp \u0026ndash;dport 22 -j ACCEPT iptables -A OUTPUT -p tcp \u0026ndash;sport 22 -j ACCEPT 针对这2条命令进行一些讲解吧 -A 参数就看成是添加一条 INPUT 的规则 -p 指定是什么协议 我们常用的tcp 协议，当然也有udp 例如53端口的DNS 到时我们要配置DNS用到53端口 大家就会发现使用udp协议的\n而 \u0026ndash;dport 就是目标端口 当数据从外部进入服务器为目标端口 反之 数据从服务器出去 则为数据源端口 使用 \u0026ndash;sport\n-j 就是指定是 ACCEPT 接收 或者 DROP 不接收 3、禁止某个IP访问 1台Linux服务器,2台windows xp 操作系统进行访问 Linux服务器ip 192.168.1.99 xp1 ip: 192.168.1.2 xp2 ip: 192.168.1.8\n下面看看我2台xp 都可以访问的\n192.168.1.2 这是 xp1 可以访问的， 192.168.1.8 xp2 也是可以正常访问的。\n那么现在我要禁止 192.168.1.2 xp1 访问， xp2 正常访问， 下面看看演示\n通过命令 iptables -A INPUT -p tcp -s 192.168.1.2 -j DROP 这里意思就是 -A 就是添加新的规则， 怎样的规则呢？ 由于我们访问网站使用tcp的， 我们就用 -p tcp , 如果是 udp 就写udp，这里就用tcp了， -s就是 来源的意思， ip来源于 192.168.1.2 ，-j 怎么做 我们拒绝它 这里应该是 DROP\n好，看看效果。好添加成功。下面进行验证 一下是否生效\n一直出现等待状态 最后 该页无法显示 ，这是 192.168.1.2 xp1 的访问被拒绝了。\n再看看另外一台 xp 是否可以访问， 是可以正常访问的 192.168.1.8 是可以正常访问的 4、如何删除规则 首先我们要知道 这条规则的编号，每条规则都有一个编号\n通过 iptables -L -n \u0026ndash;line-number 可以显示规则和相对应的编号 num target prot opt source destination 1 DROP tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:3306 2 DROP tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:21 3 DROP tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 多了 num 这一列， 这样我们就可以 看到刚才的规则对应的是 编号2\n那么我们就可以进行删除了 iptables -D INPUT 2 删除INPUT链编号为2的规则。\n再 iptables -L -n 查看一下 已经被清除了。 5、过滤无效的数据包 假设有人进入了服务器，或者有病毒木马程序，它可以通过22，80端口像服务器外传送数据。 它的这种方式就和我们正常访问22，80端口区别。它发向外发的数据不是我们通过访问网页请求 而回应的数据包。\n下面我们要禁止这些没有通过请求回应的数据包，统统把它们堵住掉。\niptables 提供了一个参数 是检查状态的，下面我们来配置下 22 和 80 端口，防止无效的数据包。\niptables -A OUTPUT -p tcp \u0026ndash;sport 22 -m state \u0026ndash;state ESTABLISHED -j ACCEPT\n可以看到和我们以前使用的： iptables -A OUTPUT -p tcp \u0026ndash;sport 22 -j ACCEPT 多了一个状态判断。\n同样80端口也一样， 现在删掉原来的2条规则， iptables -L -n \u0026ndash;line-number 这个是查看规则而且带上编号。我们看到编号就可以 删除对应的规则了。\niptables -D OUTPUT 1 这里的1表示第一条规则。\n当你删除了前面的规则， 编号也会随之改变。看到了吧。\n好，我们删除了前面2个规则，22端口还可以正常使用，说明没问题了\n下面进行保存，别忘记了，不然的话重启就会还原到原来的样子。\nservice iptables save 进行保存。\nSaving firewall rules to /etc/sysconfig/iptables: [ OK ] 其实就是把刚才设置的规则写入到 /etc/sysconfig/iptables 文件中。 6、DNS端口53设置 下面我们来看看如何设置iptables来打开DNS端口，DNS端口对应的是53\n大家看到我现在的情况了吧，只开放22和80端口， 我现在看看能不能解析域名。\nhostwww.google.com 输入这个命令后，一直等待，说明DNS不通\n出现下面提示 ： ;; connection timed out; no servers could be reached\nping 一下域名也是不通 [root@localhost ~pingwww.google.com ping: unknown hostwww.google.com\n我这里的原因就是 iptables 限制了53端口。\n有些服务器，特别是Web服务器减慢，DNS其实也有关系的，无法发送包到DNS服务器导致的。\n下面演示下如何使用 iptables 来设置DNS 53这个端口，如果你不知道 域名服务端口号，你\n可以用命令 : grep domain /etc/services\n[root@localhost ~grep domain /etc/services domain 53/tcp # name-domain server domain 53/udp domaintime 9909/tcp # domaintime domaintime 9909/udp # domaintime\n看到了吧， 我们一般使用 udp 协议。\n好了， 开始设置。。。\niptables -A OUTPUT -p udp \u0026ndash;dport 53 -j ACCEPT 这是我们 ping 一个域名，数据就是从本机出去，所以我们先设置 OUTPUT， 我们按照ping这个流程来设置。\n然后 DNS 服务器收到我们发出去的包，就回应一个回来 iptables -A INPUT -p udp \u0026ndash;sport 53 -j ACCEPT\n同时还要设置 iptables -A INPUT -p udp \u0026ndash;dport 53 -j ACCEPT iptables -A OUTPUT -p udp \u0026ndash;sport 53 -j ACCEPT\n好了， 下面开始测试下， 可以用 iptables -L -n 查看设置情况，确定没有问题就可以测试了\n[root@localhost ~iptables -L -n Chain INPUT (policy DROP) target prot opt source destination ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 ACCEPT udp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 udp spt:53 ACCEPT udp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 udp dpt:53\nChain FORWARD (policy DROP) target prot opt source destination\nChain OUTPUT (policy DROP) target prot opt source destination ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp spt:22 state ESTABLISHED ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp spt:80 state ESTABLISHED ACCEPT udp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 udp dpt:53 ACCEPT udp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 udp spt:53\n可以测试一下 是否 DNS 可以通过iptables 了。\n[root@localhost ~hostwww.google.com www.google.comis an alias forwww.l.google.com. www.l.google.comis an alias for www-china.l.google.com. www-china.l.google.com has address 64.233.189.104 www-china.l.google.com has address 64.233.189.147 www-china.l.google.com has address 64.233.189.99\n正常可以解析 google 域名。\nping 方面可能还要设置些东西。\n用 nslookup 看看吧\n[root@localhost ~nslookup\nwww.google.com Server: 192.168.1.1 Address: 192.168.1.1#53\nNon-authoritative answer: www.google.comcanonical name =www.l.google.com. www.l.google.com canonical name = www-china.l.google.com. Name: www-china.l.google.com Address: 64.233.189.147 Name: www-china.l.google.com Address: 64.233.189.99 Name: www-china.l.google.com Address: 64.233.189.104\n说明本机DNS正常， iptables 允许53这个端口的访问。 7、iptables对ftp的设置 现在我开始对ftp端口的设置，按照我们以前的视频，添加需要开放的端口 ftp连接端口有2个 21 和 20 端口，我现在添加对应的规则。\n[root@localhost rootiptables -A INPUT -p tcp \u0026ndash;dport 21 -j ACCEPT [root@localhost rootiptables -A INPUT -p tcp \u0026ndash;dport 20 -j ACCEPT [root@localhost rootiptables -A OUTPUT -p tcp \u0026ndash;sport 21 -j ACCEPT [root@localhost rootiptables -A OUTPUT -p tcp \u0026ndash;sport 20 -j ACCEPT\n好，这样就添加完了，我们用浏览器访问一下ftp,出现超时。\n所以我刚才说 ftp 是比较特殊的端口，它还有一些端口是 数据传输端口， 例如目录列表， 上传 ，下载 文件都要用到这些端口。\n而这些端口是 任意 端口。。。 这个 任意 真的比较特殊。\n如果不指定什么一个端口范围， iptables 很难对任意端口开放的， 如果iptables允许任意端口访问， 那和不设置防火墙没什么区别，所以不现实的。\n那么我们的解决办法就是 指定这个数据传输端口的一个范围。\n下面我们修改一下ftp配置文件。\n我这里使用vsftpd来修改演示，其他ftp我不知道哪里修改，大家可以找找资料。\n[root@localhost rootvi /etc/vsftpd.conf\n在配置文件的最下面 加入\npasv_min_port=30001 pasv_max_port=31000\n然后保存退出。\n这两句话的意思告诉vsftpd, 要传输数据的端口范围就在30001到31000 这个范围内传送。\n这样我们使用 iptables 就好办多了，我们就打开 30001到31000 这些端口。\n[root@localhost rootiptables -A INPUT -p tcp \u0026ndash;dport 30001:31000 -j ACCEPT [root@localhost rootiptables -A OUTPUT -p tcp \u0026ndash;sport 30001:31000 -j ACCEPT\n[root@localhost rootservice iptables save\n最后进行保存， 然后我们再用浏览器范围下 ftp。可以正常访问\n用个账号登陆上去，也没有问题，上传一些文件上去看看。\n看到了吧，上传和下载都正常。。 再查看下 iptables 的设置\n[root@localhost rootiptables -L -n Chain INPUT (policy DROP) target prot opt source destination ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:22 ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:21 ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpt:20 ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp dpts:30001:31000\nChain FORWARD (policy DROP) target prot opt source destination\nChain OUTPUT (policy DROP) target prot opt source destination ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp spt:22 ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp spt:21 ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp spt:20 ACCEPT tcp \u0026ndash; 0.0.0.0/0 0.0.0.0/0 tcp spts:30001:31000\n这是我为了演示ftp特殊端口做的简单规则，大家可以添加一些对数据包的验证 例如 -m state \u0026ndash;state ESTABLISHED,RELATED 等等要求更加高的验证\n#Flush existing rules iptables -F # Set up default DROP rule for eth0 iptables -P INPUT DROP # Allow existing connections to continue iptables -A INPUT -i eth0 -m state --state ESTABLISHED,RELATED -j ACCEPT # Accept everything from the 192.168.1.x network iptables -A INPUT -i eth0 -s 192.168.1.0/24 -j ACCEPT # Allow connections from this host to 192.168.2.10 iptables -A OUTPUT -o eth0 -d 192.168.2.10 -j ACCEPT #(repeat this line as needed) iptables -I INPUT -s \u0026lt;allowed_ip\u0026gt; -j ACCEPT iptables -P INPUT DROP 主动模式 1 iptables -A INPUT -m state \u0026ndash;state RELATED,ESTABLISHED -j ACCEPT 首先对自己主动发送的请求进行响应的报文放行，这里尤其注意是对自己已发送的报文进行响应，如果是其他客户端发送过来的请求连接这里不做处理，使用默认的或后续的匹配策略处理。 因为在iptables看来每个协议都有建立连接的概念，包括“udp”、“icmp”。state支持的状态有：NEW、ESTABLISHED、RELATED、INVALID、UNTRACKED。\nNEW：就是双方进行通信时第一个到来的报文； ESTABLISHED：state把NEW以后到来的报文都定义为ESTABLISHED状态，包括UDP等，所以说state是有类似于tcp三次握手建立连接的概念； RELATED：在一个服务中，可能开启了两个进程，而且这两个进程都需要跟服务器进行通信，例如FTP有两个通信链路，命令链路和传输数据的链路，这两个链路就是存在关系的，所以他们属于RELATED状态； INVALID：表示一个包不能被识别； UNTRACKED：表示报文不能被追踪； 为SSH加固 1 iptables -A INPUT -p icmp \u0026ndash;icmp-type 8 -m length \u0026ndash;length 128 -m recent \u0026ndash;set \u0026ndash;name SSH \u0026ndash;rsource -j ACCEPT length模块用于匹配报文长度，这里我们用ping报文的长度来充当芝麻开门的作用，recent模块功能很强，能将匹配到的报文信息记录下来，给后续规则做条件使用。它的几个参数为：\n—name： 给用来记录报文的列表起名称；（这里应该是两个-） —set： 表示将匹配到的报文记录下来； —rsource: 表示记录源IP地址； 这条指令的意思是：将ping报文长度为128的源IP地址记录到叫SSH的列表中去。这里需要注意的是ping报文头部长度就有28字节，所以实际的填充报文为：128-28=100。所以在Linux下使用ping -s 100 ip；在Windows下使用ping -l 100 ip来敲开服务器大门。\n相关的icmp报文的类型如下（因为ssh客户端是ping的请求方（发起方），所以这里要匹配类型为8的报文）：\n类型代码 类型描述 0 响应应答（ECHO-REPLY） 3 不可到达 4 源抑制 5 重定向 8 响应请求（ECHO-REQUEST） 11 超时 12 参数失灵 13 时间戳请求 14 时间戳应答 15 信息请求（*已作废） 16 信息应答（*已作废） 17 地址掩码请求 18 地址掩码应答 iptables -A INPUT -p tcp \u0026ndash;dport 8888 -m state \u0026ndash;state NEW -m recent \u0026ndash;rcheck \u0026ndash;seconds 20 \u0026ndash;name SSH \u0026ndash;rsource -j ACCEPT 8888是ssh修改后的端口号，这里之所以匹配NEW状态是因为后面我们需要对INPUT使用白名单策略，而NEW之后的状态在前面已经放行，所以这里需要对NEW状态进行放行。这里再对recent的两个参数进行说明：\n—rcheck： 检查源IP是否在列表中，以第一个匹配开始计算时间 —seconds： 记录的源IP地址的有效时间 所以这一整句话是说对NEW（新建）状态下请求8888端口的源IP进行检查，看这个IP是否在名叫SSH的列表之中，有效时间是20秒，这里的有效时间是指上一条规则记录下源IP的时间离用户请求SSH服务器的时间间隔。所以用户必须在ping完的20秒内连接客户端，否则连接失败，重新ping。\nPS： 如果是私有的git服务器的话，也同样适用这套规则，登陆或clone、push前都需要进行特殊的操作，这就能很好的保护数据和服务器的安全问题。不要以为这是弱智的问题，，这两天逛tools的时候就有人的git服务器被人攻破。。。 将INPUT策略改成白名单模式 白名单是只接受自己信任的来源，而对非信任区来源采用拒绝策略；黑名单则只拒绝自己不信任的来源，接受信任或目的不明确的来源。所以采用白名单的策略系统的安全性较高，而黑名单难免会有疏忽。\n要使用白名单，只需将INPUT的默认策略从ACCEPT改成DROP。可以使用iptables -P DROP,但如果一不小心清空了ACCEPT的规则，那么服务器将按照默认drop的策略拒绝所有的连接，导致服务器失联。所以我们使用另一种较为安全的策略：\n1 iptables -A INPUT -j DROP 我们在INPUT链的最后一条上加上DROP规则，这样即使我们不小心iptables -F INPUT清除掉INPUT规则也不用担心服务器失联。\n值得一提的是，由于采用了DROP策略，所以ping只接收长度为100的报文，也就是说正常的ping是不会被服务器接收的，这就提供了保护主机的安全的方法，相当于把主机从公网中隐藏起来，只有知道口令的人才能找得到。\n保存iptables配置 笔者主机为：Ubuntu 16.04，首先安装：\n1 2 apt install iptables-persistent apt install netfilter-persistent # ubuntu 14.04可以不用 保存：\n1 netfilter-persistent save 在/etc/rc.local中添加开机时自动执行恢复操作：\n1 netfilter-persistent reload 后言 这里只是简单的在INPUT中加固了ssh连接，但对其他类似web的服务没有讲解，但这并不是说iptables对这些服务没有办法，相反，iptables能很好的加强系统安全。比如有些服务不想暴露给外部直接访问，只允许本地处理。这时我们就能使用类似于这样的规则：\n1 iptables -I INPUT ! -s 127.0.0.1 -j DROP 通过配置iptables还可以在有限程度上防止CC攻击、DDOS等攻击，它可用的一些模块还有：\nstring： 可以匹配链路中出现的特定字符； time： 对链路的时间规则； limit： 对IP的并发限制；\n# At first you should always flush to be sure whats already defined… nothing iptables -F # Then set the default policy of the INPUT chain to DROP if the end is reached and no rule matched: iptables -P INPUT DROP # To ensure the loopback is not affacted you should add iptables -A INPUT -i lo -p all -j ACCEPT iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT # to allow all traffic on the lo-if and every incomming traffic for connections # you etablished. After that add every rule you need for # your services (don\u0026#39;t forget to open ssh if you need it! else you\u0026#39;re out): iptables -A INPUT -p tcp -m tcp --dport 1962 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 999 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 12020 -j ACCEPT # A little trick I do to keep myself and others from accidentally drilling holes into the security I finally add: iptables -A INPUT -j DROP # This line matches everything for the INPUT chain and the policy should not get anything. # advantage of this is even if you add an # ACCEPT-rule sometime after initializing your ruleset it will never become checked because # everything is droped before. so it ensures # you have to keep everything in one place. # For your question the whole thing looks like this in summary: iptables -F iptables -P INPUT DROP iptables -A INPUT -i lo -p all -j ACCEPT iptables -A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 1962 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 999 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 12020 -j ACCEPT iptables -A INPUT -j DROP 这在后续博文中可能有所涉及。\n","date":"2020-01-17","permalink":"http://localhost:1313/posts/20200117-iptables/","section":"","summary":"","tags":[],"title":"iptables 禁止端口和开放端口"},{"categories":[],"contents":"禁用NETBIOS后，局域网内计算机不可以在地址栏用主机名访问你的主机，更安全。\n以下为批处理自动关闭netbios脚本:\n@echo off rem off_netbios_Self_Del for /L %%a in (1,1,20) do ( wmic nicconfig where index=\u0026#39;%%a\u0026#39; call settcpipnetbios 2 ) cd /d %~dp0 if exist one_time.cmd ( del /f /q %0 exit ) rename %0 one_time.cmd exit 功能: 一键关闭netbios，执行完第二次后自己删除自己。\n适用性:， 在win7及win2008测试通过，其它系统没测。\n说明: 用法：复制上述脚本随便起个名，扩展名改为bat或者cmd。最好把文件放到开机启动目录，开机就运行。windows下自启动目录如下： C:\\ProgramData\\Microsoft\\Windows\\Start Menu\\Programs\\Startup\n如何开启NETBIOS? 把上述代码第四行最后数字改为1即为开启，改为0即为默认设置，为2时代表关闭（上述代码已默认设为关闭NETBIOS)。\n为何要第二次才删除？ 如果是新装或者复制了系统，第一次开机是检测并安装网卡设备。如果未安装完网卡就运行完脚本，那脚本就发挥不了作用。\n运行流程： 在运行第一次的时候会自动把本脚本重命名为one_time.cmd 在第二次运行脚本监测到有one_time.cmd文件后会自我删除。 本脚本用for循环20次，每个网卡都尝试关闭NETBIOS,（一般系统有十多个网卡序号）如果不够（不放心）就就把第三行代码由数字20改为30或更多。如果想要查看自己的网卡序号可以在CMD里输入以下命令：wmic nicconfig Get Caption,index\n参考文档:批处理如何恢复Netbios\n","date":"2020-01-17","permalink":"http://localhost:1313/posts/20200117-netbios/","section":"","summary":"","tags":["",""],"title":"批处理关闭或开启NETBIOS"},{"categories":[],"contents":"习惯了Linux系统的人们，肯定觉得Samba服务更加灵活和方便，那如何在Windows系统上搭建高效的Samba服务呢？本文介绍了通过WSL在Win10系统上，搭建Samba文件共享服务。\n背景是家里只有一个台式机，一方面家里人偶尔使用，另一方面，它是家里的数据中心，挂载了多块硬盘。所以系统用的是Windows10，但是为了方便灵活得进行文件共享，一直考虑搭建Samba服务。达到此目的的方案有多种，可以考虑用虚拟机，例如：VMWare、VirtualBox、Hyper-V，也可以考虑使用CygWin，因为Windows10提供了WSL，所以本文介绍了另一种方式，也是运行效率比较高的一种方式，使用WSL搭建Samba服务。\n背景知识 Windows文件共享服务 使用网络对外提供文件访问服务，现在广泛用于局域网内部文件的共享，例如：小米盒子、手机、PC机、包括Mac，通过139或445端口。\n139 - 早期Windows的SMB运行于NBT（NetBIOS over TCP/IP）上，使用139端口 445 - Windows2000及以上版本，SMB可以直接运行与TCP/IP上，使用445端口，效率更高 对不同版本的Windows做了抓包测试，发现WinXP只访问139端口，Win7同时访问139与445端口，Win10只访问445端口，测试结果如下：\nWindows10 win10-err\nwin10-pkg\nWindows7 win7-err\nwin7-pkg\nWindowsXP winxp-err\nwinxp-pkg\nWSL（Windows Subsystem for Linux） 是在Windows10系统上，对Windows内核进行了封装，使其可以直接支持ELF格式的Linux可执行程序，感觉有点像GNU/Windows。 现在基于WSL，已经有了多个Linux发行版，包括Ubuntu、Debian、Suse、Kali等，能够非常方便得在Windows里面运行Linux发行版，学习和使用各种Linux工具，同时也能够将Linux里面各种服务无缝集成到Windows环境中，例如：Samba服务、SSH服务等\nSamba服务 为了实现UNIX、Linux等非Windows能够访问Windows的文件共享资源，之前有个大牛将SMB（Server Message Block）协议进行了逆向分析，然后根据逆向分析的协议开发了一套开源软件Samba，可以让UNIX、Linux、Mac等系统能够与Windows之间进行文件共享。目前最新的Samba甚至可以提供AD、DC等服务。\n总体方案 根据以上背景知识，在Windows10上通过WSL搭建Samba服务的方案如下：\n释放Windows占用的139，445端口 安装WSL和Ubuntu发行版 安装Samba服务，并且配置 更改防火墙配置 最后测试 实施步骤 释放Windows占用的139，445端口 释放139端口 安装完毕的Windows10系统，默认情况下会监听139与445端口，通过netstat -a|findstr LISTENING可以查看： cmd001 禁用NetBIOS over TCP/IP，通过如下操作禁用，在“更改适配器设置”界面，双击对应网卡，打开“以太网状态”界面： netbios001 点击“属性”打开“以太网属性”界面： netbios002 选中“TCP/IPv4”项目，点击“属性”，打开“TCP/IPv4属性”界面： netbios003 点击“高级”并选中“WINS”页签，勾选“禁用TCP/IP上的NetBIOS”： 点击“确定”以后生效，如果有多块网卡，每块网卡都要按照如上步骤操作，操作完毕以后，还是通过netstat命令进行查看，发现139端口已经不再监听。 netbios005 释放445端口 通过“WIN+R”打开运行窗口，输入：services.msc，打开服务管理界面： services001 找到Computer Browser服务，双击该服务打开属性界面，将“启动类型”修改为禁用，并且直接点击“停止”： services002 找到Server服务： services003 双击Server服务，打开属性界面，将“启动类型”修改为禁用，并且直接点击“停止”： services004 设置完毕以后重启系统。 重启完毕以后，再通过netstat -a|findstr LISTENING命令检查端口使用情况，发现445端口已经释放成功。 cmd002 安装WSL和Ubuntu发行版 在“程序和功能”管理界面，点击“启用或关闭Windows功能”，在“Windows功能”列表中，勾选“适用于Linux的Windows子系统”（注意：不同的Windows版本可能名字有所差别，我试验的是17134.191版本） addfunction001 重启系统，然后打开“Microsoft Store”应用商城，在搜索栏里面输入wsl： appstore001 选择搜索结果中的Ubuntu 16.04（其他发行版应该也可以，本次试验的是Ubuntu），并且进行安装： appstore002 安装过程比较快，得益于家里的宽带： appstore003 安装完毕以后在“开始菜单”可以找到Ubuntu： startmenu001 点击图标打开控制台，也可以通过“运行”界面，先打开“CMD”窗口，再通过bash命令进入Ubuntu的命令行模式： bash001 安装Samba服务，并且配置 安装Samba服务： 先升级apt-get工具，命令：sudo apt-get update： apt-get 安装samba软件包，命令：sudo apt install samba： installsamba 配置samba服务： 这里只是一个配置示例，用最简单的配置让服务跑起来，如果需要深入了解samba服务的配置，建议去网上找更多的攻略。\n打开配置文件，并进行编辑：sudo vi /etc/samba/smb.conf，这里配置了一个用户私有目录homes，以及一个所有人可读写的共享目录share，对应windows上的目录分别是c:\\private\u0026lt;用户名\u0026gt;，以及c:\\share： sambaconfig 具体配置文件内容如下：\n[global] workgroup = WORKGROUP server string = jamieli-vm log file = /var/log/samba/log.%m log level = 0 max log size = 1000 security = user map to guest = Bad User passdb backend = smbpasswd smb passwd file = /etc/samba/smbpasswd username map = /etc/samba/smbusers guest account = nobody os level = 64\n[homes] comment = user private path = /mnt/c/private/%u read only = No\n[share] comment = home share guest ok = Yes path = /mnt/c/share read only = No public = Yes 写好配置文件，因为是user安全模式，所以需要添加一个smb用户，命令：sudo smbpasswd -a jamieli，并输入密码： smbpasswd 启动smbd服务，sudo service smbd start： servicestart 在Windows的CMD窗口查看端口暂用情况，发现139与445被smbd服务占用了： cmd004 通过Windows本地的资源管理器，输入本机IP地址，可以访问到共享目录： localvisit001 在homes目录中，创建一个test目录，可以看到对应c:\\private\\jamieli目录中，多了一个相同的目录： localvisit002 但是通过另外一台机器访问，发现访问失败，原因就是防火墙的设置问题，下一节我们讲下如何配置防火墙: macerr001\nmacerr002 更改防火墙配置 在“运行”界面输入：wf.msc，启动防火墙配置界面，选中“入站规则”菜单，右侧点击“新建规则”： wf001 在“新建入站规则向导”界面中，选中“端口”： wf002 选择“TCP”，并且输入端口“139,445”： wf003 选择“允许连接”： wf004 起名为“samba服务”，点击“完成”： wf005 最后测试： 在Mac下面进行访问测试，在Finder界面下使用“CMD+K”，打开“连接服务器”界面，输入之前配置的服务器地址： mac001 输入通过smbpasswd命令添加的SMB账户与密码： mac002 成功访问通过WSL搭建的Samba服务，此时关闭Ubuntu窗口没有任何影响，服务在后台会继续运行： mac003 总结 通过该服务配置的过程，大体了解了WSL的使用，通过该方式也可以在Windows上部署SSH等服务，对于熟悉Linux系统的人员来说是一大福音。 同时通过一些工具，也可以将这些服务包装成Windows的Service，Windows启动的时候自动加载这些服务。\n增加samba用户提示Failed to add entry for user [root@ubuntu ~]# smbpasswd -a test New SMB password: Retype new SMB password: Failed to add entry for user test.\n解决办法: 这是因为没有加相应的系统账号，所以会提示Failed to add entry for user的错误，只需增加相应的系统账号test就可以了:\n[root@ubuntu ~]# groupadd test -g 6000 [root@ubuntu ~]# useradd test -u 6000 -g 6000 -s /sbin/nologin -d /dev/null 这时就可以用smbpasswd -a test增加test这个samba账号了!为了增加系统的安全性，所以加的系统账号不要给shell它，也不给它指定目录，到时在/home目录给test账号建个文件夹，该文件夹只有test有读写权限即可! 如:\n[root@ubuntu ~]# mkdir /home/test [root@ubuntu ~]# chown -R test:test /home/test 若不想让另人访问，只让test用户可以访问，只需执行命令: [root@ubuntu ~]# chmod u+rwx,g+rwx,o-rwx /home/test\n这时可以用smbpasswd命令增加samba账号test了\n[root@ubuntu ~]# smbpasswd -a test New SMB password: Retype new SMB password: Added user test. samba 4.5.0之后win10显示密码错误 samba 4.5.0之后ntlm auth的默认选项由yes改成了no，如果windows安全策略仍使用ntlm，就会导致密码出错。\n所以有两种修改方法\n1.改Windows(我现在用的方法) 打开windows安全策略：win+R后输入secpol.msc 安全策略-\u0026gt;本地策略-\u0026gt;安全选项 将 网络安全.Lan管理器身份验证级别 的选项改为“仅发送NTLMv2响应，拒绝LM和NTLM”\n2.改Linux(未测试) 在/etc/samba/smb.conf配置文件的[global]组中加入 ntlmauth = yes 然后重启samba服务\nservice smbd restart # systemd systemctl restart smb nmb 参考 NetBIOS over TCP/IP\nWindows Subsystem for Linux Documentation\n4.5.0的详细更新在这，开头就是ntlm的默认值改动\n","date":"2020-01-17","permalink":"http://localhost:1313/posts/20200117-wsl-samba/","section":"","summary":"","tags":["","",""],"title":"玩转WSL-用Samba服务替代Win10原生的文件共享"},{"categories":[],"contents":"Diskpart 命令简介 Diskpart 命令是 Windows 环境下的一个命令，利用 Diskpart 可实现对硬盘的分区管理，包括创建分区、删除分区、合并（扩展）分区，设置分区后即刻生效，免去了重启电脑的操作。\n正常运行该命令时需要系统服务的支持，所以在纯 DOS、XP 内核的 WinPE 环境下都是不能运行的，但是在 Win7 的预安装环境下却是可以的。利用 Diskpart 命令来分区，既不用借助第三方工具，也不会产生 100MB 的“系统保留”分区，其次分区操作直接设置即刻生效，不用重新启动计算机。\n利用 Diskpart 命令分区 当安装程序运行到创建磁盘分区界面时按下 Shift+F10 启动命令窗口。\n键入 Diskpart 进入 Diskpart 的命令环境，其提示符为 DISKPART\u0026gt;。\n在此提示下键入相应命令就可以进行分区操作，具体用到的命令有：\nClean List Select Create Format Exit 这些命令的使用方法可以在 Diskpart 命令提示符下键入 Help 或者通过网络查询，如果不清楚可以查看。\n使用 List Disk 命令显示的目标磁盘若为 1 号，则建立分区的步骤如下：以下是命令顺序及操作解释：\nList Disk：显示本机的所有磁盘，以便正确操作目标磁盘 Select Disk 1：选择 0 号磁盘 Clean ：清除 0 号磁盘上的所有分区 Create Partition Primary Size=512000 ：创建主分区，容量为：512000MB Active：激活主分区 Format Quick：快速格式化当前分区 Create Partition Extended：创建扩展分区 Create Partition Logical Size=512000：创建逻辑分区一，容量为：512000MB Format Quick：快速格式化当前分区 Create Partition Logical Size=512000：创建逻辑分区二，容量为：512000MB Format Quick ：快速格式化当前分区 Create Partition Logical ：创建逻辑分区三，大小为剩余的容量 Format Quick ：快速格式化当前分区 Exit ：退出Diskpart命令环境 Exit ：退出命令窗口 这里要注意的是 Diskpart 分区时，一定要选对目标磁盘，当前被选中的磁盘 / 分区前面会有 * 号标志，可以用 List Disk / Partition 来进行查看。\nwin7安装时使用diskpart分区 1、在安装win7系统到分区这一步的时候，按住shift+F10调出命令行窗口 2、输入命令：diskpart ###启动diskpart 3、输入命令：list disk ###查看所有磁盘，一般情况下，都只有一个磁盘，列表里也只会列出一项 磁盘0 4、输入命令：select disk 0 ###选择要操作的磁盘，并将该磁盘设置为当前操作磁盘，只有一块磁盘的话，选择0，如果你有多个磁盘的话，自己根据需要进行选择 5、输入命令：clean ###清除该磁盘上的所有分区 6、输入命令：create partition primary size=20480 ###创建主分区，size默认单位MB，不加size则会将剩余的所有磁盘空间创建为一个主分区，扩展与逻辑分区类似 7、输入命令：active ###将当前主分区标为要操作的主分区 8、输入命令：format quick ###快速格式化分区 如果你准备创建多个主分区，那么重复6、7、8步骤就可以了，如果只创建一个主分区，继续下面的步骤 9、输入命令：create partition extended ###将剩余空间全部创建为扩展分区 10、输入命令：create partition logical ###将扩展分区的全部剩余空间创建为一个逻辑分区，你也可以指定size参数，将剩余空间创建出多个逻辑分区 11、输入命令：format qucik ###快速格式化该逻辑分区 12、输入命令：exit ###退出diskpart 13、输入命令：exit ###退出命令行窗口 # 分配盘符 assign 回到win7安装分区步骤，点击刷新，选择你要安装的磁盘分区进行安装就可以了。 注：这里不要再格式化了\n20210106更新 谈笑风生又一年，最近在做一个游戏多开挂机项目，一年前的win10还是被我玩炸了，Google无解懒得研究重新开始吧，反正就一堆垃圾，吸取教训这次用uefi引导\ndiskpart select disk 39 select partition 1 # 删除分区 delete partition # 先转换成GPT convert gpt # 创建EFI分区 create partition efi size=100 format quick fs=FAT32 # 创建主分区 create partition primary format quick 收工，希望明年不要再折腾win10了。。。\n","date":"2020-01-16","permalink":"http://localhost:1313/posts/20200116-using-diskpart-to-create/","section":"","summary":"","tags":["",""],"title":"Windows 下使用 Diskpart 命令分区"},{"categories":[],"contents":"最近使用终端git的时候觉得速度有点慢，考虑一下是不是可以通过让终端走代理的方式来加快速度，尝试了一下以后确实是可以的。如果只是为了设置git的话可以直接在文章最后找到git的设置代理的方法。\n前期准备: 认识代理的方式:代理是通过客户端与服务端通信,传输服务端能够访问到的资源文件,再由服务端客户端通信返回给客户端,从而间接访问服务端能访问的资源.\n以socket5通信为例子,我们通过客户端(自己想一想酸酸乳)向服务端发送socket通信,服务端访问资源再由socket通信返回给客户端.但是这里面的通信设置必须通过端口来进行通信,类似switchyomega设置过程一样,我们会设定走的代理方式是127.0.0.1:1080;这个意思就是通过本地的1080端口来进行通信.具体在终端上如何使用呢?\n如果默认是socket5通信且端口是1080,即127.0.01:1080的方式 使用如下两种方式\nsocks5://127.0.0.1:1080 这里无关自己代理客户端是不是酸酸乳或酸酸只要是通过socket通信即可,前提是满足已经能够正常代理访问.\n第二种是http代理,即通信方式为http而不是socket http://127.0.0.1:12333 详细举例:\n这里的客户端有两种方式,一个是socket通信,一个是http通信,两个方式对应的端口不同,在下文中不同代理方式设置的端口也不同. 实在不懂的记住:先把代理调试通,然后就直接打开switchyomega看看自己的设置,都是一样的\n方法一：（推荐使用） 为什么说这个方法推荐使用呢？因为他只作用于当前终端中，不会影响环境，而且命令比较简单 在终端中直接运行：\nexport http_proxy=http://proxyAddress:port 如果你是SSR,并且走的http的代理端口是12333，想执行wget或者curl来下载国外的东西，可以使用如下命令：\nexport http_proxy=http://127.0.0.1:12333 如果是https那么就经过如下命令：\nexport https_proxy=http://127.0.0.1:12333 方法二 ： 这个办法的好处是把代理服务器永久保存了，下次就可以直接用了 把代理服务器地址写入shell配置文件.bashrc或者.zshrc 直接在.bashrc或者.zshrc添加下面内容\nexport http_proxy=\u0026#34;http://localhost:port\u0026#34; export https_proxy=\u0026#34;http://localhost:port\u0026#34; 或者走socket5协议（ss,ssr）的话，代理端口是1080\nexport http_proxy=\u0026#34;socks5://127.0.0.1:1080\u0026#34; export https_proxy=\u0026#34;socks5://127.0.0.1:1080\u0026#34; 或者干脆直接设置ALL_PROXY\nexport ALL_PROXY=socks5://127.0.0.1:1080 最后在执行如下命令应用设置\nsource ~/.bashrc 或者通过设置alias简写来简化操作，每次要用的时候输入setproxy，不用了就unsetproxy。\nalias setproxy=\u0026#34;export ALL_PROXY=socks5://127.0.0.1:1080\u0026#34; alias unsetproxy=\u0026#34;unset ALL_PROXY\u0026#34; 方法三: 改相应工具的配置，比如apt的配置\nsudo vim /etc/apt/apt.conf 在文件末尾加入下面这行\nAcquire::http::Proxy \u0026ldquo;http://proxyAddress:port\u0026rdquo; 重点来了！！如果说经常使用git对于其他方面都不是经常使用，可以直接配置git的命令。 使用ss/ssr来加快git的速度 直接输入这个命令就好了\ngit config --global http.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; git config --global https.proxy \u0026#39;socks5://127.0.0.1:1080\u0026#39; ","date":"2020-01-11","permalink":"http://localhost:1313/posts/20200111-set-proxy-for-terminal/","section":"","summary":"","tags":["","",""],"title":"Linux 让终端走代理的几种方法"},{"categories":[],"contents":" 最好是先复制到自己的网盘。\n点击分享，生成链接。\n点击链接，进入页面。在console模式下输入如下代码：\n$.ajax({ type: \u0026#34;POST\u0026#34;, url: \u0026#34;/api/sharedownload?sign=\u0026#34;+yunData.SIGN+\u0026#34;\u0026amp;timestamp=\u0026#34;+yunData.TIMESTAMP, data: \u0026#34;encrypt=0\u0026amp;product=share\u0026amp;uk=\u0026#34;+yunData.SHARE_UK+\u0026#34;\u0026amp;primaryid=\u0026#34;+yunData.SHARE_ID+\u0026#34;\u0026amp;fid_list=%5B\u0026#34;+yunData.FS_ID+\u0026#34;%5D\u0026#34;, dataType: \u0026#34;json\u0026#34;, success: function(d){ window.location.href = d.list[0].dlink; } }); 客户端接口加密算法\n","date":"2020-01-10","permalink":"http://localhost:1313/posts/20200110-baiduyun-dlink/","section":"","summary":"","tags":[""],"title":"百度云分享下载链接"},{"categories":[],"contents":"github一直都是在上面拿资源。感觉有点愧对大众。是不是应该奉献自己的力量给github来推动开源的发展呢。 在两个月前第一次在github新建项目，并且push了一套比赛的源码。但。。。今天竟然忘了怎么用git了。又复习了一次。所以这次打算在这里作个笔记。给自己做个的或是给git新手做的也好吧。为互联网贡献一点力量。\n安装git和配置就不说了。\n进入到等下要push的代码的目录文件夹，打开bash 请输入图片描述\n进入到等下要push的代码的目录文件夹，打开bash 请输入图片描述\n初始化 git init 初始化后在本地代码库会自动创建一个.git隐藏文件，这个就是本地代码库\n加载文件 git add . . 是把文件夹里面的所有文件都加载进来\n还可以单个加载\ngit add index.html,test.html 四：\n提交文件，创建时间点 git commit -m \u0026#34;init commit\u0026#34; -m \u0026ldquo;这里的文件是注释\u0026rdquo;\n创建之后可以随时回到这个时间点，可以看到有4个文件被修改了，47个插入，51个删除 请输入图片描述\n可以随时用\ngit status 查看git的状态\n推送代码 第一次推送的时候要添加远程的代码库到配置\ngit remote add origin https://github.com/zhong635725959/droplook.git origin可变，随自己喜欢\n推送代码：\ngit push origin master 拉取代码强制合并：\ngit pull origin master --allow-unrelated-histories 然后会要求输入github的帐号和密码（不可见的） 请输入图片描述\nOK,成功\n解决向github提交代码是老要输入用户名密码\n元亨利贞o 0.723 2016.04.20 22:08:27 字数 524 阅读 18,138 我曾经切换过一次github账号, 似乎还更改过一次github账号的密码, 然后呢? 然后就是每次向github提交代码时都要输入用户名密码(猜测是由于上述原因导致), 每次都是啊, 这也忒麻烦了, 于是就想办法解决这个问题, 经过一番查找, 终于找到一个解决办法, 分享之, 与君共勉 !!\n==============\n解决方案:\n在你的用户目录下新建一个文本文件, 名曰.git-credentials 用户目录: windows: C:/Users/username mac os x: /Users/username linux: /home/username 在上一步创建的文件中输入一下内容: https:{username}:{password}@github.com 当然上述{username}和{password}要换成你的github的账号名和密码 修改git配置 执行命令git config \u0026ndash;global credential.helper store 上述命令会在~/.gitconfig文件末尾添加如下配置: [credential] helper = store 经过上述三步配置之后, 你push代码到github时, 便无需再输入用户名密码了~~\n================= 续集\u0026hellip;\u0026hellip; 后来发现, 不用上面三步这么麻烦, 简化流程如下:\n在命令行输入命令: git config \u0026ndash;global credential.helper store ☞ 这一步会在用户目录下的.gitconfig文件最后添加: [credential] helper = store 现在push你的代码 (git push), 这时会让你输入用户名密码, 这一步输入的用户名密码会被记住, 下次再push代码时就不用输入用户名密码啦! ☞这一步会在用户目录下生成文件.git-credential记录用户名密码的信息. ☞ git config \u0026ndash;global 命令实际上在操作用户目录下的.gitconfig文件, 我们cat一下此文件(cat .gitconfig), 其内容如下: [user] name = alice email = alice@aol.com [push] default = simple [credential] helper = store git config \u0026ndash;global user.email \u0026ldquo;alice@aol.com\u0026rdquo; 操作的就是上面的email git config \u0026ndash;global push.default matching 操作的就是上面的push段中的default字段 git config \u0026ndash;global credential.helper store 操作的就是上面最后一行的值\n问题： 在这成功之前遇到了一个问题。update were rejected because the tip of your current branch is behind \u0026hellip;.\n原因是远程的的代码库比我本地的代码库要新。所以需要在远程代码库pull一次下来。再修改代码。再push。成功。解决了。 请输入图片描述\n—————————————华丽的分割线——————————————————————\n这是我第一次写技术博客。不知道这种算不算是技术博客呢。欢迎吐槽哈。应该有好多问题的。\n之前在csdn看到一牛人的一个提升自我能力的一个建议就是写技术博客。\n已经想动手久了。但一直没动。这次终于动手了。希望可以坚持下去。加油\n—————————————华丽的分割线——————————————————————\n指定私钥 git config core.sshCommand \u0026#34;ssh -i YOUR_ID_PATH\u0026#34; 参考链接 https://help.github.com/cn/github/using-git/pushing-commits-to-a-remote-repository\n","date":"2020-01-08","permalink":"http://localhost:1313/posts/20200108-github-pull/","section":"","summary":"","tags":[""],"title":"Github Pull"}]